{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Tuan's Blog","text":"<p>Welcome to my digital garden where I cultivate thoughts on Machine Learning, Generative AI, Trustworthy AI, AI Systems, Efficient AI, and Paper Reviews.</p>"},{"location":"#about-this-blog","title":"About This Blog","text":"<p>This platform serves as a repository for:</p> <ul> <li>Deep Dives: Rigorous mathematical explorations of ML algorithms.</li> <li>Practical Guides: Hands-on code tutorials and systems engineering patterns.</li> <li>Research Notes: Summaries and thoughts on the latest papers in GenAI, Trustworthy AI, AI Systems, Efficient AI, and Paper Reviews.</li> </ul> <p>Work in Progress</p> <p>This blog is continuously evolving. Check back often for updates!</p>"},{"location":"#recent-topics","title":"Recent Topics","text":"<ul> <li> <p> Machine Learning Theory</p> <p>Foundational concepts, proofs, and algorithmic breakdowns. Explore ML Theory</p> </li> <li> <p> Generative AI</p> <p>LLMs, diffusion models, and the frontier of creation. Explore GenAI</p> </li> <li> <p> Trustworthy AI</p> <p>Safety, bias, robustness, and alignment. Explore Trustworthy AI</p> </li> <li> <p> AI Systems</p> <p>Infrastructure, distributed training, and cluster orchestration. Explore SysML</p> </li> <li> <p> CUDA Engineering</p> <p>Zero to Hero: GPU Architecture, Kernels, and Tensor Cores. Start Learning</p> </li> <li> <p> Efficient AI</p> <p>Quantization, pruning, and system optimizations. Explore Efficient AI</p> </li> <li> <p> Paper Reviews</p> <p>Critical breakdowns of the latest Arxiv papers. Read Reviews</p> </li> </ul>"},{"location":"ai-systems/","title":"AI Systems (SysML)","text":"<p>Bridging the gap between cutting-edge algorithms and massive-scale hardware.</p>"},{"location":"ai-systems/#sota-roadmap","title":"SOTA Roadmap","text":""},{"location":"ai-systems/#1-scaling-infrastructure","title":"1. Scaling Infrastructure","text":"<ul> <li>Cluster Orchestration: Kubernetes for ML (KubeFlow, Ray on K8s), Slurm.</li> <li>Interconnects: InfiniBand vs Ethernet (RoCEv2), NVLink/NVSwitch topology.</li> <li>Storage: High-performance implementations (Lustre, GPUDirect Storage).</li> </ul>"},{"location":"ai-systems/#2-distributed-training-frameworks","title":"2. Distributed Training Frameworks","text":"<ul> <li>3D Parallelism: Creating the optimal recipe of Data, Tensor, and Pipeline parallelism (Megatron-LM).</li> <li>Optimization: ZeRO Stages (DeepSpeed), FSDP (Fully Sharded Data Parallel).</li> <li>Fault Tolerance: Checkpointing strategies, auto-recovery design.</li> </ul>"},{"location":"ai-systems/#3-inference-at-scale","title":"3. Inference at Scale","text":"<ul> <li>Serving Engines: Deeper dive into TGI vs vLLM vs TRT-LLM architectures.</li> <li>Continuous Batching: Orca scheduling.</li> <li>Prefill vs/and Decode separation: Distaggregating prefill and decode compute (Splitwise).</li> </ul>"},{"location":"ai-systems/#4-data-engineering-for-ai","title":"4. Data Engineering for AI","text":"<ul> <li>Dataloaders: Ray Data, MosaicML Streaming.</li> <li>Formats: Parquet, Arrow, LanceDB.</li> </ul>"},{"location":"ai-systems/#key-resources","title":"Key Resources","text":"<ul> <li>Course: CS329S: Machine Learning Systems Design (Stanford/Chip Huyen).</li> <li>Blog: Chip Huyen's Blog (Real-world MLSys).</li> <li>Paper: Efficient Large-Scale Language Model Training on GPU Clusters (Megatron-LM).</li> </ul>"},{"location":"cuda/","title":"CUDA Engineering","text":"<p>The path to mastering GPU programming, High-Performance Computing (HPC), and securing a role at NVIDIA/Core AI Labs.</p>"},{"location":"cuda/#zero-to-hero-roadmap","title":"Zero to Hero Roadmap","text":""},{"location":"cuda/#0-the-foundation-prerequisites","title":"0. The Foundation (Prerequisites)","text":"<ul> <li>Modern C++: Pointers, Memory Layout, RAII, and <code>std::vector</code> internals. NVIDIA requires strong C++ skills, not just Python.</li> <li>Computer Architecture: Cache hierarchies (L1/L2), SIMD concepts, and Latency vs Throughput.</li> </ul>"},{"location":"cuda/#1-kernel-basics","title":"1. Kernel Basics","text":"<ul> <li>GPU Architecture: SMs, Warps, Scheduling, and the execution hierarchy.</li> <li>Structuring Kernels: Grids, Blocks, Threads mapping.</li> <li>Hello World: Vector Addition, Matrix Multiplication (Naive).</li> </ul>"},{"location":"cuda/#2-tools-of-the-trade-crucial","title":"2. Tools of the Trade (Crucial)","text":"<ul> <li>Profiling: Using Nsight Compute (NCU) and Nsight Systems (NSYS) to identify bottlenecks.</li> <li>Debugging: Compute Sanitizer and <code>printf</code> debugging strategies.</li> </ul>"},{"location":"cuda/#3-memory-mastery","title":"3. Memory Mastery","text":"<ul> <li>Global Memory: Coalescing patterns to maximize bandwidth.</li> <li>Shared Memory: Using the L1/Shared cache for tiling (Tiled MatMul).</li> <li>Register File: Optimization and preventing spills.</li> </ul>"},{"location":"cuda/#4-compute-optimization","title":"4. Compute Optimization","text":"<ul> <li>Control Flow: Branch divergence minimization.</li> <li>Warp Primitives: Shuffle instructions for fast reductions.</li> <li>Occupancy: Calculating optimal thread/block usage.</li> </ul>"},{"location":"cuda/#5-advanced-modern-cuda","title":"5. Advanced &amp; Modern CUDA","text":"<ul> <li>Tensor Cores: Using <code>wmma</code> intrinsics (Volta/Ampere/Hopper).</li> <li>CUTLASS: Understanding the template library for high-performance GEMMs.</li> <li>Triton: The Pythonic way to write CUDA (OpenAI).</li> </ul>"},{"location":"cuda/#6-capstone-projects-resume-builders","title":"6. Capstone Projects (Resume Builders)","text":"<ul> <li>Optimized MatMul: Implementing tiling and analyzing performance vs cuBLAS.</li> <li>Custom Attention: Writing FlashAttention from scratch.</li> <li>Requirement: Every project must include Benchmarks (Op/s, Bandwidth) and Nsight timeline analysis.</li> </ul>"},{"location":"cuda/#deep-dive-pmpp-study-notes","title":"\ud83d\udcd6 Deep Dive: PMPP Study Notes","text":"<p>I am currently working through the 4<sup>th</sup> Edition of \"Programming Massively Parallel Processors\". </p> <ul> <li>PMPP Book Overview: Syllabus and core concepts.</li> <li>Chapter 1: Introduction: The shift to throughput-oriented computing.</li> <li>Chapter 2: Data Parallel Computing: Kernels, Grids, Blocks, and Threads.</li> <li>Chapter 3: Multidimensional Grids: 2D/3D mapping and matrix operations.</li> <li>Chapter 4: Compute Architecture: SMs, warps, and occupancy.</li> <li>Chapter 5: Memory Architecture: Tiling and shared memory optimization.</li> <li>Chapter 6: Performance Considerations: Coalescing and thread coarsening.</li> <li>Chapter 7: Convolution: Constant memory and halo cells.</li> <li>Chapter 8: Stencil: 3D patterns and register tiling.</li> <li>Chapter 9: Parallel Histogram: Atomic operations and privatization.</li> <li>Chapter 10: Reduction: Minimizing divergence and hierarchical reduction.</li> <li>Chapter 11: Prefix Sum (Scan): Parallelizing sequential recursions.</li> <li>Chapter 12: Parallel Merge: Data-dependent workload boundaries.</li> <li>Chapter 13: Parallel Sorting: Efficient data movement for sorting.</li> <li>Chapter 14: Sparse Matrix Computation: Handling irregular data structures.</li> <li>Chapter 15: Parallel Graph Algorithms: Vertex and edge centric processing.</li> <li>Chapter 16: Deep Learning: Modern AI as matrix multiplications.</li> <li>Chapter 17: MRI Reconstruction: Hardware trigonometry and constant cache.</li> <li>Chapter 18: Molecular Dynamics: Spatial binning and cutoff summation.</li> <li>Chapter 19: Programming Strategy: Computational thinking and algorithm selection.</li> <li>Chapter 20: Heterogeneous Clusters: Scaling with MPI and CUDA Streams.</li> <li>Chapter 21: Dynamic Parallelism: Kernels launching other kernels.</li> <li>Chapter 22: Evolution and Trends: Unified Memory and task-level concurrency.</li> <li>Chapter 23: Conclusion: The future of throughput-oriented computing.</li> <li>Appendix A: Numerical Issues: Floating-point precision and stability.</li> <li>GPU Engineer Roadmap: Career advice and landing roles at top tech companies.</li> </ul>"},{"location":"cuda/#key-resources","title":"Key Resources","text":"<ul> <li>Book: Programming Massively Parallel Processors (The \"Bible\" of GPU programming).</li> <li>Official Docs: CUDA C++ Programming Guide &amp; Best Practices Guide.</li> <li>Community: CUDA Mode (Excellent lectures &amp; repo).</li> <li>Interactive: GPU Mode Lectures (YouTube).</li> </ul>"},{"location":"cuda/pmpp/","title":"Programming Massively Parallel Processors (PMPP) - Overview","text":"EnglishTi\u1ebfng Vi\u1ec7t"},{"location":"cuda/pmpp/#en-syllabus","title":"Syllabus: PMPP (4<sup>th</sup> Edition)","text":"<p>This syllabus is organized into four major phases: Foundations, Performance Optimization, Parallel Patterns, and Advanced Applications (AI/ML).</p>"},{"location":"cuda/pmpp/#en-phase1","title":"Phase 1: Foundations of GPU Computing","text":"<ol> <li>Introduction to Heterogeneous Computing: Why parallel computing? The shift from \"faster clocks\" to \"more cores.\"</li> <li>The CUDA Programming Model: Kernels, grids, blocks, and threads. Your first \"Vector Addition\" program.</li> <li>Data-Parallel Execution Model: Understanding the SIMT (Single Instruction, Multiple Threads) architecture and hardware multithreading.</li> <li>GPU Memory Hierarchy: Global, constant, and shared memory; registers and caches.</li> </ol>"},{"location":"cuda/pmpp/#en-phase2","title":"Phase 2: Performance and Hardware Architecture","text":"<ol> <li>Performance Considerations: Thread divergence, memory coalescing, and latency hiding.</li> <li>Compute Capability and Occupancy: How to balance resources (registers/shared memory) to keep the GPU fully utilized.</li> <li>Floating Point Excellence: Understanding precision (FP32, FP16, BF16) and numerical stability.</li> </ol>"},{"location":"cuda/pmpp/#en-phase3","title":"Phase 3: Fundamental Parallel Patterns","text":"<ol> <li>Convolution: Implementation of 1D and 2D filters.</li> <li>Prefix Sum (Scan): Solving problems that seem inherently sequential.</li> <li>Reduction: Efficiently summing or finding the max/min of billions of elements.</li> <li>Stencil Computation: Grid-based updates (used in weather simulations).</li> <li>Histogramming: Dealing with \"atomic\" operations and memory contention.</li> <li>Sparse Matrix-Vector Multiplication (SpMV): Handling data where most values are zero.</li> <li>Merge Sort: Implementing high-performance sorting on the GPU.</li> </ol>"},{"location":"cuda/pmpp/#en-phase4","title":"Phase 4: Advanced Topics and Modern AI","text":"<ol> <li>Deep Learning and Tensor Cores: (New in 4<sup>th</sup> Ed) How GPUs accelerate Transformers and CNNs.</li> <li>Graph Processing: Navigating irregular data structures.</li> <li>Dynamic Parallelism: Kernels launching other kernels.</li> <li>Multi-GPU Programming: Using NVLink and MPI.</li> </ol>"},{"location":"cuda/pmpp/#en-unique","title":"What makes this book unique?","text":"<p>The 4<sup>th</sup> Edition is a masterclass in \"Thinking in Parallel.\"</p> <ol> <li>Pattern-Based Teaching: Focuses on \"Algorithmic Patterns\" like Reduction, Scan, and Convolution rather than just syntax.</li> <li>Bridging Software and Hardware: Explains why code is slow by looking at hardware limitations (bandwidth, warp scheduling).</li> <li>Focus on Modern AI: Significant new content on Tensor Cores and Mixed Precision (FP16/INT8).</li> </ol>"},{"location":"cuda/pmpp/#en-path-beyond","title":"The Path Beyond","text":"<p>Ready to turn this knowledge into a career? Check out the GPU Engineer Roadmap for advice on projects, portfolios, and interviewing.</p>"},{"location":"cuda/pmpp/#vi-syllabus","title":"L\u1ed9 tr\u00ecnh h\u1ecdc: PMPP (\u1ea4n b\u1ea3n th\u1ee9 4)","text":"<p>L\u1ed9 tr\u00ecnh n\u00e0y \u0111\u01b0\u1ee3c chia th\u00e0nh b\u1ed1n giai \u0111o\u1ea1n ch\u00ednh: N\u1ec1n t\u1ea3ng, T\u1ed1i \u01b0u h\u00f3a hi\u1ec7u n\u0103ng, C\u00e1c m\u1eabu song song (Parallel Patterns), v\u00e0 \u1ee8ng d\u1ee5ng n\u00e2ng cao (AI/ML).</p>"},{"location":"cuda/pmpp/#vi-phase1","title":"Giai \u0111o\u1ea1n 1: N\u1ec1n t\u1ea3ng c\u1ee7a T\u00ednh to\u00e1n GPU","text":"<ol> <li>Gi\u1edbi thi\u1ec7u v\u1ec1 T\u00ednh to\u00e1n kh\u00f4ng \u0111\u1ed3ng nh\u1ea5t: T\u1ea1i sao c\u1ea7n t\u00ednh to\u00e1n song song? S\u1ef1 chuy\u1ec3n d\u1ecbch t\u1eeb \"t\u0103ng xung nh\u1ecbp\" sang \"t\u0103ng s\u1ed1 l\u00f5i\".</li> <li>M\u00f4 h\u00ecnh l\u1eadp tr\u00ecnh CUDA: Kernel, grid, block, v\u00e0 thread. Ch\u01b0\u01a1ng tr\u00ecnh \"C\u1ed9ng vector\" \u0111\u1ea7u ti\u00ean.</li> <li>M\u00f4 h\u00ecnh th\u1ef1c thi song song d\u1eef li\u1ec7u: Hi\u1ec3u v\u1ec1 ki\u1ebfn tr\u00fac SIMT (Single Instruction, Multiple Threads) v\u00e0 \u0111a lu\u1ed3ng ph\u1ea7n c\u1ee9ng.</li> <li>H\u1ec7 th\u1ed1ng ph\u00e2n c\u1ea5p b\u1ed9 nh\u1edb GPU: B\u1ed9 nh\u1edb global, constant, v\u00e0 shared; register v\u00e0 cache.</li> </ol>"},{"location":"cuda/pmpp/#vi-phase2","title":"Giai \u0111o\u1ea1n 2: Hi\u1ec7u n\u0103ng v\u00e0 Ki\u1ebfn tr\u00fac ph\u1ea7n c\u1ee9ng","text":"<ol> <li>C\u00e1c c\u00e2n nh\u1eafc v\u1ec1 hi\u1ec7u n\u0103ng: Ph\u00e2n k\u1ef3 lu\u1ed3ng (thread divergence), g\u1ed9p b\u1ed9 nh\u1edb (memory coalescing), v\u00e0 che gi\u1ea5u \u0111\u1ed9 tr\u1ec5.</li> <li>Kh\u1ea3 n\u0103ng t\u00ednh to\u00e1n v\u00e0 \u0110\u1ed9 l\u1ea5p \u0111\u1ea7y (Occupancy): C\u00e1ch c\u00e2n b\u1eb1ng t\u00e0i nguy\u00ean \u0111\u1ec3 GPU lu\u00f4n ho\u1ea1t \u0111\u1ed9ng h\u1ebft c\u00f4ng su\u1ea5t.</li> <li>\u0110\u1ed9 ch\u00ednh x\u00e1c s\u1ed1 th\u1ef1c: Hi\u1ec3u v\u1ec1 FP32, FP16, BF16 v\u00e0 t\u00ednh \u1ed5n \u0111\u1ecbnh s\u1ed1 h\u1ecdc.</li> </ol>"},{"location":"cuda/pmpp/#vi-phase3","title":"Giai \u0111o\u1ea1n 3: C\u00e1c m\u1eabu song song c\u01a1 b\u1ea3n","text":"<ol> <li>T\u00edch ch\u1eadp (Convolution): Tri\u1ec3n khai c\u00e1c b\u1ed9 l\u1ecdc 1D v\u00e0 2D.</li> <li>Prefix Sum (Scan): Gi\u1ea3i quy\u1ebft c\u00e1c b\u00e0i to\u00e1n c\u00f3 v\u1ebb tu\u1ea7n t\u1ef1.</li> <li>Reduction (Gom nh\u00f3m): T\u00ednh t\u1ed5ng ho\u1eb7c t\u00ecm max/min m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3.</li> <li>Stencil Computation: C\u1eadp nh\u1eadt d\u1ef1a tr\u00ean l\u01b0\u1edbi (d\u00f9ng trong m\u00f4 ph\u1ecfng th\u1eddi ti\u1ebft).</li> <li>Histogramming (Bi\u1ec3u \u0111\u1ed3 t\u1ea7n su\u1ea5t): X\u1eed l\u00fd c\u00e1c thao t\u00e1c \"atomic\" v\u00e0 tranh ch\u1ea5p b\u1ed9 nh\u1edb.</li> <li>Nh\u00e2n ma tr\u1eadn th\u01b0a (SpMV): X\u1eed l\u00fd d\u1eef li\u1ec7u c\u00f3 nhi\u1ec1u gi\u00e1 tr\u1ecb b\u1eb1ng kh\u00f4ng.</li> <li>Merge Sort: Tri\u1ec3n khai s\u1eafp x\u1ebfp hi\u1ec7u n\u0103ng cao tr\u00ean GPU.</li> </ol>"},{"location":"cuda/pmpp/#vi-phase4","title":"Giai \u0111o\u1ea1n 4: Ch\u1ee7 \u0111\u1ec1 n\u00e2ng cao v\u00e0 AI hi\u1ec7n \u0111\u1ea1i","text":"<ol> <li>Deep Learning v\u00e0 Tensor Cores: (M\u1edbi \u1edf b\u1ea3n 4) C\u00e1ch GPU t\u0103ng t\u1ed1c Transformer v\u00e0 CNN.</li> <li>X\u1eed l\u00fd \u0111\u1ed3 th\u1ecb: \u0110i\u1ec1u h\u01b0\u1edbng c\u00e1c c\u1ea5u tr\u00fac d\u1eef li\u1ec7u kh\u00f4ng \u0111\u1ec1u.</li> <li>Dynamic Parallelism: Kernel kh\u1edfi t\u1ea1o kernel kh\u00e1c.</li> <li>L\u1eadp tr\u00ecnh Multi-GPU: S\u1eed d\u1ee5ng NVLink v\u00e0 MPI.</li> </ol>"},{"location":"cuda/pmpp/#vi-unique","title":"T\u1ea1i sao cu\u1ed1n s\u00e1ch n\u00e0y \u0111\u1eb7c bi\u1ec7t?","text":"<p>\u1ea4n b\u1ea3n th\u1ee9 4 l\u00e0 m\u1ed9t kh\u00f3a h\u1ecdc chuy\u00ean s\u00e2u v\u1ec1 \"T\u01b0 duy song song\".</p> <ol> <li>Ph\u01b0\u01a1ng ph\u00e1p d\u1ea1y d\u1ef1a tr\u00ean m\u1eabu (Pattern-Based): T\u1eadp trung v\u00e0o \"C\u00e1c m\u1eabu thu\u1eadt to\u00e1n\" nh\u01b0 Reduction, Scan, T\u00edch ch\u1eadp thay v\u00ec ch\u1ec9 d\u1ea1y c\u00fa ph\u00e1p.</li> <li>K\u1ebft n\u1ed1i Ph\u1ea7n m\u1ec1m v\u00e0 Ph\u1ea7n c\u1ee9ng: Gi\u1ea3i th\u00edch t\u1ea1i sao code ch\u1ea1y ch\u1eadm th\u00f4ng qua c\u00e1c gi\u1edbi h\u1ea1n ph\u1ea7n c\u1ee9ng (b\u0103ng th\u00f4ng, warp scheduling).</li> <li>T\u1eadp trung v\u00e0o AI hi\u1ec7n \u0111\u1ea1i: N\u1ed9i dung m\u1edbi v\u1ec1 Tensor Cores v\u00e0 \u0110\u1ed9 ch\u00ednh x\u00e1c h\u1ed7n h\u1ee3p (FP16/INT8).</li> </ol>"},{"location":"cuda/pmpp/#vi-path-beyond","title":"Con \u0111\u01b0\u1eddng ph\u00eda tr\u01b0\u1edbc","text":"<p>B\u1ea1n \u0111\u00e3 s\u1eb5n s\u00e0ng bi\u1ebfn ki\u1ebfn th\u1ee9c n\u00e0y th\u00e0nh s\u1ef1 nghi\u1ec7p? H\u00e3y xem L\u1ed9 tr\u00ecnh K\u1ef9 s\u01b0 GPU \u0111\u1ec3 bi\u1ebft c\u00e1c l\u1eddi khuy\u00ean v\u1ec1 d\u1ef1 \u00e1n, danh m\u1ee5c h\u1ed3 s\u01a1 v\u00e0 ph\u1ecfng v\u1ea5n.</p>"},{"location":"cuda/pmpp/appendix-a/","title":"Appendix A: Numerical Considerations","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This section is critical for engineers working in scientific computing, finance, and AI, as it explains why \"the order of operations\" matters and how floating-point math can lead to subtle errors in parallel code.</p> <p>Ph\u1ea7n n\u00e0y r\u1ea5t quan tr\u1ecdng \u0111\u1ed1i v\u1edbi c\u00e1c k\u1ef9 s\u01b0 l\u00e0m vi\u1ec7c trong l\u0129nh v\u1ef1c t\u00ednh to\u00e1n khoa h\u1ecdc, t\u00e0i ch\u00ednh v\u00e0 AI, v\u00ec n\u00f3 gi\u1ea3i th\u00edch t\u1ea1i sao \"th\u1ee9 t\u1ef1 c\u00e1c ph\u00e9p to\u00e1n\" l\u1ea1i quan tr\u1ecdng v\u00e0 c\u00e1ch to\u00e1n h\u1ecdc d\u1ea5u ph\u1ea9y \u0111\u1ed9ng (floating-point) c\u00f3 th\u1ec3 d\u1eabn \u0111\u1ebfn c\u00e1c sai s\u1ed1 tinh vi trong m\u00e3 song song.</p>"},{"location":"cuda/pmpp/appendix-a/#en-representation","title":"A.1 Floating-point Data Representation","text":"<ul> <li>The IEEE-754 Standard: Explains the universal standard for representing real numbers in binary.</li> <li> <p>Bit Patterns: A floating-point number is divided into three groups:</p> <ol> <li>Sign (S): 0 for positive, 1 for negative.</li> <li>Exponent (E): Determines the range of the number.</li> <li>Mantissa (M): Determines the precision.</li> </ol> </li> <li> <p>Normalized Representation: In IEEE format, numbers are adjusted so the first bit is always \"1\" (e.g., \\(1.M\\)). This \"hidden bit\" saves space and increases precision.</p> </li> <li>Excess Encoding: The exponent uses a \"bias\" (Excess-N) so that even negative exponents are represented as positive integers. This allows the hardware to compare the size of two numbers using simple, fast integer logic.</li> </ul>"},{"location":"cuda/pmpp/appendix-a/#en-representable","title":"A.2 Representable Numbers","text":"<ul> <li>The Number Line: Numbers are not spread evenly across the line. They are denser near zero and get further apart as they get larger.</li> <li>Precision vs. Range: More bits in the mantissa increase precision (closeness to the real value); more bits in the exponent increase range (how big or small the number can be).</li> <li> <p>The Underflow Problem:</p> <ul> <li>Abrupt Underflow: An old method where very small numbers are simply \"flushed\" to zero. This creates a large gap around zero where the algorithm becomes unstable.</li> <li>Denormalization: The modern solution. It allows the \"hidden bit\" to be 0 for extremely tiny numbers, ensuring they \"fade to zero\" gracefully. Modern GPUs (Pascal and later) handle these in hardware with no speed penalty.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/appendix-a/#en-special","title":"A.3 Special Bit Patterns","text":"<ul> <li>Infinity (\\(\\infty\\)): Generated when a number exceeds the maximum range (Overflow) or when dividing by zero.</li> <li> <p>NaN (Not a Number): Generated by mathematically undefined operations (e.g., \\(0/0\\) or \\(\\infty - \\infty\\)).</p> <ul> <li>Signaling NaN: Triggers an immediate error/exception (not supported by current GPUs during massive parallel execution).</li> <li>Quiet NaN: Propagates through the calculation, allowing the programmer to see that something went wrong at the end without crashing the whole system.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/appendix-a/#en-accuracy","title":"A.4 Arithmetic Accuracy and Rounding","text":"<ul> <li>Rounding Error: Most decimal numbers (like 0.1) cannot be represented exactly in binary.</li> <li>ULP (Unit in the Last Place): The smallest possible difference between two representable numbers. A perfectly designed hardware unit should have an error of no more than 0.5 ULP.</li> <li>GPU Fast Math: CUDA offers \"Intrinsic\" functions (like <code>__sin()</code>) that are faster because they use specialized hardware (SFUs) but may have a higher ULP error than standard library functions.</li> </ul>"},{"location":"cuda/pmpp/appendix-a/#en-algorithm","title":"A.5 Algorithm Considerations","text":"<ul> <li>The Associativity Trap: In pure math, \\((a + b) + c = a + (b + c)\\). In floating-point math, this is false.</li> <li> <p>Parallel Summation: In a reduction tree (Chapter 10), the order of addition changes compared to a serial CPU loop.</p> <ul> <li>The Danger: If you add a tiny number to a very large number, the tiny number is \"lost\" because it falls below the precision of the large number.</li> <li>The Fix: Parallel reduction trees are actually often more accurate than serial loops because they combine numbers of similar sizes first, preserving more precision.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/appendix-a/#en-solvers","title":"A.6 Linear Solvers and Numerical Stability","text":"<ul> <li>Gaussian Elimination: Illustrates how an algorithm can be \"mathematically correct\" but \"numerically unstable.\"</li> <li>Pivoting: A technique to swap rows in a matrix to avoid dividing by very small numbers, which would blow up the error.</li> <li>Communication-Avoiding Algorithms: Explains the trade-off in modern clusters\u2014sometimes it is better to accept slightly less numerical accuracy to avoid the massive time delay of \"pivoting\" across multiple nodes in a cluster.</li> </ul> <p>Key Takeaway for the Appendix: It warns that Parallelism changes the math. Because floating-point addition is not associative, your GPU result may differ slightly from your CPU result. For high-stakes engineering, you must understand ULP and Denormalization to ensure your massive speedup doesn't come at the cost of \"garbage\" results.</p>"},{"location":"cuda/pmpp/appendix-a/#vi-representation","title":"A.1 Bi\u1ec3u di\u1ec5n d\u1eef li\u1ec7u d\u1ea5u ph\u1ea9y \u0111\u1ed9ng","text":"<ul> <li>Ti\u00eau chu\u1ea9n IEEE-754: Gi\u1ea3i th\u00edch ti\u00eau chu\u1ea9n ph\u1ed5 qu\u00e1t \u0111\u1ec3 bi\u1ec3u di\u1ec5n c\u00e1c s\u1ed1 th\u1ef1c trong h\u1ec7 nh\u1ecb ph\u00e2n.</li> <li> <p>C\u00e1c m\u1eabu bit: M\u1ed9t s\u1ed1 d\u1ea5u ph\u1ea9y \u0111\u1ed9ng \u0111\u01b0\u1ee3c chia th\u00e0nh ba nh\u00f3m:</p> <ol> <li>Sign (S - D\u1ea5u): 0 cho s\u1ed1 d\u01b0\u01a1ng, 1 cho s\u1ed1 \u00e2m.</li> <li>Exponent (E - S\u1ed1 m\u0169): X\u00e1c \u0111\u1ecbnh ph\u1ea1m vi c\u1ee7a s\u1ed1.</li> <li>Mantissa (M - Ph\u1ea7n \u0111\u1ecbnh tr\u1ecb): X\u00e1c \u0111\u1ecbnh \u0111\u1ed9 ch\u00ednh x\u00e1c.</li> </ol> </li> <li> <p>Bi\u1ec3u di\u1ec5n chu\u1ea9n h\u00f3a: Trong \u0111\u1ecbnh d\u1ea1ng IEEE, c\u00e1c s\u1ed1 \u0111\u01b0\u1ee3c \u0111i\u1ec1u ch\u1ec9nh sao cho bit \u0111\u1ea7u ti\u00ean lu\u00f4n l\u00e0 \"1\" (v\u00ed d\u1ee5: \\(1.M\\)). \"Bit \u1ea9n\" n\u00e0y gi\u00fap ti\u1ebft ki\u1ec7m kh\u00f4ng gian v\u00e0 t\u0103ng \u0111\u1ed9 ch\u00ednh x\u00e1c.</p> </li> <li>M\u00e3 h\u00f3a d\u01b0 (Excess Encoding): S\u1ed1 m\u0169 s\u1eed d\u1ee5ng m\u1ed9t \"\u0111\u1ed9 l\u1ec7ch\" (bias - Excess-N) \u0111\u1ec3 ngay c\u1ea3 c\u00e1c s\u1ed1 m\u0169 \u00e2m c\u0169ng \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n th\u00e0nh c\u00e1c s\u1ed1 nguy\u00ean d\u01b0\u01a1ng. \u0110i\u1ec1u n\u00e0y cho ph\u00e9p ph\u1ea7n c\u1ee9ng so s\u00e1nh k\u00edch th\u01b0\u1edbc c\u1ee7a hai s\u1ed1 b\u1eb1ng logic s\u1ed1 nguy\u00ean \u0111\u01a1n gi\u1ea3n v\u00e0 nhanh ch\u00f3ng.</li> </ul>"},{"location":"cuda/pmpp/appendix-a/#vi-representable","title":"A.2 C\u00e1c s\u1ed1 c\u00f3 th\u1ec3 bi\u1ec3u di\u1ec5n","text":"<ul> <li>\u0110\u01b0\u1eddng s\u1ed1: C\u00e1c s\u1ed1 kh\u00f4ng \u0111\u01b0\u1ee3c r\u1ea3i \u0111\u1ec1u tr\u00ean \u0111\u01b0\u1eddng s\u1ed1. Ch\u00fang d\u00e0y \u0111\u1eb7c h\u01a1n \u1edf g\u1ea7n s\u1ed1 kh\u00f4ng v\u00e0 c\u00e1ch xa nhau h\u01a1n khi gi\u00e1 tr\u1ecb l\u1edbn d\u1ea7n.</li> <li>\u0110\u1ed9 ch\u00ednh x\u00e1c vs. Ph\u1ea1m vi: Nhi\u1ec1u bit h\u01a1n trong ph\u1ea7n \u0111\u1ecbnh tr\u1ecb gi\u00fap t\u0103ng \u0111\u1ed9 ch\u00ednh x\u00e1c (m\u1ee9c \u0111\u1ed9 g\u1ea7n v\u1edbi gi\u00e1 tr\u1ecb th\u1ef1c); nhi\u1ec1u bit h\u01a1n trong s\u1ed1 m\u0169 gi\u00fap t\u0103ng ph\u1ea1m vi (s\u1ed1 c\u00f3 th\u1ec3 l\u1edbn ho\u1eb7c nh\u1ecf \u0111\u1ebfn m\u1ee9c n\u00e0o).</li> <li> <p>V\u1ea5n \u0111\u1ec1 Underflow (Tr\u00e0n d\u01b0\u1edbi):</p> <ul> <li>Abrupt Underflow: M\u1ed9t ph\u01b0\u01a1ng ph\u00e1p c\u0169 trong \u0111\u00f3 c\u00e1c s\u1ed1 c\u1ef1c nh\u1ecf \u0111\u01b0\u1ee3c \"\u00e9p\" tr\u1ef1c ti\u1ebfp v\u1ec1 kh\u00f4ng. \u0110i\u1ec1u n\u00e0y t\u1ea1o ra m\u1ed9t kho\u1ea3ng tr\u1ed1ng l\u1edbn xung quanh s\u1ed1 kh\u00f4ng, n\u01a1i thu\u1eadt to\u00e1n tr\u1edf n\u00ean kh\u00f4ng \u1ed5n \u0111\u1ecbnh.</li> <li>Denormalization (Phi chu\u1ea9n h\u00f3a): Gi\u1ea3i ph\u00e1p hi\u1ec7n \u0111\u1ea1i. N\u00f3 cho ph\u00e9p \"bit \u1ea9n\" b\u1eb1ng 0 \u0111\u1ed1i v\u1edbi c\u00e1c s\u1ed1 c\u1ef1c nh\u1ecf, \u0111\u1ea3m b\u1ea3o ch\u00fang \"m\u1edd d\u1ea7n v\u1ec1 kh\u00f4ng\" m\u1ed9t c\u00e1ch m\u01b0\u1ee3t m\u00e0. C\u00e1c GPU hi\u1ec7n \u0111\u1ea1i (Pascal tr\u1edf v\u1ec1 sau) x\u1eed l\u00fd vi\u1ec7c n\u00e0y b\u1eb1ng ph\u1ea7n c\u1ee9ng m\u00e0 kh\u00f4ng l\u00e0m gi\u1ea3m t\u1ed1c \u0111\u1ed9.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/appendix-a/#vi-special","title":"A.3 C\u00e1c m\u1eabu bit \u0111\u1eb7c bi\u1ec7t","text":"<ul> <li>V\u00f4 c\u00f9ng (\\(\\infty\\)): \u0110\u01b0\u1ee3c t\u1ea1o ra khi m\u1ed9t s\u1ed1 v\u01b0\u1ee3t qu\u00e1 ph\u1ea1m vi t\u1ed1i \u0111a (Tr\u00e0n tr\u00ean - Overflow) ho\u1eb7c khi chia cho kh\u00f4ng.</li> <li> <p>NaN (Not a Number - Kh\u00f4ng ph\u1ea3i l\u00e0 m\u1ed9t s\u1ed1): \u0110\u01b0\u1ee3c t\u1ea1o ra b\u1edfi c\u00e1c ph\u00e9p to\u00e1n kh\u00f4ng x\u00e1c \u0111\u1ecbnh v\u1ec1 m\u1eb7t to\u00e1n h\u1ecdc (v\u00ed d\u1ee5: \\(0/0\\) ho\u1eb7c \\(\\infty - \\infty\\)).</p> <ul> <li>Signaling NaN: K\u00edch ho\u1ea1t m\u1ed9t l\u1ed7i/ngo\u1ea1i l\u1ec7 ngay l\u1eadp t\u1ee9c (kh\u00f4ng \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3 b\u1edfi c\u00e1c GPU hi\u1ec7n t\u1ea1i trong qu\u00e1 tr\u00ecnh th\u1ef1c thi song song kh\u1ed5ng l\u1ed3).</li> <li>Quiet NaN: \u0110\u01b0\u1ee3c truy\u1ec1n \u0111i trong su\u1ed1t qu\u00e1 tr\u00ecnh t\u00ednh to\u00e1n, cho ph\u00e9p l\u1eadp tr\u00ecnh vi\u00ean th\u1ea5y r\u1eb1ng c\u00f3 g\u00ec \u0111\u00f3 kh\u00f4ng \u1ed5n \u1edf k\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng m\u00e0 kh\u00f4ng l\u00e0m s\u1eadp to\u00e0n b\u1ed9 h\u1ec7 th\u1ed1ng.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/appendix-a/#vi-accuracy","title":"A.4 \u0110\u1ed9 ch\u00ednh x\u00e1c s\u1ed1 h\u1ecdc v\u00e0 L\u00e0m tr\u00f2n","text":"<ul> <li>Sai s\u1ed1 l\u00e0m tr\u00f2n: H\u1ea7u h\u1ebft c\u00e1c s\u1ed1 th\u1eadp ph\u00e2n (nh\u01b0 0.1) kh\u00f4ng th\u1ec3 \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n ch\u00ednh x\u00e1c trong h\u1ec7 nh\u1ecb ph\u00e2n.</li> <li>ULP (Unit in the Last Place): S\u1ef1 kh\u00e1c bi\u1ec7t nh\u1ecf nh\u1ea5t c\u00f3 th\u1ec3 c\u00f3 gi\u1eefa hai s\u1ed1 c\u00f3 th\u1ec3 bi\u1ec3u di\u1ec5n. M\u1ed9t \u0111\u01a1n v\u1ecb ph\u1ea7n c\u1ee9ng \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf ho\u00e0n h\u1ea3o ph\u1ea3i c\u00f3 sai s\u1ed1 kh\u00f4ng qu\u00e1 0.5 ULP.</li> <li>GPU Fast Math: CUDA cung c\u1ea5p c\u00e1c h\u00e0m \"N\u1ed9i t\u1ea1i\" (nh\u01b0 <code>__sin()</code>) nhanh h\u01a1n v\u00ec ch\u00fang s\u1eed d\u1ee5ng ph\u1ea7n c\u1ee9ng chuy\u00ean d\u1ee5ng (SFU) nh\u01b0ng c\u00f3 th\u1ec3 c\u00f3 sai s\u1ed1 ULP cao h\u01a1n c\u00e1c h\u00e0m th\u01b0 vi\u1ec7n ti\u00eau chu\u1ea9n.</li> </ul>"},{"location":"cuda/pmpp/appendix-a/#vi-algorithm","title":"A.5 Xem x\u00e9t v\u1ec1 Thu\u1eadt to\u00e1n","text":"<ul> <li>B\u1eaby t\u00ednh k\u1ebft h\u1ee3p: Trong to\u00e1n h\u1ecdc thu\u1ea7n t\u00fay, \\((a + b) + c = a + (b + c)\\). Trong to\u00e1n h\u1ecdc d\u1ea5u ph\u1ea9y \u0111\u1ed9ng, \u0111i\u1ec1u n\u00e0y l\u00e0 sai.</li> <li> <p>Ph\u00e9p c\u1ed9ng song song: Trong m\u1ed9t c\u00e2y reduction (Ch\u01b0\u01a1ng 10), th\u1ee9 t\u1ef1 c\u1ee7a ph\u00e9p c\u1ed9ng thay \u0111\u1ed5i so v\u1edbi m\u1ed9t v\u00f2ng l\u1eb7p tu\u1ea7n t\u1ef1 c\u1ee7a CPU.</p> <ul> <li>M\u1ed1i nguy hi\u1ec3m: N\u1ebfu b\u1ea1n c\u1ed9ng m\u1ed9t s\u1ed1 c\u1ef1c nh\u1ecf v\u00e0o m\u1ed9t s\u1ed1 c\u1ef1c l\u1edbn, s\u1ed1 nh\u1ecf s\u1ebd b\u1ecb \"m\u1ea5t\" v\u00ec n\u00f3 n\u1eb1m d\u01b0\u1edbi gi\u1edbi h\u1ea1n \u0111\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a s\u1ed1 l\u1edbn.</li> <li>Gi\u1ea3i ph\u00e1p: C\u00e1c c\u00e2y reduction song song tr\u00ean th\u1ef1c t\u1ebf th\u01b0\u1eddng ch\u00ednh x\u00e1c h\u01a1n c\u00e1c v\u00f2ng l\u1eb7p tu\u1ea7n t\u1ef1 v\u00ec ch\u00fang k\u1ebft h\u1ee3p c\u00e1c s\u1ed1 c\u00f3 k\u00edch th\u01b0\u1edbc t\u01b0\u01a1ng t\u1ef1 nhau tr\u01b0\u1edbc, gi\u00fap gi\u1eef l\u1ea1i nhi\u1ec1u \u0111\u1ed9 ch\u00ednh x\u00e1c h\u01a1n.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/appendix-a/#vi-solvers","title":"A.6 C\u00e1c b\u1ed9 gi\u1ea3i tuy\u1ebfn t\u00ednh v\u00e0 \u0110\u1ed9 \u1ed5n \u0111\u1ecbnh s\u1ed1 h\u1ecdc","text":"<ul> <li>Kh\u1eed Gauss: Minh h\u1ecda c\u00e1ch m\u1ed9t thu\u1eadt to\u00e1n c\u00f3 th\u1ec3 \"\u0111\u00fang v\u1ec1 m\u1eb7t to\u00e1n h\u1ecdc\" nh\u01b0ng \"kh\u00f4ng \u1ed5n \u0111\u1ecbnh v\u1ec1 m\u1eb7t s\u1ed1 h\u1ecdc\".</li> <li>Xoay v\u00f2ng (Pivoting): M\u1ed9t k\u1ef9 thu\u1eadt \u0111\u1ec3 tr\u00e1o \u0111\u1ed5i c\u00e1c h\u00e0ng trong ma tr\u1eadn nh\u1eb1m tr\u00e1nh vi\u1ec7c chia cho c\u00e1c s\u1ed1 c\u1ef1c nh\u1ecf, v\u1ed1n s\u1ebd l\u00e0m sai s\u1ed1 b\u00f9ng ph\u00e1t.</li> <li>Thu\u1eadt to\u00e1n tr\u00e1nh truy\u1ec1n th\u00f4ng (Communication-Avoiding Algorithms): Gi\u1ea3i th\u00edch s\u1ef1 \u0111\u00e1nh \u0111\u1ed5i trong c\u00e1c c\u1ee5m m\u00e1y t\u00ednh hi\u1ec7n \u0111\u1ea1i\u2014\u0111\u00f4i khi ch\u1ea5p nh\u1eadn \u0111\u1ed9 ch\u00ednh x\u00e1c s\u1ed1 h\u1ecdc th\u1ea5p h\u01a1n m\u1ed9t ch\u00fat \u0111\u1ec3 tr\u00e1nh s\u1ef1 ch\u1eadm tr\u1ec5 kh\u1ed5ng l\u1ed3 c\u1ee7a vi\u1ec7c \"xoay v\u00f2ng\" tr\u00ean nhi\u1ec1u n\u00fat trong m\u1ed9t c\u1ee5m.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh cho Ph\u1ee5 l\u1ee5c: N\u00f3 c\u1ea3nh b\u00e1o r\u1eb1ng T\u00ednh song song l\u00e0m thay \u0111\u1ed5i to\u00e1n h\u1ecdc. B\u1edfi v\u00ec ph\u00e9p c\u1ed9ng d\u1ea5u ph\u1ea9y \u0111\u1ed9ng kh\u00f4ng c\u00f3 t\u00ednh k\u1ebft h\u1ee3p, k\u1ebft qu\u1ea3 GPU c\u1ee7a b\u1ea1n c\u00f3 th\u1ec3 kh\u00e1c m\u1ed9t ch\u00fat so v\u1edbi k\u1ebft qu\u1ea3 CPU. \u0110\u1ed1i v\u1edbi c\u00e1c d\u1ef1 \u00e1n k\u1ef9 thu\u1eadt quan tr\u1ecdng, b\u1ea1n ph\u1ea3i hi\u1ec3u v\u1ec1 ULP v\u00e0 Denormalization \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o vi\u1ec7c t\u0103ng t\u1ed1c kh\u1ed5ng l\u1ed3 kh\u00f4ng ph\u1ea3i tr\u1ea3 gi\u00e1 b\u1eb1ng c\u00e1c k\u1ebft qu\u1ea3 \"r\u00e1c\".</p>"},{"location":"cuda/pmpp/chapter-01/","title":"Chapter 1: Introduction","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter sets the stage for the book by explaining the shift in the computing industry from sequential to parallel processing.</p> <p>Ch\u01b0\u01a1ng n\u00e0y \u0111\u1eb7t n\u1ec1n m\u00f3ng cho cu\u1ed1n s\u00e1ch b\u1eb1ng c\u00e1ch gi\u1ea3i th\u00edch s\u1ef1 chuy\u1ec3n d\u1ecbch trong ng\u00e0nh c\u00f4ng nghi\u1ec7p m\u00e1y t\u00ednh t\u1eeb x\u1eed l\u00fd tu\u1ea7n t\u1ef1 sang x\u1eed l\u00fd song song.</p>"},{"location":"cuda/pmpp/chapter-01/#en-heterogeneous","title":"1.1 Heterogeneous Parallel Computing","text":"<p>The Shift (2003): Before 2003, performance increased by raising clock frequencies. Due to energy and heat limits, the industry shifted to two main trajectories:</p> <ul> <li>Multicore Trajectory: (CPUs like Intel/AMD) Focuses on latency-oriented design. They use large caches and sophisticated branch prediction to make a single sequence of instructions (a thread) run as fast as possible.</li> <li>Many-thread Trajectory: (GPUs like NVIDIA A100) Focuses on throughput-oriented design. They use thousands of smaller, simpler cores to execute massive numbers of threads simultaneously.</li> </ul> <p>Performance Gap: In 2021, a high-end GPU (A100) offered significantly higher peak floating-point throughput (TFLOPS) compared to a high-end CPU, particularly in single and half-precision (essential for AI).</p> <p>The CUDA Model: Introduced in 2007, it moved away from the \"GPGPU\" era (where programmers had to \"trick\" the GPU by treating data as pixels) to a general-purpose programming model where the CPU (host) and GPU (device) work together.</p>"},{"location":"cuda/pmpp/chapter-01/#en-why-speed","title":"1.2 Why More Speed or Parallelism?","text":"<p>Superapplications: The need for speed is driven by \"superapplications\" in science and consumer tech:</p> <ul> <li>Molecular Biology: Simulating interactions between billions of atoms.</li> <li>Video/Imaging: Real-time view synthesis for high-definition TV and better smartphone interfaces.</li> <li>Gaming &amp; Digital Twins: Moving from pre-rendered scenes to dynamic simulations and \"digital twins\" for stress-testing physical objects.</li> </ul>"},{"location":"cuda/pmpp/chapter-01/#en-speedup","title":"1.3 Speeding Up Real Applications","text":"<p>Defining Speedup: The ratio of time taken on System B (serial) vs. System A (parallel).</p> <p>Amdahl's Law: A critical concept stating that the total speedup of an application is limited by its sequential portion.</p> <ul> <li>Example: If only 30% of a program is parallelized, even an infinite speedup of that part only results in a 1.43x total improvement.</li> <li>To get a 100x speedup, more than 99.9% of the work must be parallelized.</li> </ul> <p>The \"Peach\" Analogy: Real-world applications are like a peach. The \"pit\" is the sequential part (hard to bite into/parallelize), while the \"flesh\" is the parallel part (large and easy to process).</p> <p>Memory Bandwidth: Simply running threads isn't enough; memory (DRAM) speed often becomes the bottleneck (Memory-bound). The book focuses on using on-chip memory to bypass these limits.</p>"},{"location":"cuda/pmpp/chapter-01/#en-challenges","title":"1.4 Challenges in Parallel Programming","text":"<ul> <li>Algorithmic Complexity: Some parallel algorithms do more total work than sequential ones; if the data isn't large enough, they can be slower.</li> <li>Data Characteristics: Performance can vary based on whether data is \"regular\" or \"erratic\" (leading to load imbalance).</li> <li>Synchronization: Coordination between threads (barriers or atomics) adds overhead.</li> <li>The Goal: The book aims to teach \"Parallel Patterns\" that solve these common challenges across different domains.</li> </ul>"},{"location":"cuda/pmpp/chapter-01/#en-interfaces","title":"1.5 Related Parallel Programming Interfaces","text":"<ul> <li>OpenMP: A high-level, directive-based model for multicore CPUs. It is easier to use but offers less explicit control than CUDA.</li> <li>MPI (Message Passing Interface): The standard for cluster computing (multiple nodes that don't share memory). CUDA is often used within a node, while MPI handles communication between nodes.</li> <li>OpenCL: A cross-vendor standard similar to CUDA. Skills learned in CUDA are directly transferable to OpenCL.</li> </ul>"},{"location":"cuda/pmpp/chapter-01/#en-goals","title":"1.6 Overarching Goals","text":"<ul> <li>Computational Thinking: Learning to formulate problems in a way that is amenable to massive parallelism.</li> <li>Scalability: Writing code that scales naturally as GPUs get more cores in the future.</li> <li>Reliability: Ensuring code is not just fast, but functionally correct and debuggable.</li> </ul>"},{"location":"cuda/pmpp/chapter-01/#en-organization","title":"1.7 Organization of the Book","text":"<p>The chapter concludes with a roadmap of the book's four parts:</p> <ol> <li>Foundations: CUDA basics and architecture.</li> <li>Parallel Patterns: Fundamental algorithms (Convolution, Stencil, Reduction, etc.).</li> <li>Advanced Patterns: Complex applications like Deep Learning and Graph Traversal.</li> <li>Advanced Practices: Clusters, Dynamic Parallelism, and the future.</li> </ol> <p>Summary: Chapter 1 transitions the reader from \"thinking sequentially\" to \"thinking in throughput,\" emphasizing that the most important skill in modern computing is the ability to manage thousands of threads and the memory traffic they generate.</p>"},{"location":"cuda/pmpp/chapter-01/#vi-heterogeneous","title":"1.1 T\u00ednh to\u00e1n song song kh\u00f4ng \u0111\u1ed3ng nh\u1ea5t","text":"<p>S\u1ef1 chuy\u1ec3n d\u1ecbch (2003): Tr\u01b0\u1edbc n\u0103m 2003, hi\u1ec7u n\u0103ng t\u0103ng b\u1eb1ng c\u00e1ch t\u0103ng t\u1ea7n s\u1ed1 xung nh\u1ecbp. Do gi\u1edbi h\u1ea1n v\u1ec1 n\u0103ng l\u01b0\u1ee3ng v\u00e0 nhi\u1ec7t, ng\u00e0nh c\u00f4ng nghi\u1ec7p chuy\u1ec3n sang hai h\u01b0\u1edbng ch\u00ednh:</p> <ul> <li>H\u01b0\u1edbng \u0111a l\u00f5i: (CPU nh\u01b0 Intel/AMD) T\u1eadp trung v\u00e0o thi\u1ebft k\u1ebf h\u01b0\u1edbng \u0111\u1ed9 tr\u1ec5. S\u1eed d\u1ee5ng cache l\u1edbn v\u00e0 d\u1ef1 \u0111o\u00e1n nh\u00e1nh tinh vi \u0111\u1ec3 l\u00e0m cho m\u1ed9t chu\u1ed7i l\u1ec7nh \u0111\u01a1n (m\u1ed9t lu\u1ed3ng) ch\u1ea1y nhanh nh\u1ea5t c\u00f3 th\u1ec3.</li> <li>H\u01b0\u1edbng \u0111a lu\u1ed3ng: (GPU nh\u01b0 NVIDIA A100) T\u1eadp trung v\u00e0o thi\u1ebft k\u1ebf h\u01b0\u1edbng th\u00f4ng l\u01b0\u1ee3ng. S\u1eed d\u1ee5ng h\u00e0ng ngh\u00ecn l\u00f5i nh\u1ecf h\u01a1n, \u0111\u01a1n gi\u1ea3n h\u01a1n \u0111\u1ec3 th\u1ef1c thi s\u1ed1 l\u01b0\u1ee3ng l\u1edbn lu\u1ed3ng \u0111\u1ed3ng th\u1eddi.</li> </ul> <p>Kho\u1ea3ng c\u00e1ch hi\u1ec7u n\u0103ng: N\u0103m 2021, GPU cao c\u1ea5p (A100) cung c\u1ea5p th\u00f4ng l\u01b0\u1ee3ng t\u00ednh to\u00e1n d\u1ea5u ph\u1ea9y \u0111\u1ed9ng \u0111\u1ec9nh (TFLOPS) cao h\u01a1n \u0111\u00e1ng k\u1ec3 so v\u1edbi CPU cao c\u1ea5p, \u0111\u1eb7c bi\u1ec7t \u1edf \u0111\u1ed9 ch\u00ednh x\u00e1c \u0111\u01a1n v\u00e0 n\u1eeda (quan tr\u1ecdng cho AI).</p> <p>M\u00f4 h\u00ecnh CUDA: \u0110\u01b0\u1ee3c gi\u1edbi thi\u1ec7u n\u0103m 2007, chuy\u1ec3n t\u1eeb k\u1ef7 nguy\u00ean \"GPGPU\" (l\u1eadp tr\u00ecnh vi\u00ean ph\u1ea3i \"l\u1eeba\" GPU b\u1eb1ng c\u00e1ch coi d\u1eef li\u1ec7u nh\u01b0 pixel) sang m\u00f4 h\u00ecnh l\u1eadp tr\u00ecnh \u0111a m\u1ee5c \u0111\u00edch n\u01a1i CPU (host) v\u00e0 GPU (device) l\u00e0m vi\u1ec7c c\u00f9ng nhau.</p>"},{"location":"cuda/pmpp/chapter-01/#vi-why-speed","title":"1.2 T\u1ea1i sao c\u1ea7n t\u1ed1c \u0111\u1ed9 ho\u1eb7c t\u00ednh song song cao h\u01a1n?","text":"<p>Si\u00eau \u1ee9ng d\u1ee5ng: Nhu c\u1ea7u v\u1ec1 t\u1ed1c \u0111\u1ed9 \u0111\u01b0\u1ee3c th\u00fac \u0111\u1ea9y b\u1edfi \"si\u00eau \u1ee9ng d\u1ee5ng\" trong khoa h\u1ecdc v\u00e0 c\u00f4ng ngh\u1ec7 ti\u00eau d\u00f9ng:</p> <ul> <li>Sinh h\u1ecdc ph\u00e2n t\u1eed: M\u00f4 ph\u1ecfng t\u01b0\u01a1ng t\u00e1c gi\u1eefa h\u00e0ng t\u1ef7 nguy\u00ean t\u1eed.</li> <li>Video/H\u00ecnh \u1ea3nh: T\u1ed5ng h\u1ee3p khung h\u00ecnh th\u1eddi gian th\u1ef1c cho TV \u0111\u1ed9 n\u00e9t cao v\u00e0 giao di\u1ec7n smartphone t\u1ed1t h\u01a1n.</li> <li>Game &amp; B\u1ea3n sao s\u1ed1: Chuy\u1ec3n t\u1eeb c\u1ea3nh \u0111\u01b0\u1ee3c render tr\u01b0\u1edbc sang m\u00f4 ph\u1ecfng \u0111\u1ed9ng v\u00e0 \"b\u1ea3n sao s\u1ed1\" \u0111\u1ec3 ki\u1ec3m tra \u0111\u1ed9 b\u1ec1n c\u1ee7a v\u1eadt th\u1ec3 v\u1eadt l\u00fd.</li> </ul>"},{"location":"cuda/pmpp/chapter-01/#vi-speedup","title":"1.3 T\u0103ng t\u1ed1c \u1ee9ng d\u1ee5ng th\u1ef1c t\u1ebf","text":"<p>\u0110\u1ecbnh ngh\u0129a Speedup: T\u1ef7 l\u1ec7 th\u1eddi gian th\u1ef1c thi tr\u00ean H\u1ec7 th\u1ed1ng B (tu\u1ea7n t\u1ef1) so v\u1edbi H\u1ec7 th\u1ed1ng A (song song).</p> <p>\u0110\u1ecbnh lu\u1eadt Amdahl: Kh\u00e1i ni\u1ec7m quan tr\u1ecdng cho r\u1eb1ng t\u1ed5ng t\u1ed1c \u0111\u1ed9 t\u0103ng c\u1ee7a \u1ee9ng d\u1ee5ng b\u1ecb gi\u1edbi h\u1ea1n b\u1edfi ph\u1ea7n tu\u1ea7n t\u1ef1 c\u1ee7a n\u00f3.</p> <ul> <li>V\u00ed d\u1ee5: N\u1ebfu ch\u1ec9 30% ch\u01b0\u01a1ng tr\u00ecnh \u0111\u01b0\u1ee3c song song h\u00f3a, ngay c\u1ea3 khi ph\u1ea7n \u0111\u00f3 t\u0103ng t\u1ed1c v\u00f4 h\u1ea1n c\u0169ng ch\u1ec9 d\u1eabn \u0111\u1ebfn c\u1ea3i thi\u1ec7n t\u1ed5ng th\u1ec3 1.43 l\u1ea7n.</li> <li>\u0110\u1ec3 \u0111\u1ea1t t\u1ed1c \u0111\u1ed9 t\u0103ng 100 l\u1ea7n, h\u01a1n 99.9% c\u00f4ng vi\u1ec7c ph\u1ea3i \u0111\u01b0\u1ee3c song song h\u00f3a.</li> </ul> <p>Ph\u00e9p \u1ea9n d\u1ee5 \"Qu\u1ea3 \u0111\u00e0o\": \u1ee8ng d\u1ee5ng th\u1ef1c t\u1ebf gi\u1ed1ng nh\u01b0 qu\u1ea3 \u0111\u00e0o. \"H\u1ea1t\" l\u00e0 ph\u1ea7n tu\u1ea7n t\u1ef1 (kh\u00f3 song song h\u00f3a), trong khi \"th\u1ecbt\" l\u00e0 ph\u1ea7n song song (l\u1edbn v\u00e0 d\u1ec5 x\u1eed l\u00fd).</p> <p>B\u0103ng th\u00f4ng b\u1ed9 nh\u1edb: Ch\u1ec9 ch\u1ea1y nhi\u1ec1u lu\u1ed3ng l\u00e0 ch\u01b0a \u0111\u1ee7; t\u1ed1c \u0111\u1ed9 b\u1ed9 nh\u1edb (DRAM) th\u01b0\u1eddng tr\u1edf th\u00e0nh n\u00fat th\u1eaft c\u1ed5 chai (Memory-bound). Cu\u1ed1n s\u00e1ch t\u1eadp trung v\u00e0o vi\u1ec7c s\u1eed d\u1ee5ng b\u1ed9 nh\u1edb tr\u00ean chip \u0111\u1ec3 v\u01b0\u1ee3t qua gi\u1edbi h\u1ea1n n\u00e0y.</p>"},{"location":"cuda/pmpp/chapter-01/#vi-challenges","title":"1.4 Th\u00e1ch th\u1ee9c trong l\u1eadp tr\u00ecnh song song","text":"<ul> <li>\u0110\u1ed9 ph\u1ee9c t\u1ea1p thu\u1eadt to\u00e1n: M\u1ed9t s\u1ed1 thu\u1eadt to\u00e1n song song th\u1ef1c hi\u1ec7n nhi\u1ec1u c\u00f4ng vi\u1ec7c h\u01a1n so v\u1edbi phi\u00ean b\u1ea3n tu\u1ea7n t\u1ef1; n\u1ebfu d\u1eef li\u1ec7u kh\u00f4ng \u0111\u1ee7 l\u1edbn, ch\u00fang c\u00f3 th\u1ec3 ch\u1eadm h\u01a1n.</li> <li>\u0110\u1eb7c t\u00ednh d\u1eef li\u1ec7u: Hi\u1ec7u n\u0103ng c\u00f3 th\u1ec3 thay \u0111\u1ed5i t\u00f9y thu\u1ed9c v\u00e0o d\u1eef li\u1ec7u \"\u0111\u1ec1u \u0111\u1eb7n\" hay \"b\u1ea5t th\u01b0\u1eddng\" (d\u1eabn \u0111\u1ebfn m\u1ea5t c\u00e2n b\u1eb1ng t\u1ea3i).</li> <li>\u0110\u1ed3ng b\u1ed9 h\u00f3a: \u0110i\u1ec1u ph\u1ed1i gi\u1eefa c\u00e1c lu\u1ed3ng (barrier ho\u1eb7c atomic) t\u1ea1o ra chi ph\u00ed qu\u1ea3n l\u00fd.</li> <li>M\u1ee5c ti\u00eau: Cu\u1ed1n s\u00e1ch h\u01b0\u1edbng \u0111\u1ebfn vi\u1ec7c d\u1ea1y \"C\u00e1c m\u1eabu song song\" gi\u1ea3i quy\u1ebft nh\u1eefng th\u00e1ch th\u1ee9c ph\u1ed5 bi\u1ebfn n\u00e0y trong nhi\u1ec1u l\u0129nh v\u1ef1c kh\u00e1c nhau.</li> </ul>"},{"location":"cuda/pmpp/chapter-01/#vi-interfaces","title":"1.5 C\u00e1c giao di\u1ec7n l\u1eadp tr\u00ecnh song song li\u00ean quan","text":"<ul> <li>OpenMP: M\u00f4 h\u00ecnh c\u1ea5p cao, d\u1ef1a tr\u00ean ch\u1ec9 th\u1ecb cho CPU \u0111a l\u00f5i. D\u1ec5 s\u1eed d\u1ee5ng h\u01a1n nh\u01b0ng ki\u1ec3m so\u00e1t \u00edt r\u00f5 r\u00e0ng h\u01a1n CUDA.</li> <li>MPI (Message Passing Interface): Ti\u00eau chu\u1ea9n cho t\u00ednh to\u00e1n c\u1ee5m (nhi\u1ec1u node kh\u00f4ng chia s\u1ebb b\u1ed9 nh\u1edb). CUDA th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong m\u1ed9t node, trong khi MPI x\u1eed l\u00fd giao ti\u1ebfp gi\u1eefa c\u00e1c node.</li> <li>OpenCL: Ti\u00eau chu\u1ea9n \u0111a nh\u00e0 cung c\u1ea5p t\u01b0\u01a1ng t\u1ef1 CUDA. K\u1ef9 n\u0103ng h\u1ecdc \u0111\u01b0\u1ee3c t\u1eeb CUDA c\u00f3 th\u1ec3 chuy\u1ec3n \u0111\u1ed5i tr\u1ef1c ti\u1ebfp sang OpenCL.</li> </ul>"},{"location":"cuda/pmpp/chapter-01/#vi-goals","title":"1.6 M\u1ee5c ti\u00eau t\u1ed5ng qu\u00e1t","text":"<ul> <li>T\u01b0 duy t\u00ednh to\u00e1n: H\u1ecdc c\u00e1ch x\u00e2y d\u1ef1ng b\u00e0i to\u00e1n theo c\u00e1ch ph\u00f9 h\u1ee3p v\u1edbi t\u00ednh song song l\u1edbn.</li> <li>Kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng: Vi\u1ebft code m\u1edf r\u1ed9ng t\u1ef1 nhi\u00ean khi GPU c\u00f3 th\u00eam l\u00f5i trong t\u01b0\u01a1ng lai.</li> <li>\u0110\u1ed9 tin c\u1eady: \u0110\u1ea3m b\u1ea3o code kh\u00f4ng ch\u1ec9 nhanh m\u00e0 c\u00f2n \u0111\u00fang v\u1ec1 m\u1eb7t ch\u1ee9c n\u0103ng v\u00e0 c\u00f3 th\u1ec3 debug \u0111\u01b0\u1ee3c.</li> </ul>"},{"location":"cuda/pmpp/chapter-01/#vi-organization","title":"1.7 C\u1ea5u tr\u00fac cu\u1ed1n s\u00e1ch","text":"<p>Ch\u01b0\u01a1ng k\u1ebft th\u00fac v\u1edbi l\u1ed9 tr\u00ecnh b\u1ed1n ph\u1ea7n c\u1ee7a cu\u1ed1n s\u00e1ch:</p> <ol> <li>N\u1ec1n t\u1ea3ng: C\u01a1 b\u1ea3n CUDA v\u00e0 ki\u1ebfn tr\u00fac.</li> <li>C\u00e1c m\u1eabu song song: Thu\u1eadt to\u00e1n c\u01a1 b\u1ea3n (Convolution, Stencil, Reduction, v.v.).</li> <li>C\u00e1c m\u1eabu n\u00e2ng cao: \u1ee8ng d\u1ee5ng ph\u1ee9c t\u1ea1p nh\u01b0 Deep Learning v\u00e0 Graph Traversal.</li> <li>Th\u1ef1c h\u00e0nh n\u00e2ng cao: C\u1ee5m, Dynamic Parallelism v\u00e0 t\u01b0\u01a1ng lai.</li> </ol> <p>T\u00f3m t\u1eaft: Ch\u01b0\u01a1ng 1 chuy\u1ec3n \u0111\u1ed5i ng\u01b0\u1eddi \u0111\u1ecdc t\u1eeb \"t\u01b0 duy tu\u1ea7n t\u1ef1\" sang \"t\u01b0 duy th\u00f4ng l\u01b0\u1ee3ng,\" nh\u1ea5n m\u1ea1nh r\u1eb1ng k\u1ef9 n\u0103ng quan tr\u1ecdng nh\u1ea5t trong t\u00ednh to\u00e1n hi\u1ec7n \u0111\u1ea1i l\u00e0 kh\u1ea3 n\u0103ng qu\u1ea3n l\u00fd h\u00e0ng ngh\u00ecn lu\u1ed3ng v\u00e0 l\u01b0u l\u01b0\u1ee3ng b\u1ed9 nh\u1edb m\u00e0 ch\u00fang t\u1ea1o ra.</p>"},{"location":"cuda/pmpp/chapter-02/","title":"Chapter 2: Heterogeneous Data Parallel Computing","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter introduces the fundamental concepts of data parallelism and the basic structure of a CUDA C program using a simple \"Vector Addition\" example.</p> <p>Ch\u01b0\u01a1ng n\u00e0y gi\u1edbi thi\u1ec7u c\u00e1c kh\u00e1i ni\u1ec7m c\u01a1 b\u1ea3n v\u1ec1 t\u00ednh song song d\u1eef li\u1ec7u v\u00e0 c\u1ea5u tr\u00fac c\u01a1 b\u1ea3n c\u1ee7a ch\u01b0\u01a1ng tr\u00ecnh CUDA C s\u1eed d\u1ee5ng v\u00ed d\u1ee5 \u0111\u01a1n gi\u1ea3n \"C\u1ed9ng Vector\".</p>"},{"location":"cuda/pmpp/chapter-02/#en-data-parallelism","title":"2.1 Data Parallelism","text":"<p>Definition: A programming phenomenon where computation is performed independently on different parts of a dataset.</p> <p>Scalability: Data parallelism is the primary source of scalability in parallel programs; as datasets grow, more threads can be used to handle the work.</p> <p>Illustrative Example: Color-to-Grayscale Conversion</p> <ul> <li>Each pixel in a color image \\((r, g, b)\\) is converted to a luminance value \\((L)\\) using the formula:      $\\(L = r \\times 0.21 + g \\times 0.72 + b \\times 0.07\\)$</li> <li>Since the conversion of one pixel does not depend on any other pixel, this task is highly data-parallel.</li> </ul> <p>Task Parallelism vs. Data Parallelism: While task parallelism involves doing different functions at the same time, data parallelism focuses on doing the same function on many data elements simultaneously.</p>"},{"location":"cuda/pmpp/chapter-02/#en-structure","title":"2.2 CUDA C Program Structure","text":"<p>Heterogeneous Computing: A CUDA C program consists of a Host (CPU) and one or more Devices (GPUs).</p> <p>Kernels: These are functions that are executed on the device in a data-parallel manner.</p> <p>Execution Flow: The program starts on the host. When a kernel is called, a large number of threads (a Grid) are launched on the device to execute the kernel. Once the grid finishes, control returns to the host.</p>"},{"location":"cuda/pmpp/chapter-02/#en-vector-add","title":"2.3 A Vector Addition Kernel","text":"<p>The Baseline: In sequential C, vector addition uses a <code>for</code> loop to iterate through every element.</p> <p>The GPU Approach: In CUDA, the <code>for</code> loop is replaced by a grid of threads. Each thread is responsible for adding exactly one pair of elements.</p> <p>Naming Conventions: To avoid confusion, the book uses the suffix <code>_h</code> for variables residing in host memory and <code>_d</code> for those in device memory.</p>"},{"location":"cuda/pmpp/chapter-02/#en-memory","title":"2.4 Device Global Memory and Data Transfer","text":"<p>Global Memory: The GPU has its own high-capacity DRAM (e.g., 16GB\u201380GB). The host cannot directly access this memory using standard pointers; specialized API functions are required.</p> <p>Key API Functions:</p> <ul> <li><code>cudaMalloc()</code>: Allocates a piece of memory in the device global memory. It is modeled after the standard C <code>malloc()</code>.</li> <li><code>cudaFree()</code>: Frees allocated memory on the device.</li> <li><code>cudaMemcpy()</code>: Transfers data between host and device. It requires a \"direction\" parameter, such as <code>cudaMemcpyHostToDevice</code> or <code>cudaMemcpyDeviceToHost</code>.</li> </ul>"},{"location":"cuda/pmpp/chapter-02/#en-threading","title":"2.5 Kernel Functions and Threading","text":"<p>Function Declarations:</p> <ul> <li><code>__global__</code>: Marks a function as a kernel. It is called from the host and executed on the device. It must return <code>void</code>.</li> <li><code>__device__</code>: A function called and executed only on the device.</li> <li><code>__host__</code>: A traditional C function (the default).</li> </ul> <p>Built-in Variables (Identifying Threads):</p> <ul> <li><code>threadIdx</code>: The unique coordinate of a thread within its block.</li> <li><code>blockIdx</code>: The coordinate of a block within the grid.</li> <li><code>blockDim</code>: The number of threads in each block.</li> </ul> <p>Index Calculation: To map a thread to a specific array element, threads calculate a unique global index:</p> <pre><code>int i = blockIdx.x * blockDim.x + threadIdx.x;\n</code></pre> <p>Automatic Variables: Variables declared inside a kernel are private to each thread (stored in registers).</p>"},{"location":"cuda/pmpp/chapter-02/#en-calling","title":"2.6 Calling Kernel Functions","text":"<p>Execution Configuration: Kernels are launched using the <code>&lt;&lt;&lt;...&gt;&gt;&gt;</code> syntax.</p> <ul> <li>First Parameter: Number of blocks in the grid.</li> <li>Second Parameter: Number of threads per block.</li> </ul> <p>Ceiling Division: To ensure every data element is covered, the number of blocks is often calculated using a ceiling function: <code>ceil(n / 256.0)</code>.</p> <p>Boundary Checks: Because the number of threads launched is often a multiple of the block size, kernels must include an <code>if (i &lt; n)</code> check to prevent threads from accessing memory outside the array bounds.</p>"},{"location":"cuda/pmpp/chapter-02/#en-compilation","title":"2.7 Compilation","text":"<p>NVCC: The NVIDIA C Compiler. It separates the source file into host code (processed by standard compilers like <code>gcc</code> or <code>cl.exe</code>) and device code (compiled into PTX or binary object files for the GPU).</p>"},{"location":"cuda/pmpp/chapter-02/#en-keywords","title":"2.8 Summary of Keywords","text":"<ul> <li>Memory: <code>cudaMalloc</code>, <code>cudaFree</code>, <code>cudaMemcpy</code>.</li> <li>Declaration: <code>__global__</code>, <code>__device__</code>, <code>__host__</code>.</li> <li>Hierarchy: Grid \\(\\rightarrow\\) Block \\(\\rightarrow\\) Thread.</li> </ul> <p>Key Takeaway: Chapter 2 shifts the programmer's focus from writing loops to defining a single thread's behavior and using a hierarchy of indices to map those threads to massive amounts of data.</p>"},{"location":"cuda/pmpp/chapter-02/#vi-data-parallelism","title":"2.1 T\u00ednh song song d\u1eef li\u1ec7u","text":"<p>\u0110\u1ecbnh ngh\u0129a: Hi\u1ec7n t\u01b0\u1ee3ng l\u1eadp tr\u00ecnh trong \u0111\u00f3 t\u00ednh to\u00e1n \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n \u0111\u1ed9c l\u1eadp tr\u00ean c\u00e1c ph\u1ea7n kh\u00e1c nhau c\u1ee7a t\u1eadp d\u1eef li\u1ec7u.</p> <p>Kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng: T\u00ednh song song d\u1eef li\u1ec7u l\u00e0 ngu\u1ed3n ch\u00ednh c\u1ee7a kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng trong c\u00e1c ch\u01b0\u01a1ng tr\u00ecnh song song; khi t\u1eadp d\u1eef li\u1ec7u t\u0103ng l\u00ean, c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng nhi\u1ec1u lu\u1ed3ng h\u01a1n \u0111\u1ec3 x\u1eed l\u00fd c\u00f4ng vi\u1ec7c.</p> <p>V\u00ed d\u1ee5 minh h\u1ecda: Chuy\u1ec3n \u0111\u1ed5i m\u00e0u sang x\u00e1m</p> <ul> <li>M\u1ed7i pixel trong \u1ea3nh m\u00e0u \\((r, g, b)\\) \u0111\u01b0\u1ee3c chuy\u1ec3n \u0111\u1ed5i th\u00e0nh gi\u00e1 tr\u1ecb \u0111\u1ed9 s\u00e1ng \\((L)\\) b\u1eb1ng c\u00f4ng th\u1ee9c:     $\\(L = r \\times 0.21 + g \\times 0.72 + b \\times 0.07\\)$</li> <li>V\u00ec vi\u1ec7c chuy\u1ec3n \u0111\u1ed5i m\u1ed9t pixel kh\u00f4ng ph\u1ee5 thu\u1ed9c v\u00e0o b\u1ea5t k\u1ef3 pixel n\u00e0o kh\u00e1c, t\u00e1c v\u1ee5 n\u00e0y c\u00f3 t\u00ednh song song d\u1eef li\u1ec7u cao.</li> </ul> <p>T\u00ednh song song t\u00e1c v\u1ee5 vs. T\u00ednh song song d\u1eef li\u1ec7u: Trong khi t\u00ednh song song t\u00e1c v\u1ee5 li\u00ean quan \u0111\u1ebfn vi\u1ec7c th\u1ef1c hi\u1ec7n c\u00e1c h\u00e0m kh\u00e1c nhau c\u00f9ng l\u00fac, t\u00ednh song song d\u1eef li\u1ec7u t\u1eadp trung v\u00e0o vi\u1ec7c th\u1ef1c hi\u1ec7n c\u00f9ng m\u1ed9t h\u00e0m tr\u00ean nhi\u1ec1u ph\u1ea7n t\u1eed d\u1eef li\u1ec7u \u0111\u1ed3ng th\u1eddi.</p>"},{"location":"cuda/pmpp/chapter-02/#vi-structure","title":"2.2 C\u1ea5u tr\u00fac ch\u01b0\u01a1ng tr\u00ecnh CUDA C","text":"<p>T\u00ednh to\u00e1n kh\u00f4ng \u0111\u1ed3ng nh\u1ea5t: Ch\u01b0\u01a1ng tr\u00ecnh CUDA C bao g\u1ed3m Host (CPU) v\u00e0 m\u1ed9t ho\u1eb7c nhi\u1ec1u Device (GPU).</p> <p>Kernel: \u0110\u00e2y l\u00e0 c\u00e1c h\u00e0m \u0111\u01b0\u1ee3c th\u1ef1c thi tr\u00ean device theo c\u00e1ch song song d\u1eef li\u1ec7u.</p> <p>Lu\u1ed3ng th\u1ef1c thi: Ch\u01b0\u01a1ng tr\u00ecnh b\u1eaft \u0111\u1ea7u tr\u00ean host. Khi kernel \u0111\u01b0\u1ee3c g\u1ecdi, m\u1ed9t s\u1ed1 l\u01b0\u1ee3ng l\u1edbn lu\u1ed3ng (m\u1ed9t Grid) \u0111\u01b0\u1ee3c kh\u1edfi ch\u1ea1y tr\u00ean device \u0111\u1ec3 th\u1ef1c thi kernel. Khi grid k\u1ebft th\u00fac, \u0111i\u1ec1u khi\u1ec3n quay l\u1ea1i host.</p>"},{"location":"cuda/pmpp/chapter-02/#vi-vector-add","title":"2.3 Kernel c\u1ed9ng vector","text":"<p>C\u01a1 s\u1edf: Trong C tu\u1ea7n t\u1ef1, ph\u00e9p c\u1ed9ng vector s\u1eed d\u1ee5ng v\u00f2ng l\u1eb7p <code>for</code> \u0111\u1ec3 l\u1eb7p qua m\u1ecdi ph\u1ea7n t\u1eed.</p> <p>C\u00e1ch ti\u1ebfp c\u1eadn GPU: Trong CUDA, v\u00f2ng l\u1eb7p <code>for</code> \u0111\u01b0\u1ee3c thay th\u1ebf b\u1eb1ng l\u01b0\u1edbi c\u00e1c lu\u1ed3ng. M\u1ed7i lu\u1ed3ng ch\u1ecbu tr\u00e1ch nhi\u1ec7m c\u1ed9ng ch\u00ednh x\u00e1c m\u1ed9t c\u1eb7p ph\u1ea7n t\u1eed.</p> <p>Quy \u01b0\u1edbc \u0111\u1eb7t t\u00ean: \u0110\u1ec3 tr\u00e1nh nh\u1ea7m l\u1eabn, cu\u1ed1n s\u00e1ch s\u1eed d\u1ee5ng h\u1eadu t\u1ed1 <code>_h</code> cho c\u00e1c bi\u1ebfn n\u1eb1m trong b\u1ed9 nh\u1edb host v\u00e0 <code>_d</code> cho c\u00e1c bi\u1ebfn trong b\u1ed9 nh\u1edb device.</p>"},{"location":"cuda/pmpp/chapter-02/#vi-memory","title":"2.4 B\u1ed9 nh\u1edb Global c\u1ee7a Device v\u00e0 Truy\u1ec1n d\u1eef li\u1ec7u","text":"<p>B\u1ed9 nh\u1edb Global: GPU c\u00f3 DRAM dung l\u01b0\u1ee3ng cao ri\u00eang (v\u00ed d\u1ee5: 16GB\u201380GB). Host kh\u00f4ng th\u1ec3 truy c\u1eadp tr\u1ef1c ti\u1ebfp b\u1ed9 nh\u1edb n\u00e0y b\u1eb1ng con tr\u1ecf ti\u00eau chu\u1ea9n; c\u1ea7n c\u00e1c h\u00e0m API chuy\u00ean bi\u1ec7t.</p> <p>C\u00e1c h\u00e0m API ch\u00ednh:</p> <ul> <li><code>cudaMalloc()</code>: C\u1ea5p ph\u00e1t m\u1ed9t ph\u1ea7n b\u1ed9 nh\u1edb trong b\u1ed9 nh\u1edb global c\u1ee7a device. \u0110\u01b0\u1ee3c m\u00f4 h\u00ecnh h\u00f3a theo <code>malloc()</code> ti\u00eau chu\u1ea9n c\u1ee7a C.</li> <li><code>cudaFree()</code>: Gi\u1ea3i ph\u00f3ng b\u1ed9 nh\u1edb \u0111\u00e3 c\u1ea5p ph\u00e1t tr\u00ean device.</li> <li><code>cudaMemcpy()</code>: Truy\u1ec1n d\u1eef li\u1ec7u gi\u1eefa host v\u00e0 device. Y\u00eau c\u1ea7u tham s\u1ed1 \"h\u01b0\u1edbng\", ch\u1eb3ng h\u1ea1n nh\u01b0 <code>cudaMemcpyHostToDevice</code> ho\u1eb7c <code>cudaMemcpyDeviceToHost</code>.</li> </ul>"},{"location":"cuda/pmpp/chapter-02/#vi-threading","title":"2.5 H\u00e0m Kernel v\u00e0 Lu\u1ed3ng","text":"<p>Khai b\u00e1o h\u00e0m:</p> <ul> <li><code>__global__</code>: \u0110\u00e1nh d\u1ea5u h\u00e0m l\u00e0 kernel. \u0110\u01b0\u1ee3c g\u1ecdi t\u1eeb host v\u00e0 th\u1ef1c thi tr\u00ean device. Ph\u1ea3i tr\u1ea3 v\u1ec1 <code>void</code>.</li> <li><code>__device__</code>: H\u00e0m \u0111\u01b0\u1ee3c g\u1ecdi v\u00e0 th\u1ef1c thi ch\u1ec9 tr\u00ean device.</li> <li><code>__host__</code>: H\u00e0m C truy\u1ec1n th\u1ed1ng (m\u1eb7c \u0111\u1ecbnh).</li> </ul> <p>Bi\u1ebfn d\u1ef1ng s\u1eb5n (X\u00e1c \u0111\u1ecbnh lu\u1ed3ng):</p> <ul> <li><code>threadIdx</code>: T\u1ecda \u0111\u1ed9 duy nh\u1ea5t c\u1ee7a lu\u1ed3ng trong block c\u1ee7a n\u00f3.</li> <li><code>blockIdx</code>: T\u1ecda \u0111\u1ed9 c\u1ee7a block trong grid.</li> <li><code>blockDim</code>: S\u1ed1 l\u01b0\u1ee3ng lu\u1ed3ng trong m\u1ed7i block.</li> </ul> <p>T\u00ednh to\u00e1n ch\u1ec9 s\u1ed1: \u0110\u1ec3 \u00e1nh x\u1ea1 lu\u1ed3ng \u0111\u1ebfn ph\u1ea7n t\u1eed m\u1ea3ng c\u1ee5 th\u1ec3, c\u00e1c lu\u1ed3ng t\u00ednh to\u00e1n ch\u1ec9 s\u1ed1 to\u00e0n c\u1ee5c duy nh\u1ea5t:</p> <pre><code>int i = blockIdx.x * blockDim.x + threadIdx.x;\n</code></pre> <p>Bi\u1ebfn t\u1ef1 \u0111\u1ed9ng: C\u00e1c bi\u1ebfn \u0111\u01b0\u1ee3c khai b\u00e1o b\u00ean trong kernel l\u00e0 ri\u00eang t\u01b0 cho m\u1ed7i lu\u1ed3ng (l\u01b0u tr\u1eef trong register).</p>"},{"location":"cuda/pmpp/chapter-02/#vi-calling","title":"2.6 G\u1ecdi h\u00e0m Kernel","text":"<p>C\u1ea5u h\u00ecnh th\u1ef1c thi: Kernel \u0111\u01b0\u1ee3c kh\u1edfi ch\u1ea1y b\u1eb1ng c\u00fa ph\u00e1p <code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>.</p> <ul> <li>Tham s\u1ed1 \u0111\u1ea7u ti\u00ean: S\u1ed1 l\u01b0\u1ee3ng block trong grid.</li> <li>Tham s\u1ed1 th\u1ee9 hai: S\u1ed1 l\u01b0\u1ee3ng lu\u1ed3ng tr\u00ean m\u1ed7i block.</li> </ul> <p>Ph\u00e9p chia l\u00e0m tr\u00f2n l\u00ean: \u0110\u1ec3 \u0111\u1ea3m b\u1ea3o m\u1ecdi ph\u1ea7n t\u1eed d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c bao ph\u1ee7, s\u1ed1 l\u01b0\u1ee3ng block th\u01b0\u1eddng \u0111\u01b0\u1ee3c t\u00ednh b\u1eb1ng h\u00e0m l\u00e0m tr\u00f2n l\u00ean: <code>ceil(n / 256.0)</code>.</p> <p>Ki\u1ec3m tra bi\u00ean: V\u00ec s\u1ed1 l\u01b0\u1ee3ng lu\u1ed3ng \u0111\u01b0\u1ee3c kh\u1edfi ch\u1ea1y th\u01b0\u1eddng l\u00e0 b\u1ed9i s\u1ed1 c\u1ee7a k\u00edch th\u01b0\u1edbc block, kernel ph\u1ea3i bao g\u1ed3m ki\u1ec3m tra <code>if (i &lt; n)</code> \u0111\u1ec3 ng\u0103n c\u00e1c lu\u1ed3ng truy c\u1eadp b\u1ed9 nh\u1edb ngo\u00e0i gi\u1edbi h\u1ea1n m\u1ea3ng.</p>"},{"location":"cuda/pmpp/chapter-02/#vi-compilation","title":"2.7 Bi\u00ean d\u1ecbch","text":"<p>NVCC: Tr\u00ecnh bi\u00ean d\u1ecbch NVIDIA C. N\u00f3 t\u00e1ch file ngu\u1ed3n th\u00e0nh code host (\u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi tr\u00ecnh bi\u00ean d\u1ecbch ti\u00eau chu\u1ea9n nh\u01b0 <code>gcc</code> ho\u1eb7c <code>cl.exe</code>) v\u00e0 code device (\u0111\u01b0\u1ee3c bi\u00ean d\u1ecbch th\u00e0nh PTX ho\u1eb7c file \u0111\u1ed1i t\u01b0\u1ee3ng nh\u1ecb ph\u00e2n cho GPU).</p>"},{"location":"cuda/pmpp/chapter-02/#vi-keywords","title":"2.8 T\u00f3m t\u1eaft t\u1eeb kh\u00f3a","text":"<ul> <li>B\u1ed9 nh\u1edb: <code>cudaMalloc</code>, <code>cudaFree</code>, <code>cudaMemcpy</code>.</li> <li>Khai b\u00e1o: <code>__global__</code>, <code>__device__</code>, <code>__host__</code>.</li> <li>Ph\u00e2n c\u1ea5p: Grid \\(\\rightarrow\\) Block \\(\\rightarrow\\) Thread.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 2 chuy\u1ec3n tr\u1ecdng t\u00e2m c\u1ee7a l\u1eadp tr\u00ecnh vi\u00ean t\u1eeb vi\u1ebft v\u00f2ng l\u1eb7p sang \u0111\u1ecbnh ngh\u0129a h\u00e0nh vi c\u1ee7a m\u1ed9t lu\u1ed3ng \u0111\u01a1n l\u1ebb v\u00e0 s\u1eed d\u1ee5ng h\u1ec7 ph\u00e2n c\u1ea5p ch\u1ec9 s\u1ed1 \u0111\u1ec3 \u00e1nh x\u1ea1 c\u00e1c lu\u1ed3ng \u0111\u00f3 \u0111\u1ebfn l\u01b0\u1ee3ng d\u1eef li\u1ec7u l\u1edbn.</p>"},{"location":"cuda/pmpp/chapter-03/","title":"Chapter 3: Multidimensional Grids and Data","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter expands on the CUDA programming model by moving from simple 1D vectors to multidimensional data structures (2D images and matrices) and explaining how threads are organized to process them.</p> <p>Ch\u01b0\u01a1ng n\u00e0y m\u1edf r\u1ed9ng m\u00f4 h\u00ecnh l\u1eadp tr\u00ecnh CUDA b\u1eb1ng c\u00e1ch chuy\u1ec3n t\u1eeb vector 1D \u0111\u01a1n gi\u1ea3n sang c\u1ea5u tr\u00fac d\u1eef li\u1ec7u \u0111a chi\u1ec1u (\u1ea3nh 2D v\u00e0 ma tr\u1eadn) v\u00e0 gi\u1ea3i th\u00edch c\u00e1ch t\u1ed5 ch\u1ee9c lu\u1ed3ng \u0111\u1ec3 x\u1eed l\u00fd ch\u00fang.</p>"},{"location":"cuda/pmpp/chapter-03/#en-grid-org","title":"3.1 Multidimensional Grid Organization","text":"<p>Grid and Block Hierarchy: Threads are organized into a two-level hierarchy (Grid \\(\\rightarrow\\) Block). Both can be defined in 1D, 2D, or 3D.</p> <p>Key Built-in Variables:</p> <ul> <li><code>gridDim</code>: The dimensions of the grid (number of blocks).</li> <li><code>blockDim</code>: The dimensions of each block (number of threads).</li> <li><code>blockIdx</code>: The coordinates of a block within the grid.</li> <li><code>threadIdx</code>: The coordinates of a thread within its block.</li> </ul> <p>Dimensionality Limits: While threads can be 3D, the total number of threads in a single block cannot exceed 1024.</p> <p>Type <code>dim3</code>: CUDA uses a special integer vector type <code>dim3</code> to specify these dimensions. For example:</p> <pre><code>dim3 grid(32, 1, 1);\ndim3 block(128, 1, 1);\n</code></pre>"},{"location":"cuda/pmpp/chapter-03/#en-mapping","title":"3.2 Mapping Threads to Multidimensional Data","text":"<p>Concept: To process a 2D image, it is most intuitive to use a 2D grid of 2D blocks.</p> <p>Mapping Formula (2D): To find the specific row and column a thread should work on:</p> <pre><code>row = blockIdx.y * blockDim.y + threadIdx.y;\ncol = blockIdx.x * blockDim.x + threadIdx.x;\n</code></pre> <p>Memory Linearization (Row-Major Order):</p> <ul> <li>In C and CUDA, multidimensional arrays are stored in a \"flat\" 1D memory space.</li> <li>Row-Major Layout: Elements of a row are placed in consecutive locations.</li> <li>The Formula: To access a 2D element at <code>(row, col)</code> in a 1D array of a certain <code>Width</code>:     <pre><code>index = row * Width + col;\n</code></pre></li> </ul> <p>Boundary Checks: If the data size (e.g., a 62x76 image) is not a perfect multiple of the block size (e.g., 16x16), some threads will be \"out of bounds.\" The kernel must use <code>if</code> statements to ensure these threads do not access invalid memory.</p>"},{"location":"cuda/pmpp/chapter-03/#en-blur","title":"3.3 Image Blur: A More Complex Kernel","text":"<p>Beyond Independence: Unlike vector addition where each thread is totally isolated, image blurring requires a thread to access its neighbors.</p> <p>The Process: A blurred pixel is the average value of an \\(N \\times N\\) patch of pixels surrounding the target.</p> <p>Inner Loops: The kernel uses nested <code>for</code> loops to iterate through the neighborhood patch.</p> <p>Ghost Cells/Edges: The kernel includes logic to handle pixels at the edge of the image where a full \\(N \\times N\\) patch doesn't exist (using 0 or the nearest pixel as a filler).</p>"},{"location":"cuda/pmpp/chapter-03/#en-matmul","title":"3.4 Matrix Multiplication","text":"<p>The Pattern: This is a core application of multidimensional mapping.</p> <p>Algorithm: To compute one element of the resulting matrix \\(P\\), a thread must perform a dot product of a row from matrix \\(M\\) and a column from matrix \\(N\\).</p> <p>Kernel Structure:</p> <ul> <li>Each thread is assigned to one element of the output matrix \\(P\\).</li> <li>The thread uses a loop to multiply and sum elements:     <pre><code>Pvalue += M[row * Width + k] * N[k * Width + col];\n</code></pre></li> </ul> <p>Efficiency Warning: The book notes that this \"simple\" matrix multiplication is limited by global memory bandwidth (it is \"memory-bound\"). This sets the stage for the optimization techniques (like tiling) introduced in later chapters.</p>"},{"location":"cuda/pmpp/chapter-03/#en-summary","title":"3.5 Summary of Skills","text":"<ul> <li>Understanding how to use <code>blockIdx</code> and <code>threadIdx</code> in 2D/3D.</li> <li>Mapping multidimensional data to the \"flat\" row-major memory of the GPU.</li> <li>Implementing kernels where threads must iterate over data subsets (like patches or matrix rows).</li> </ul> <p>Key Takeaway: Chapter 3 teaches the \"arithmetic of mapping.\" The most critical skill here is learning how to calculate a 1D memory index from 2D or 3D thread coordinates so that thousands of threads can navigate complex data structures without crashing or overlapping.</p>"},{"location":"cuda/pmpp/chapter-03/#vi-grid-org","title":"3.1 T\u1ed5 ch\u1ee9c Grid \u0111a chi\u1ec1u","text":"<p>Ph\u00e2n c\u1ea5p Grid v\u00e0 Block: C\u00e1c lu\u1ed3ng \u0111\u01b0\u1ee3c t\u1ed5 ch\u1ee9c th\u00e0nh ph\u00e2n c\u1ea5p hai c\u1ea5p (Grid \\(\\rightarrow\\) Block). C\u1ea3 hai c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a trong 1D, 2D, ho\u1eb7c 3D.</p> <p>C\u00e1c bi\u1ebfn d\u1ef1ng s\u1eb5n ch\u00ednh:</p> <ul> <li><code>gridDim</code>: K\u00edch th\u01b0\u1edbc c\u1ee7a grid (s\u1ed1 l\u01b0\u1ee3ng block).</li> <li><code>blockDim</code>: K\u00edch th\u01b0\u1edbc c\u1ee7a m\u1ed7i block (s\u1ed1 l\u01b0\u1ee3ng lu\u1ed3ng).</li> <li><code>blockIdx</code>: T\u1ecda \u0111\u1ed9 c\u1ee7a block trong grid.</li> <li><code>threadIdx</code>: T\u1ecda \u0111\u1ed9 c\u1ee7a lu\u1ed3ng trong block c\u1ee7a n\u00f3.</li> </ul> <p>Gi\u1edbi h\u1ea1n chi\u1ec1u: M\u1eb7c d\u00f9 lu\u1ed3ng c\u00f3 th\u1ec3 l\u00e0 3D, t\u1ed5ng s\u1ed1 lu\u1ed3ng trong m\u1ed9t block kh\u00f4ng \u0111\u01b0\u1ee3c v\u01b0\u1ee3t qu\u00e1 1024.</p> <p>Ki\u1ec3u <code>dim3</code>: CUDA s\u1eed d\u1ee5ng ki\u1ec3u vector s\u1ed1 nguy\u00ean \u0111\u1eb7c bi\u1ec7t <code>dim3</code> \u0111\u1ec3 ch\u1ec9 \u0111\u1ecbnh c\u00e1c chi\u1ec1u n\u00e0y. V\u00ed d\u1ee5:</p> <pre><code>dim3 grid(32, 1, 1);\ndim3 block(128, 1, 1);\n</code></pre>"},{"location":"cuda/pmpp/chapter-03/#vi-mapping","title":"3.2 \u00c1nh x\u1ea1 lu\u1ed3ng \u0111\u1ebfn d\u1eef li\u1ec7u \u0111a chi\u1ec1u","text":"<p>Kh\u00e1i ni\u1ec7m: \u0110\u1ec3 x\u1eed l\u00fd \u1ea3nh 2D, tr\u1ef1c quan nh\u1ea5t l\u00e0 s\u1eed d\u1ee5ng grid 2D c\u1ee7a c\u00e1c block 2D.</p> <p>C\u00f4ng th\u1ee9c \u00e1nh x\u1ea1 (2D): \u0110\u1ec3 t\u00ecm h\u00e0ng v\u00e0 c\u1ed9t c\u1ee5 th\u1ec3 m\u00e0 lu\u1ed3ng n\u00ean l\u00e0m vi\u1ec7c:</p> <pre><code>row = blockIdx.y * blockDim.y + threadIdx.y;\ncol = blockIdx.x * blockDim.x + threadIdx.x;\n</code></pre> <p>Tuy\u1ebfn t\u00ednh h\u00f3a b\u1ed9 nh\u1edb (Th\u1ee9 t\u1ef1 h\u00e0ng-ch\u00ednh):</p> <ul> <li>Trong C v\u00e0 CUDA, m\u1ea3ng \u0111a chi\u1ec1u \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef trong kh\u00f4ng gian b\u1ed9 nh\u1edb 1D \"ph\u1eb3ng\".</li> <li>B\u1ed1 c\u1ee5c h\u00e0ng-ch\u00ednh: C\u00e1c ph\u1ea7n t\u1eed c\u1ee7a m\u1ed9t h\u00e0ng \u0111\u01b0\u1ee3c \u0111\u1eb7t \u1edf c\u00e1c v\u1ecb tr\u00ed li\u00ean ti\u1ebfp.</li> <li>C\u00f4ng th\u1ee9c: \u0110\u1ec3 truy c\u1eadp ph\u1ea7n t\u1eed 2D t\u1ea1i <code>(row, col)</code> trong m\u1ea3ng 1D c\u00f3 <code>Width</code> nh\u1ea5t \u0111\u1ecbnh:     <pre><code>index = row * Width + col;\n</code></pre></li> </ul> <p>Ki\u1ec3m tra bi\u00ean: N\u1ebfu k\u00edch th\u01b0\u1edbc d\u1eef li\u1ec7u (v\u00ed d\u1ee5: \u1ea3nh 62x76) kh\u00f4ng ph\u1ea3i l\u00e0 b\u1ed9i s\u1ed1 ho\u00e0n h\u1ea3o c\u1ee7a k\u00edch th\u01b0\u1edbc block (v\u00ed d\u1ee5: 16x16), m\u1ed9t s\u1ed1 lu\u1ed3ng s\u1ebd \"ngo\u00e0i gi\u1edbi h\u1ea1n\". Kernel ph\u1ea3i s\u1eed d\u1ee5ng c\u00e2u l\u1ec7nh <code>if</code> \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o c\u00e1c lu\u1ed3ng n\u00e0y kh\u00f4ng truy c\u1eadp b\u1ed9 nh\u1edb kh\u00f4ng h\u1ee3p l\u1ec7.</p>"},{"location":"cuda/pmpp/chapter-03/#vi-blur","title":"3.3 L\u00e0m m\u1edd \u1ea3nh: Kernel ph\u1ee9c t\u1ea1p h\u01a1n","text":"<p>V\u01b0\u1ee3t ra ngo\u00e0i t\u00ednh \u0111\u1ed9c l\u1eadp: Kh\u00f4ng gi\u1ed1ng nh\u01b0 ph\u00e9p c\u1ed9ng vector n\u01a1i m\u1ed7i lu\u1ed3ng ho\u00e0n to\u00e0n \u0111\u1ed9c l\u1eadp, l\u00e0m m\u1edd \u1ea3nh y\u00eau c\u1ea7u lu\u1ed3ng truy c\u1eadp c\u00e1c pixel l\u00e2n c\u1eadn.</p> <p>Quy tr\u00ecnh: M\u1ed9t pixel m\u1edd l\u00e0 gi\u00e1 tr\u1ecb trung b\u00ecnh c\u1ee7a v\u00f9ng \\(N \\times N\\) pixel xung quanh m\u1ee5c ti\u00eau.</p> <p>V\u00f2ng l\u1eb7p b\u00ean trong: Kernel s\u1eed d\u1ee5ng v\u00f2ng l\u1eb7p l\u1ed3ng nhau \u0111\u1ec3 l\u1eb7p qua v\u00f9ng l\u00e2n c\u1eadn.</p> <p>\u00d4 ma/C\u1ea1nh: Kernel bao g\u1ed3m logic \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c pixel \u1edf c\u1ea1nh \u1ea3nh n\u01a1i kh\u00f4ng t\u1ed3n t\u1ea1i v\u00f9ng \\(N \\times N\\) \u0111\u1ea7y \u0111\u1ee7 (s\u1eed d\u1ee5ng 0 ho\u1eb7c pixel g\u1ea7n nh\u1ea5t l\u00e0m gi\u00e1 tr\u1ecb \u0111i\u1ec1n).</p>"},{"location":"cuda/pmpp/chapter-03/#vi-matmul","title":"3.4 Nh\u00e2n ma tr\u1eadn","text":"<p>M\u1eabu: \u0110\u00e2y l\u00e0 \u1ee9ng d\u1ee5ng c\u1ed1t l\u00f5i c\u1ee7a \u00e1nh x\u1ea1 \u0111a chi\u1ec1u.</p> <p>Thu\u1eadt to\u00e1n: \u0110\u1ec3 t\u00ednh m\u1ed9t ph\u1ea7n t\u1eed c\u1ee7a ma tr\u1eadn k\u1ebft qu\u1ea3 \\(P\\), lu\u1ed3ng ph\u1ea3i th\u1ef1c hi\u1ec7n t\u00edch v\u00f4 h\u01b0\u1edbng c\u1ee7a m\u1ed9t h\u00e0ng t\u1eeb ma tr\u1eadn \\(M\\) v\u00e0 m\u1ed9t c\u1ed9t t\u1eeb ma tr\u1eadn \\(N\\).</p> <p>C\u1ea5u tr\u00fac Kernel:</p> <ul> <li>M\u1ed7i lu\u1ed3ng \u0111\u01b0\u1ee3c g\u00e1n cho m\u1ed9t ph\u1ea7n t\u1eed c\u1ee7a ma tr\u1eadn \u0111\u1ea7u ra \\(P\\).</li> <li>Lu\u1ed3ng s\u1eed d\u1ee5ng v\u00f2ng l\u1eb7p \u0111\u1ec3 nh\u00e2n v\u00e0 c\u1ed9ng c\u00e1c ph\u1ea7n t\u1eed:     <pre><code>Pvalue += M[row * Width + k] * N[k * Width + col];\n</code></pre></li> </ul> <p>C\u1ea3nh b\u00e1o hi\u1ec7u qu\u1ea3: Cu\u1ed1n s\u00e1ch l\u01b0u \u00fd r\u1eb1ng ph\u00e9p nh\u00e2n ma tr\u1eadn \"\u0111\u01a1n gi\u1ea3n\" n\u00e0y b\u1ecb gi\u1edbi h\u1ea1n b\u1edfi b\u0103ng th\u00f4ng b\u1ed9 nh\u1edb global (n\u00f3 l\u00e0 \"memory-bound\"). \u0110i\u1ec1u n\u00e0y \u0111\u1eb7t n\u1ec1n t\u1ea3ng cho c\u00e1c k\u1ef9 thu\u1eadt t\u1ed1i \u01b0u h\u00f3a (nh\u01b0 tiling) \u0111\u01b0\u1ee3c gi\u1edbi thi\u1ec7u trong c\u00e1c ch\u01b0\u01a1ng sau.</p>"},{"location":"cuda/pmpp/chapter-03/#vi-summary","title":"3.5 T\u00f3m t\u1eaft k\u1ef9 n\u0103ng","text":"<ul> <li>Hi\u1ec3u c\u00e1ch s\u1eed d\u1ee5ng <code>blockIdx</code> v\u00e0 <code>threadIdx</code> trong 2D/3D.</li> <li>\u00c1nh x\u1ea1 d\u1eef li\u1ec7u \u0111a chi\u1ec1u \u0111\u1ebfn b\u1ed9 nh\u1edb \"ph\u1eb3ng\" theo th\u1ee9 t\u1ef1 h\u00e0ng-ch\u00ednh c\u1ee7a GPU.</li> <li>Tri\u1ec3n khai kernel n\u01a1i c\u00e1c lu\u1ed3ng ph\u1ea3i l\u1eb7p qua c\u00e1c t\u1eadp con d\u1eef li\u1ec7u (nh\u01b0 v\u00f9ng ho\u1eb7c h\u00e0ng ma tr\u1eadn).</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 3 d\u1ea1y \"s\u1ed1 h\u1ecdc \u00e1nh x\u1ea1\". K\u1ef9 n\u0103ng quan tr\u1ecdng nh\u1ea5t \u1edf \u0111\u00e2y l\u00e0 h\u1ecdc c\u00e1ch t\u00ednh ch\u1ec9 s\u1ed1 b\u1ed9 nh\u1edb 1D t\u1eeb t\u1ecda \u0111\u1ed9 lu\u1ed3ng 2D ho\u1eb7c 3D \u0111\u1ec3 h\u00e0ng ngh\u00ecn lu\u1ed3ng c\u00f3 th\u1ec3 \u0111i\u1ec1u h\u01b0\u1edbng c\u00e1c c\u1ea5u tr\u00fac d\u1eef li\u1ec7u ph\u1ee9c t\u1ea1p m\u00e0 kh\u00f4ng b\u1ecb l\u1ed7i ho\u1eb7c ch\u1ed3ng ch\u00e9o.</p>"},{"location":"cuda/pmpp/chapter-04/","title":"Chapter 4: Compute Architecture and Scheduling","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>While Chapter 2 and 3 focused on how to write code, Chapter 4 explains how the hardware actually executes that code. It bridges the gap between the software \"Grid/Block\" model and the physical GPU.</p> <p>Trong khi Ch\u01b0\u01a1ng 2 v\u00e0 3 t\u1eadp trung v\u00e0o c\u00e1ch vi\u1ebft code, Ch\u01b0\u01a1ng 4 gi\u1ea3i th\u00edch c\u00e1ch ph\u1ea7n c\u1ee9ng th\u1ef1c s\u1ef1 th\u1ef1c thi code \u0111\u00f3. N\u00f3 k\u1ebft n\u1ed1i kho\u1ea3ng c\u00e1ch gi\u1eefa m\u00f4 h\u00ecnh ph\u1ea7n m\u1ec1m \"Grid/Block\" v\u00e0 GPU v\u1eadt l\u00fd.</p>"},{"location":"cuda/pmpp/chapter-04/#en-architecture","title":"4.1 Architecture of a Modern GPU","text":"<p>Streaming Multiprocessors (SM): The GPU is organized into an array of SMs. This is the heart of the GPU.</p> <p>Cores: Each SM contains many processing units, often called \"CUDA cores.\"</p> <p>Example (Ampere A100): This architecture features 108 SMs, each with 64 cores, totaling 6,912 cores.</p> <p>Resource Sharing: All cores within a single SM share control logic and instruction caches.</p>"},{"location":"cuda/pmpp/chapter-04/#en-scheduling","title":"4.2 Block Scheduling","text":"<p>Distribution: When a kernel is launched, the CUDA runtime assigns thread blocks to available SMs.</p> <p>Block Integrity: A thread block is assigned to exactly one SM and cannot be split across multiple SMs.</p> <p>Capacity: An SM can host multiple blocks at the same time, but there is a hardware limit based on available registers and memory.</p>"},{"location":"cuda/pmpp/chapter-04/#en-sync","title":"4.3 Synchronization and Transparent Scalability","text":"<p><code>__syncthreads()</code>: A barrier synchronization function. All threads in a block must reach this call before any are allowed to proceed.</p> <p>Deadlock Warning: If <code>__syncthreads()</code> is placed inside a conditional (if-else), all threads must either enter the conditional or none at all; otherwise, the block will hang (deadlock).</p> <p>Transparent Scalability: Because blocks are independent and cannot synchronize with other blocks, the same code can run on a cheap GPU (with 2 SMs) or a high-end GPU (with 100 SMs) without any changes. The hardware simply handles more blocks in parallel on the larger chip.</p>"},{"location":"cuda/pmpp/chapter-04/#en-warps","title":"4.4 Warps and SIMD Hardware","text":"<p>The Warp: This is the actual unit of thread scheduling. In current NVIDIA hardware, a warp consists of 32 threads.</p> <p>SIMT (Single Instruction, Multiple Threads): All 32 threads in a warp execute the same instruction at the same time.</p> <p>Hardware Efficiency: This allows the GPU to use a single \"Control\" unit for many \"ALUs\" (math units), saving space on the chip for more math power.</p>"},{"location":"cuda/pmpp/chapter-04/#en-divergence","title":"4.5 Control Divergence","text":"<p>The Problem: What happens if 16 threads in a warp want to do the <code>if</code> path and 16 want to do the <code>else</code> path?</p> <p>The Penalty: The hardware must execute both paths sequentially. While the <code>if</code> path runs, the <code>else</code> threads are disabled, and vice versa. This is called Control Divergence.</p> <p>Impact: Performance is best when all threads in a warp follow the same path. Divergence on boundary checks becomes less impactful as data size increases, because fewer warps \"straddle\" the boundary.</p>"},{"location":"cuda/pmpp/chapter-04/#en-latency","title":"4.6 Warp Scheduling and Latency Tolerance","text":"<p>Latency Hiding: Memory accesses are slow (taking hundreds of cycles).</p> <p>Context Switching: While one warp is waiting for data from memory, the SM's scheduler immediately switches to another warp that is ready to perform math.</p> <p>Zero-Overhead: Unlike CPUs, where switching tasks is \"expensive\" (requires saving and loading state), GPU threads have their own registers already loaded. Switching between warps costs zero clock cycles.</p>"},{"location":"cuda/pmpp/chapter-04/#en-occupancy","title":"4.7 Resource Partitioning and Occupancy","text":"<p>Occupancy: The ratio of active warps on an SM to the maximum number of warps the SM could potentially support.</p> <p>Resource Limits: SMs have a fixed amount of:</p> <ol> <li>Registers (per SM).</li> <li>Shared Memory (per SM).</li> <li>Thread Block Slots.</li> </ol> <p>The Performance Cliff: If your kernel uses too many registers per thread, the SM will be able to host fewer blocks. This can lead to a sudden drop in performance (a \"cliff\") because there aren't enough active warps to hide memory latency.</p>"},{"location":"cuda/pmpp/chapter-04/#en-query","title":"4.8 Querying Device Properties","text":"<p>Portability: To write code that runs well on different GPUs, programmers can use API functions:</p> <ul> <li><code>cudaGetDeviceCount()</code>: Finds how many GPUs are in the system.</li> <li><code>cudaGetDeviceProperties()</code>: Returns a struct (<code>cudaDeviceProp</code>) containing the number of SMs, max threads per block, and total memory.</li> </ul> <p>Key Takeaway: Chapter 4 explains that the \"magic\" of GPU speed comes from latency hiding. By having thousands of threads \"resident\" on the chip, the GPU always has math to do while it waits for slow memory transfers to complete. High performance requires maintaining high occupancy and avoiding control divergence.</p>"},{"location":"cuda/pmpp/chapter-04/#vi-architecture","title":"4.1 Ki\u1ebfn tr\u00fac GPU hi\u1ec7n \u0111\u1ea1i","text":"<p>Streaming Multiprocessors (SM): GPU \u0111\u01b0\u1ee3c t\u1ed5 ch\u1ee9c th\u00e0nh m\u1ea3ng c\u00e1c SM. \u0110\u00e2y l\u00e0 tr\u00e1i tim c\u1ee7a GPU.</p> <p>L\u00f5i: M\u1ed7i SM ch\u1ee9a nhi\u1ec1u \u0111\u01a1n v\u1ecb x\u1eed l\u00fd, th\u01b0\u1eddng \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 \"CUDA cores\".</p> <p>V\u00ed d\u1ee5 (Ampere A100): Ki\u1ebfn tr\u00fac n\u00e0y c\u00f3 108 SM, m\u1ed7i SM c\u00f3 64 l\u00f5i, t\u1ed5ng c\u1ed9ng 6,912 l\u00f5i.</p> <p>Chia s\u1ebb t\u00e0i nguy\u00ean: T\u1ea5t c\u1ea3 c\u00e1c l\u00f5i trong m\u1ed9t SM chia s\u1ebb logic \u0111i\u1ec1u khi\u1ec3n v\u00e0 cache l\u1ec7nh.</p>"},{"location":"cuda/pmpp/chapter-04/#vi-scheduling","title":"4.2 L\u1eadp l\u1ecbch Block","text":"<p>Ph\u00e2n ph\u1ed1i: Khi kernel \u0111\u01b0\u1ee3c kh\u1edfi ch\u1ea1y, CUDA runtime g\u00e1n c\u00e1c thread block cho c\u00e1c SM c\u00f3 s\u1eb5n.</p> <p>T\u00ednh to\u00e0n v\u1eb9n Block: M\u1ed9t thread block \u0111\u01b0\u1ee3c g\u00e1n cho ch\u00ednh x\u00e1c m\u1ed9t SM v\u00e0 kh\u00f4ng th\u1ec3 chia nh\u1ecf tr\u00ean nhi\u1ec1u SM.</p> <p>Dung l\u01b0\u1ee3ng: M\u1ed9t SM c\u00f3 th\u1ec3 ch\u1ee9a nhi\u1ec1u block c\u00f9ng l\u00fac, nh\u01b0ng c\u00f3 gi\u1edbi h\u1ea1n ph\u1ea7n c\u1ee9ng d\u1ef1a tr\u00ean register v\u00e0 b\u1ed9 nh\u1edb c\u00f3 s\u1eb5n.</p>"},{"location":"cuda/pmpp/chapter-04/#vi-sync","title":"4.3 \u0110\u1ed3ng b\u1ed9 h\u00f3a v\u00e0 Kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng trong su\u1ed1t","text":"<p><code>__syncthreads()</code>: H\u00e0m \u0111\u1ed3ng b\u1ed9 h\u00f3a r\u00e0o c\u1ea3n. T\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng trong block ph\u1ea3i \u0111\u1ea1t \u0111\u1ebfn l\u1ec7nh g\u1ecdi n\u00e0y tr\u01b0\u1edbc khi b\u1ea5t k\u1ef3 lu\u1ed3ng n\u00e0o \u0111\u01b0\u1ee3c ph\u00e9p ti\u1ebfp t\u1ee5c.</p> <p>C\u1ea3nh b\u00e1o Deadlock: N\u1ebfu <code>__syncthreads()</code> \u0111\u01b0\u1ee3c \u0111\u1eb7t b\u00ean trong \u0111i\u1ec1u ki\u1ec7n (if-else), t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng ph\u1ea3i ho\u1eb7c v\u00e0o \u0111i\u1ec1u ki\u1ec7n ho\u1eb7c kh\u00f4ng v\u00e0o; n\u1ebfu kh\u00f4ng, block s\u1ebd b\u1ecb treo (deadlock).</p> <p>Kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng trong su\u1ed1t: V\u00ec c\u00e1c block \u0111\u1ed9c l\u1eadp v\u00e0 kh\u00f4ng th\u1ec3 \u0111\u1ed3ng b\u1ed9 v\u1edbi c\u00e1c block kh\u00e1c, c\u00f9ng m\u1ed9t code c\u00f3 th\u1ec3 ch\u1ea1y tr\u00ean GPU r\u1ebb (v\u1edbi 2 SM) ho\u1eb7c GPU cao c\u1ea5p (v\u1edbi 100 SM) m\u00e0 kh\u00f4ng c\u1ea7n thay \u0111\u1ed5i. Ph\u1ea7n c\u1ee9ng \u0111\u01a1n gi\u1ea3n x\u1eed l\u00fd nhi\u1ec1u block song song h\u01a1n tr\u00ean chip l\u1edbn h\u01a1n.</p>"},{"location":"cuda/pmpp/chapter-04/#vi-warps","title":"4.4 Warp v\u00e0 Ph\u1ea7n c\u1ee9ng SIMD","text":"<p>Warp: \u0110\u00e2y l\u00e0 \u0111\u01a1n v\u1ecb th\u1ef1c t\u1ebf c\u1ee7a l\u1eadp l\u1ecbch lu\u1ed3ng. Trong ph\u1ea7n c\u1ee9ng NVIDIA hi\u1ec7n t\u1ea1i, m\u1ed9t warp bao g\u1ed3m 32 lu\u1ed3ng.</p> <p>SIMT (Single Instruction, Multiple Threads): T\u1ea5t c\u1ea3 32 lu\u1ed3ng trong warp th\u1ef1c thi c\u00f9ng m\u1ed9t l\u1ec7nh c\u00f9ng l\u00fac.</p> <p>Hi\u1ec7u qu\u1ea3 ph\u1ea7n c\u1ee9ng: \u0110i\u1ec1u n\u00e0y cho ph\u00e9p GPU s\u1eed d\u1ee5ng m\u1ed9t \u0111\u01a1n v\u1ecb \"\u0110i\u1ec1u khi\u1ec3n\" duy nh\u1ea5t cho nhi\u1ec1u \"ALU\" (\u0111\u01a1n v\u1ecb to\u00e1n h\u1ecdc), ti\u1ebft ki\u1ec7m kh\u00f4ng gian tr\u00ean chip cho nhi\u1ec1u s\u1ee9c m\u1ea1nh to\u00e1n h\u1ecdc h\u01a1n.</p>"},{"location":"cuda/pmpp/chapter-04/#vi-divergence","title":"4.5 Ph\u00e2n k\u1ef3 \u0111i\u1ec1u khi\u1ec3n","text":"<p>V\u1ea5n \u0111\u1ec1: \u0110i\u1ec1u g\u00ec x\u1ea3y ra n\u1ebfu 16 lu\u1ed3ng trong warp mu\u1ed1n \u0111i \u0111\u01b0\u1eddng <code>if</code> v\u00e0 16 mu\u1ed1n \u0111i \u0111\u01b0\u1eddng <code>else</code>?</p> <p>H\u00ecnh ph\u1ea1t: Ph\u1ea7n c\u1ee9ng ph\u1ea3i th\u1ef1c thi c\u1ea3 hai \u0111\u01b0\u1eddng tu\u1ea7n t\u1ef1. Trong khi \u0111\u01b0\u1eddng <code>if</code> ch\u1ea1y, c\u00e1c lu\u1ed3ng <code>else</code> b\u1ecb v\u00f4 hi\u1ec7u h\u00f3a, v\u00e0 ng\u01b0\u1ee3c l\u1ea1i. \u0110\u00e2y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 Ph\u00e2n k\u1ef3 \u0111i\u1ec1u khi\u1ec3n.</p> <p>T\u00e1c \u0111\u1ed9ng: Hi\u1ec7u n\u0103ng t\u1ed1t nh\u1ea5t khi t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng trong warp \u0111i theo c\u00f9ng m\u1ed9t \u0111\u01b0\u1eddng. Ph\u00e2n k\u1ef3 tr\u00ean ki\u1ec3m tra bi\u00ean tr\u1edf n\u00ean \u00edt t\u00e1c \u0111\u1ed9ng h\u01a1n khi k\u00edch th\u01b0\u1edbc d\u1eef li\u1ec7u t\u0103ng, v\u00ec \u00edt warp \"n\u1eb1m ch\u1ed3ng\" bi\u00ean h\u01a1n.</p>"},{"location":"cuda/pmpp/chapter-04/#vi-latency","title":"4.6 L\u1eadp l\u1ecbch Warp v\u00e0 Dung sai \u0111\u1ed9 tr\u1ec5","text":"<p>Che gi\u1ea5u \u0111\u1ed9 tr\u1ec5: Truy c\u1eadp b\u1ed9 nh\u1edb ch\u1eadm (m\u1ea5t h\u00e0ng tr\u0103m chu k\u1ef3).</p> <p>Chuy\u1ec3n ng\u1eef c\u1ea3nh: Trong khi m\u1ed9t warp \u0111ang ch\u1edd d\u1eef li\u1ec7u t\u1eeb b\u1ed9 nh\u1edb, b\u1ed9 l\u1eadp l\u1ecbch c\u1ee7a SM ngay l\u1eadp t\u1ee9c chuy\u1ec3n sang warp kh\u00e1c s\u1eb5n s\u00e0ng th\u1ef1c hi\u1ec7n to\u00e1n h\u1ecdc.</p> <p>Kh\u00f4ng c\u00f3 chi ph\u00ed: Kh\u00f4ng gi\u1ed1ng nh\u01b0 CPU, n\u01a1i chuy\u1ec3n t\u00e1c v\u1ee5 \"t\u1ed1n k\u00e9m\" (y\u00eau c\u1ea7u l\u01b0u v\u00e0 t\u1ea3i tr\u1ea1ng th\u00e1i), c\u00e1c lu\u1ed3ng GPU c\u00f3 register ri\u00eang \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ea3i. Chuy\u1ec3n \u0111\u1ed5i gi\u1eefa c\u00e1c warp kh\u00f4ng t\u1ed1n chu k\u1ef3 \u0111\u1ed3ng h\u1ed3 n\u00e0o.</p>"},{"location":"cuda/pmpp/chapter-04/#vi-occupancy","title":"4.7 Ph\u00e2n v\u00f9ng t\u00e0i nguy\u00ean v\u00e0 \u0110\u1ed9 l\u1ea5p \u0111\u1ea7y","text":"<p>\u0110\u1ed9 l\u1ea5p \u0111\u1ea7y (Occupancy): T\u1ef7 l\u1ec7 warp ho\u1ea1t \u0111\u1ed9ng tr\u00ean SM so v\u1edbi s\u1ed1 l\u01b0\u1ee3ng warp t\u1ed1i \u0111a m\u00e0 SM c\u00f3 th\u1ec3 h\u1ed7 tr\u1ee3.</p> <p>Gi\u1edbi h\u1ea1n t\u00e0i nguy\u00ean: SM c\u00f3 s\u1ed1 l\u01b0\u1ee3ng c\u1ed1 \u0111\u1ecbnh:</p> <ol> <li>Register (m\u1ed7i SM).</li> <li>Shared Memory (m\u1ed7i SM).</li> <li>Thread Block Slots.</li> </ol> <p>V\u00e1ch \u0111\u00e1 hi\u1ec7u n\u0103ng: N\u1ebfu kernel c\u1ee7a b\u1ea1n s\u1eed d\u1ee5ng qu\u00e1 nhi\u1ec1u register m\u1ed7i lu\u1ed3ng, SM s\u1ebd ch\u1ec9 c\u00f3 th\u1ec3 ch\u1ee9a \u00edt block h\u01a1n. \u0110i\u1ec1u n\u00e0y c\u00f3 th\u1ec3 d\u1eabn \u0111\u1ebfn s\u1ee5t gi\u1ea3m hi\u1ec7u n\u0103ng \u0111\u1ed9t ng\u1ed9t (m\u1ed9t \"v\u00e1ch \u0111\u00e1\") v\u00ec kh\u00f4ng c\u00f3 \u0111\u1ee7 warp ho\u1ea1t \u0111\u1ed9ng \u0111\u1ec3 che gi\u1ea5u \u0111\u1ed9 tr\u1ec5 b\u1ed9 nh\u1edb.</p>"},{"location":"cuda/pmpp/chapter-04/#vi-query","title":"4.8 Truy v\u1ea5n thu\u1ed9c t\u00ednh Device","text":"<p>T\u00ednh di \u0111\u1ed9ng: \u0110\u1ec3 vi\u1ebft code ch\u1ea1y t\u1ed1t tr\u00ean c\u00e1c GPU kh\u00e1c nhau, l\u1eadp tr\u00ecnh vi\u00ean c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng c\u00e1c h\u00e0m API:</p> <ul> <li><code>cudaGetDeviceCount()</code>: T\u00ecm s\u1ed1 l\u01b0\u1ee3ng GPU trong h\u1ec7 th\u1ed1ng.</li> <li><code>cudaGetDeviceProperties()</code>: Tr\u1ea3 v\u1ec1 struct (<code>cudaDeviceProp</code>) ch\u1ee9a s\u1ed1 l\u01b0\u1ee3ng SM, s\u1ed1 lu\u1ed3ng t\u1ed1i \u0111a m\u1ed7i block v\u00e0 t\u1ed5ng b\u1ed9 nh\u1edb.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 4 gi\u1ea3i th\u00edch r\u1eb1ng \"ph\u00e9p m\u00e0u\" c\u1ee7a t\u1ed1c \u0111\u1ed9 GPU \u0111\u1ebfn t\u1eeb che gi\u1ea5u \u0111\u1ed9 tr\u1ec5. B\u1eb1ng c\u00e1ch c\u00f3 h\u00e0ng ngh\u00ecn lu\u1ed3ng \"th\u01b0\u1eddng tr\u00fa\" tr\u00ean chip, GPU lu\u00f4n c\u00f3 to\u00e1n h\u1ecdc \u0111\u1ec3 l\u00e0m trong khi ch\u1edd c\u00e1c chuy\u1ec3n b\u1ed9 nh\u1edb ch\u1eadm ho\u00e0n th\u00e0nh. Hi\u1ec7u n\u0103ng cao y\u00eau c\u1ea7u duy tr\u00ec \u0111\u1ed9 l\u1ea5p \u0111\u1ea7y cao v\u00e0 tr\u00e1nh ph\u00e2n k\u1ef3 \u0111i\u1ec1u khi\u1ec3n.</p>"},{"location":"cuda/pmpp/chapter-05/","title":"Chapter 5: Memory Architecture and Data Locality","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This is one of the most important chapters in the book. It explains how to overcome the \"Memory Wall\"\u2014the fact that moving data is often much slower than doing the actual math.</p> <p>\u0110\u00e2y l\u00e0 m\u1ed9t trong nh\u1eefng ch\u01b0\u01a1ng quan tr\u1ecdng nh\u1ea5t trong cu\u1ed1n s\u00e1ch. N\u00f3 gi\u1ea3i th\u00edch c\u00e1ch v\u01b0\u1ee3t qua \"B\u1ee9c t\u01b0\u1eddng b\u1ed9 nh\u1edb\"\u2014th\u1ef1c t\u1ebf l\u00e0 di chuy\u1ec3n d\u1eef li\u1ec7u th\u01b0\u1eddng ch\u1eadm h\u01a1n nhi\u1ec1u so v\u1edbi th\u1ef1c hi\u1ec7n ph\u00e9p to\u00e1n.</p>"},{"location":"cuda/pmpp/chapter-05/#en-efficiency","title":"5.1 Importance of Memory Access Efficiency","text":"<p>The Problem: Global memory (DRAM) is off-chip and slow. A kernel can be \"memory-bound,\" meaning its execution speed is limited by how fast data can be delivered, not how fast the processors are.</p> <p>Arithmetic Intensity: This is the ratio of floating-point operations (FLOPs) to the number of bytes (B) accessed from global memory.</p> <ul> <li>Example: Simple matrix multiplication has a ratio of 0.25 OP/B (2 operations for every 8 bytes loaded).</li> <li>The Bottleneck: On an A100 GPU, this low ratio means you only utilize 2% of the GPU's potential math power because the threads are constantly waiting for data.</li> </ul>"},{"location":"cuda/pmpp/chapter-05/#en-memory-types","title":"5.2 CUDA Memory Types","text":"<p>CUDA provides a hierarchy of memory to help programmers manage data locality:</p> <ul> <li>Registers: Fastest. Per-thread. Used for automatic variables.</li> <li>Shared Memory: Very fast. Per-block. Accessible by all threads in a block. It is \"scratchpad memory\" that the programmer controls explicitly.</li> <li>Constant Memory: Read-only, cached, and very fast when all threads in a warp access the same address.</li> <li>Local Memory: Not actually local; it resides in global memory. Used when a thread runs out of registers (\"register spilling\").</li> <li>Global Memory: High capacity but slow. Accessible by all threads in all grids.</li> </ul>"},{"location":"cuda/pmpp/chapter-05/#en-tiling","title":"5.3 Tiling for Reduced Memory Traffic","text":"<p>The Concept of Tiling: A strategy to partition data into small subsets (tiles) that fit into the high-speed Shared Memory.</p> <p>The Goal: Instead of every thread loading the same data from slow global memory multiple times, the threads in a block collaborate to load a tile into shared memory once and then reuse it many times.</p> <p>Locality: By focusing on a small subset of data, we exploit \"data reuse,\" drastically reducing the traffic to the slow DRAM.</p>"},{"location":"cuda/pmpp/chapter-05/#en-tiled-matmul","title":"5.4 A Tiled Matrix Multiplication Kernel","text":"<p>Phase-Based Execution: Tiled kernels operate in phases:</p> <ol> <li>Collaborative Load: Each thread in a block loads one element from the global matrix into a shared memory array.</li> <li>Barrier (<code>__syncthreads()</code>): Ensure all threads have finished loading the tile before anyone starts the math.</li> <li>Computation: Threads perform the dot product using the data now in fast shared memory.</li> <li>Barrier (<code>__syncthreads()</code>): Ensure all threads are finished with the current tile before loading the next one (prevents overwriting data still in use).</li> </ol> <p>The Payoff: Global memory traffic is reduced by a factor equal to the <code>TILE_WIDTH</code>. If you use 16x16 tiles, you cut global memory requests by 16 times.</p>"},{"location":"cuda/pmpp/chapter-05/#en-boundary","title":"5.5 Boundary Checks","text":"<p>Arbitrary Sizes: Real-world matrices aren't always perfect multiples of the tile size.</p> <p>The \"Padding\" Strategy: If a tile goes over the edge of the actual data, the threads must detect this and load a 0.0 into shared memory. This allows the dot product math to continue without crashing or producing wrong results (since adding 0 doesn't change a sum).</p>"},{"location":"cuda/pmpp/chapter-05/#en-occupancy","title":"5.6 Impact of Memory Usage on Occupancy","text":"<p>Resource Limits: Every SM has a fixed amount of shared memory (e.g., 64KB or 164KB).</p> <p>Occupancy Trade-off: If your kernel requests too much shared memory per block, the hardware will be able to run fewer blocks simultaneously. This reduces occupancy, which may make it harder for the GPU to hide latency (as explained in Chapter 4).</p> <p>Dynamic Allocation: Explains how to use the <code>extern __shared__</code> keyword to allow the host code to decide the amount of shared memory at runtime.</p> <p>Key Takeaway: Chapter 5 introduces Tiling, the single most important optimization technique for GPU programming. It teaches you to stop treating the GPU as a \"black box\" and start manually managing data movement between slow global memory and fast on-chip shared memory.</p>"},{"location":"cuda/pmpp/chapter-05/#vi-efficiency","title":"5.1 T\u1ea7m quan tr\u1ecdng c\u1ee7a hi\u1ec7u qu\u1ea3 truy c\u1eadp b\u1ed9 nh\u1edb","text":"<p>V\u1ea5n \u0111\u1ec1: B\u1ed9 nh\u1edb global (DRAM) n\u1eb1m ngo\u00e0i chip v\u00e0 ch\u1eadm. M\u1ed9t kernel c\u00f3 th\u1ec3 b\u1ecb \"gi\u1edbi h\u1ea1n b\u1ed9 nh\u1edb\", ngh\u0129a l\u00e0 t\u1ed1c \u0111\u1ed9 th\u1ef1c thi c\u1ee7a n\u00f3 b\u1ecb gi\u1edbi h\u1ea1n b\u1edfi t\u1ed1c \u0111\u1ed9 cung c\u1ea5p d\u1eef li\u1ec7u, kh\u00f4ng ph\u1ea3i t\u1ed1c \u0111\u1ed9 c\u1ee7a b\u1ed9 x\u1eed l\u00fd.</p> <p>C\u01b0\u1eddng \u0111\u1ed9 s\u1ed1 h\u1ecdc: \u0110\u00e2y l\u00e0 t\u1ef7 l\u1ec7 c\u00e1c ph\u00e9p to\u00e1n d\u1ea5u ph\u1ea9y \u0111\u1ed9ng (FLOPs) so v\u1edbi s\u1ed1 byte (B) \u0111\u01b0\u1ee3c truy c\u1eadp t\u1eeb b\u1ed9 nh\u1edb global.</p> <ul> <li>V\u00ed d\u1ee5: Nh\u00e2n ma tr\u1eadn \u0111\u01a1n gi\u1ea3n c\u00f3 t\u1ef7 l\u1ec7 0.25 OP/B (2 ph\u00e9p to\u00e1n cho m\u1ed7i 8 byte \u0111\u01b0\u1ee3c t\u1ea3i).</li> <li>N\u00fat th\u1eaft c\u1ed5 chai: Tr\u00ean GPU A100, t\u1ef7 l\u1ec7 th\u1ea5p n\u00e0y c\u00f3 ngh\u0129a l\u00e0 b\u1ea1n ch\u1ec9 s\u1eed d\u1ee5ng 2% s\u1ee9c m\u1ea1nh to\u00e1n h\u1ecdc ti\u1ec1m n\u0103ng c\u1ee7a GPU v\u00ec c\u00e1c lu\u1ed3ng li\u00ean t\u1ee5c ch\u1edd d\u1eef li\u1ec7u.</li> </ul>"},{"location":"cuda/pmpp/chapter-05/#vi-memory-types","title":"5.2 C\u00e1c lo\u1ea1i b\u1ed9 nh\u1edb CUDA","text":"<p>CUDA cung c\u1ea5p ph\u00e2n c\u1ea5p b\u1ed9 nh\u1edb \u0111\u1ec3 gi\u00fap l\u1eadp tr\u00ecnh vi\u00ean qu\u1ea3n l\u00fd t\u00ednh \u0111\u1ecba ph\u01b0\u01a1ng c\u1ee7a d\u1eef li\u1ec7u:</p> <ul> <li>Register: Nhanh nh\u1ea5t. M\u1ed7i lu\u1ed3ng. \u0110\u01b0\u1ee3c s\u1eed d\u1ee5ng cho c\u00e1c bi\u1ebfn t\u1ef1 \u0111\u1ed9ng.</li> <li>Shared Memory: R\u1ea5t nhanh. M\u1ed7i block. C\u00f3 th\u1ec3 truy c\u1eadp b\u1edfi t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng trong block. \u0110\u00e2y l\u00e0 \"b\u1ed9 nh\u1edb t\u1ea1m\" m\u00e0 l\u1eadp tr\u00ecnh vi\u00ean ki\u1ec3m so\u00e1t r\u00f5 r\u00e0ng.</li> <li>Constant Memory: Ch\u1ec9 \u0111\u1ecdc, \u0111\u01b0\u1ee3c cache v\u00e0 r\u1ea5t nhanh khi t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng trong warp truy c\u1eadp c\u00f9ng m\u1ed9t \u0111\u1ecba ch\u1ec9.</li> <li>Local Memory: Kh\u00f4ng th\u1ef1c s\u1ef1 local; n\u00f3 n\u1eb1m trong b\u1ed9 nh\u1edb global. \u0110\u01b0\u1ee3c s\u1eed d\u1ee5ng khi lu\u1ed3ng h\u1ebft register (\"register spilling\").</li> <li>Global Memory: Dung l\u01b0\u1ee3ng cao nh\u01b0ng ch\u1eadm. C\u00f3 th\u1ec3 truy c\u1eadp b\u1edfi t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng trong t\u1ea5t c\u1ea3 c\u00e1c grid.</li> </ul>"},{"location":"cuda/pmpp/chapter-05/#vi-tiling","title":"5.3 Tiling \u0111\u1ec3 gi\u1ea3m l\u01b0u l\u01b0\u1ee3ng b\u1ed9 nh\u1edb","text":"<p>Kh\u00e1i ni\u1ec7m Tiling: Chi\u1ebfn l\u01b0\u1ee3c ph\u00e2n v\u00f9ng d\u1eef li\u1ec7u th\u00e0nh c\u00e1c t\u1eadp con nh\u1ecf (tile) ph\u00f9 h\u1ee3p v\u1edbi Shared Memory t\u1ed1c \u0111\u1ed9 cao.</p> <p>M\u1ee5c ti\u00eau: Thay v\u00ec m\u1ed7i lu\u1ed3ng t\u1ea3i c\u00f9ng m\u1ed9t d\u1eef li\u1ec7u t\u1eeb b\u1ed9 nh\u1edb global ch\u1eadm nhi\u1ec1u l\u1ea7n, c\u00e1c lu\u1ed3ng trong block c\u1ed9ng t\u00e1c \u0111\u1ec3 t\u1ea3i tile v\u00e0o shared memory m\u1ed9t l\u1ea7n v\u00e0 sau \u0111\u00f3 t\u00e1i s\u1eed d\u1ee5ng nhi\u1ec1u l\u1ea7n.</p> <p>T\u00ednh \u0111\u1ecba ph\u01b0\u01a1ng: B\u1eb1ng c\u00e1ch t\u1eadp trung v\u00e0o t\u1eadp con d\u1eef li\u1ec7u nh\u1ecf, ch\u00fang ta khai th\u00e1c \"t\u00e1i s\u1eed d\u1ee5ng d\u1eef li\u1ec7u\", gi\u1ea3m \u0111\u00e1ng k\u1ec3 l\u01b0u l\u01b0\u1ee3ng \u0111\u1ebfn DRAM ch\u1eadm.</p>"},{"location":"cuda/pmpp/chapter-05/#vi-tiled-matmul","title":"5.4 Kernel nh\u00e2n ma tr\u1eadn Tiled","text":"<p>Th\u1ef1c thi theo giai \u0111o\u1ea1n: Kernel tiled ho\u1ea1t \u0111\u1ed9ng theo c\u00e1c giai \u0111o\u1ea1n:</p> <ol> <li>T\u1ea3i c\u1ed9ng t\u00e1c: M\u1ed7i lu\u1ed3ng trong block t\u1ea3i m\u1ed9t ph\u1ea7n t\u1eed t\u1eeb ma tr\u1eadn global v\u00e0o m\u1ea3ng shared memory.</li> <li>R\u00e0o c\u1ea3n (<code>__syncthreads()</code>): \u0110\u1ea3m b\u1ea3o t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng \u0111\u00e3 ho\u00e0n th\u00e0nh vi\u1ec7c t\u1ea3i tile tr\u01b0\u1edbc khi b\u1ea5t k\u1ef3 ai b\u1eaft \u0111\u1ea7u t\u00ednh to\u00e1n.</li> <li>T\u00ednh to\u00e1n: C\u00e1c lu\u1ed3ng th\u1ef1c hi\u1ec7n t\u00edch v\u00f4 h\u01b0\u1edbng s\u1eed d\u1ee5ng d\u1eef li\u1ec7u hi\u1ec7n c\u00f3 trong shared memory nhanh.</li> <li>R\u00e0o c\u1ea3n (<code>__syncthreads()</code>): \u0110\u1ea3m b\u1ea3o t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng \u0111\u00e3 ho\u00e0n th\u00e0nh v\u1edbi tile hi\u1ec7n t\u1ea1i tr\u01b0\u1edbc khi t\u1ea3i tile ti\u1ebfp theo (ng\u0103n ghi \u0111\u00e8 d\u1eef li\u1ec7u v\u1eabn \u0111ang s\u1eed d\u1ee5ng).</li> </ol> <p>L\u1ee3i \u00edch: L\u01b0u l\u01b0\u1ee3ng b\u1ed9 nh\u1edb global \u0111\u01b0\u1ee3c gi\u1ea3m theo h\u1ec7 s\u1ed1 b\u1eb1ng <code>TILE_WIDTH</code>. N\u1ebfu b\u1ea1n s\u1eed d\u1ee5ng tile 16x16, b\u1ea1n c\u1eaft gi\u1ea3m y\u00eau c\u1ea7u b\u1ed9 nh\u1edb global 16 l\u1ea7n.</p>"},{"location":"cuda/pmpp/chapter-05/#vi-boundary","title":"5.5 Ki\u1ec3m tra bi\u00ean","text":"<p>K\u00edch th\u01b0\u1edbc t\u00f9y \u00fd: Ma tr\u1eadn th\u1ef1c t\u1ebf kh\u00f4ng ph\u1ea3i l\u00fac n\u00e0o c\u0169ng l\u00e0 b\u1ed9i s\u1ed1 ho\u00e0n h\u1ea3o c\u1ee7a k\u00edch th\u01b0\u1edbc tile.</p> <p>Chi\u1ebfn l\u01b0\u1ee3c \"\u0110\u1ec7m\": N\u1ebfu tile v\u01b0\u1ee3t ra ngo\u00e0i c\u1ea1nh c\u1ee7a d\u1eef li\u1ec7u th\u1ef1c t\u1ebf, c\u00e1c lu\u1ed3ng ph\u1ea3i ph\u00e1t hi\u1ec7n \u0111i\u1ec1u n\u00e0y v\u00e0 t\u1ea3i 0.0 v\u00e0o shared memory. \u0110i\u1ec1u n\u00e0y cho ph\u00e9p ph\u00e9p to\u00e1n t\u00edch v\u00f4 h\u01b0\u1edbng ti\u1ebfp t\u1ee5c m\u00e0 kh\u00f4ng b\u1ecb l\u1ed7i ho\u1eb7c t\u1ea1o ra k\u1ebft qu\u1ea3 sai (v\u00ec c\u1ed9ng 0 kh\u00f4ng thay \u0111\u1ed5i t\u1ed5ng).</p>"},{"location":"cuda/pmpp/chapter-05/#vi-occupancy","title":"5.6 T\u00e1c \u0111\u1ed9ng c\u1ee7a vi\u1ec7c s\u1eed d\u1ee5ng b\u1ed9 nh\u1edb \u0111\u1ebfn Occupancy","text":"<p>Gi\u1edbi h\u1ea1n t\u00e0i nguy\u00ean: M\u1ed7i SM c\u00f3 s\u1ed1 l\u01b0\u1ee3ng shared memory c\u1ed1 \u0111\u1ecbnh (v\u00ed d\u1ee5: 64KB ho\u1eb7c 164KB).</p> <p>\u0110\u00e1nh \u0111\u1ed5i Occupancy: N\u1ebfu kernel c\u1ee7a b\u1ea1n y\u00eau c\u1ea7u qu\u00e1 nhi\u1ec1u shared memory m\u1ed7i block, ph\u1ea7n c\u1ee9ng s\u1ebd ch\u1ec9 c\u00f3 th\u1ec3 ch\u1ea1y \u00edt block \u0111\u1ed3ng th\u1eddi h\u01a1n. \u0110i\u1ec1u n\u00e0y l\u00e0m gi\u1ea3m occupancy, c\u00f3 th\u1ec3 khi\u1ebfn GPU kh\u00f3 che gi\u1ea5u \u0111\u1ed9 tr\u1ec5 h\u01a1n (nh\u01b0 gi\u1ea3i th\u00edch trong Ch\u01b0\u01a1ng 4).</p> <p>C\u1ea5p ph\u00e1t \u0111\u1ed9ng: Gi\u1ea3i th\u00edch c\u00e1ch s\u1eed d\u1ee5ng t\u1eeb kh\u00f3a <code>extern __shared__</code> \u0111\u1ec3 cho ph\u00e9p code host quy\u1ebft \u0111\u1ecbnh s\u1ed1 l\u01b0\u1ee3ng shared memory t\u1ea1i runtime.</p> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 5 gi\u1edbi thi\u1ec7u Tiling, k\u1ef9 thu\u1eadt t\u1ed1i \u01b0u h\u00f3a quan tr\u1ecdng nh\u1ea5t cho l\u1eadp tr\u00ecnh GPU. N\u00f3 d\u1ea1y b\u1ea1n ng\u1eebng coi GPU nh\u01b0 \"h\u1ed9p \u0111en\" v\u00e0 b\u1eaft \u0111\u1ea7u qu\u1ea3n l\u00fd th\u1ee7 c\u00f4ng di chuy\u1ec3n d\u1eef li\u1ec7u gi\u1eefa b\u1ed9 nh\u1edb global ch\u1eadm v\u00e0 shared memory nhanh tr\u00ean chip.</p>"},{"location":"cuda/pmpp/chapter-06/","title":"Chapter 6: Performance Considerations","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter concludes Part I of the book by providing a systematic approach to identifying and fixing performance bottlenecks. It focuses on how to interact with the physical DRAM and how to balance parallel work.</p> <p>Ch\u01b0\u01a1ng n\u00e0y k\u1ebft th\u00fac Ph\u1ea7n I c\u1ee7a cu\u1ed1n s\u00e1ch b\u1eb1ng c\u00e1ch cung c\u1ea5p ph\u01b0\u01a1ng ph\u00e1p c\u00f3 h\u1ec7 th\u1ed1ng \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh v\u00e0 kh\u1eafc ph\u1ee5c c\u00e1c n\u00fat th\u1eaft c\u1ed5 chai hi\u1ec7u n\u0103ng. N\u00f3 t\u1eadp trung v\u00e0o c\u00e1ch t\u01b0\u01a1ng t\u00e1c v\u1edbi DRAM v\u1eadt l\u00fd v\u00e0 c\u00e1ch c\u00e2n b\u1eb1ng c\u00f4ng vi\u1ec7c song song.</p>"},{"location":"cuda/pmpp/chapter-06/#en-coalescing","title":"6.1 Memory Coalescing","text":"<p>DRAM Bursts: Global memory (DRAM) does not just provide a single byte when requested. Instead, it delivers a \"burst\" of consecutive locations (e.g., 32, 64, or 128 bytes).</p> <p>The Technique: If all threads in a warp access a single burst of data in one instruction, the hardware coalesces these many requests into a single memory transaction.</p> <p>Row-Major Impact: Because C/CUDA use row-major order, threads mapping to adjacent columns (<code>col = ... + threadIdx.x</code>) will naturally access adjacent memory locations.</p> <p>The Penalty: If threads access data in a \"stride\" (e.g., each thread accessing the same column but in different rows), the hardware must perform many separate, slow memory transactions. This is \"uncoalesced\" access.</p>"},{"location":"cuda/pmpp/chapter-06/#en-latency-hiding","title":"6.2 Hiding Memory Latency","text":"<p>Memory Parallelism: DRAM is organized into Channels and Banks. Multiple requests can be processed simultaneously if they are spread across different banks.</p> <p>The Symbiosis: High performance depends on a relationship between the threads and the DRAM. To reach peak bandwidth, you need enough active warps (high occupancy) to ensure the memory system is always busy processing requests while the cores are busy doing math.</p>"},{"location":"cuda/pmpp/chapter-06/#en-coarsening","title":"6.3 Thread Coarsening","text":"<p>The \"Price of Parallelism\": Sometimes, having every thread do the smallest possible unit of work leads to redundant data loading or too much synchronization.</p> <p>Definition: Thread coarsening is an optimization where the programmer makes one thread responsible for multiple output elements.</p> <p>Benefit: In matrix multiplication, two adjacent output tiles often share the same input row. By using one coarsened thread to calculate two output points, that row is loaded from global memory only once instead of twice, saving bandwidth.</p> <p>Risks: Too much coarsening reduces the total number of threads, which can lower occupancy and prevent the GPU from hiding latency.</p>"},{"location":"cuda/pmpp/chapter-06/#en-checklist","title":"6.4 A Checklist of Optimizations","text":"<p>The authors consolidate the book's foundational lessons into a \"Universal Checklist\":</p> <ol> <li>Maximizing Occupancy: Tuning SM resources (registers/shared memory) to keep more warps active.</li> <li>Enabling Coalescing: Rearranging thread-to-data mapping so global memory accesses are contiguous.</li> <li>Minimizing Control Divergence: Ensuring threads in a warp take the same execution path.</li> <li>Tiling of Reused Data: Using shared memory to reduce global memory traffic.</li> <li>Privatization: (Introduced later) Giving threads/blocks their own private copies of data to avoid \"Atomic\" operation contention.</li> <li>Thread Coarsening: Reducing redundant work by grouping tasks into a single thread.</li> </ol>"},{"location":"cuda/pmpp/chapter-06/#en-bottleneck","title":"6.5 Knowing Your Computation's Bottleneck","text":"<p>Resource Limits: Every application has a primary limiting factor (Memory-bound vs. Compute-bound).</p> <p>Profilers: The authors recommend using tools like the NVIDIA Profiler to identify the \"performance cliff\" or \"bottleneck.\"</p> <p>Strategy: Optimization is only useful if it targets the actual bottleneck. For example, adding shared memory tiling won't help if your kernel is already limited by its math operations (compute-bound).</p> <p>Key Takeaway: Chapter 6 teaches the \"economics\" of GPU programming. It's not just about writing parallel code; it's about writing code that respects the way hardware moves data (Coalescing) and finding the right balance between doing work in parallel and doing it serially (Coarsening) to maximize efficiency.</p>"},{"location":"cuda/pmpp/chapter-06/#vi-coalescing","title":"6.1 G\u1ed9p b\u1ed9 nh\u1edb (Memory Coalescing)","text":"<p>DRAM Burst: B\u1ed9 nh\u1edb global (DRAM) kh\u00f4ng ch\u1ec9 cung c\u1ea5p m\u1ed9t byte khi \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u. Thay v\u00e0o \u0111\u00f3, n\u00f3 cung c\u1ea5p m\u1ed9t \"burst\" c\u00e1c v\u1ecb tr\u00ed li\u00ean ti\u1ebfp (v\u00ed d\u1ee5: 32, 64 ho\u1eb7c 128 byte).</p> <p>K\u1ef9 thu\u1eadt: N\u1ebfu t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng trong warp truy c\u1eadp m\u1ed9t burst d\u1eef li\u1ec7u duy nh\u1ea5t trong m\u1ed9t l\u1ec7nh, ph\u1ea7n c\u1ee9ng g\u1ed9p nhi\u1ec1u y\u00eau c\u1ea7u n\u00e0y th\u00e0nh m\u1ed9t giao d\u1ecbch b\u1ed9 nh\u1edb duy nh\u1ea5t.</p> <p>T\u00e1c \u0111\u1ed9ng th\u1ee9 t\u1ef1 h\u00e0ng-ch\u00ednh: V\u00ec C/CUDA s\u1eed d\u1ee5ng th\u1ee9 t\u1ef1 h\u00e0ng-ch\u00ednh, c\u00e1c lu\u1ed3ng \u00e1nh x\u1ea1 \u0111\u1ebfn c\u00e1c c\u1ed9t li\u1ec1n k\u1ec1 (<code>col = ... + threadIdx.x</code>) s\u1ebd t\u1ef1 nhi\u00ean truy c\u1eadp c\u00e1c v\u1ecb tr\u00ed b\u1ed9 nh\u1edb li\u1ec1n k\u1ec1.</p> <p>H\u00ecnh ph\u1ea1t: N\u1ebfu c\u00e1c lu\u1ed3ng truy c\u1eadp d\u1eef li\u1ec7u theo \"b\u01b0\u1edbc nh\u1ea3y\" (v\u00ed d\u1ee5: m\u1ed7i lu\u1ed3ng truy c\u1eadp c\u00f9ng m\u1ed9t c\u1ed9t nh\u01b0ng \u1edf c\u00e1c h\u00e0ng kh\u00e1c nhau), ph\u1ea7n c\u1ee9ng ph\u1ea3i th\u1ef1c hi\u1ec7n nhi\u1ec1u giao d\u1ecbch b\u1ed9 nh\u1edb ri\u00eang bi\u1ec7t, ch\u1eadm. \u0110\u00e2y l\u00e0 truy c\u1eadp \"kh\u00f4ng g\u1ed9p\".</p>"},{"location":"cuda/pmpp/chapter-06/#vi-latency-hiding","title":"6.2 Che gi\u1ea5u \u0111\u1ed9 tr\u1ec5 b\u1ed9 nh\u1edb","text":"<p>T\u00ednh song song b\u1ed9 nh\u1edb: DRAM \u0111\u01b0\u1ee3c t\u1ed5 ch\u1ee9c th\u00e0nh K\u00eanh v\u00e0 Bank. Nhi\u1ec1u y\u00eau c\u1ea7u c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c x\u1eed l\u00fd \u0111\u1ed3ng th\u1eddi n\u1ebfu ch\u00fang \u0111\u01b0\u1ee3c ph\u00e2n t\u00e1n tr\u00ean c\u00e1c bank kh\u00e1c nhau.</p> <p>S\u1ef1 c\u1ed9ng sinh: Hi\u1ec7u n\u0103ng cao ph\u1ee5 thu\u1ed9c v\u00e0o m\u1ed1i quan h\u1ec7 gi\u1eefa c\u00e1c lu\u1ed3ng v\u00e0 DRAM. \u0110\u1ec3 \u0111\u1ea1t b\u0103ng th\u00f4ng \u0111\u1ec9nh, b\u1ea1n c\u1ea7n \u0111\u1ee7 warp ho\u1ea1t \u0111\u1ed9ng (occupancy cao) \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o h\u1ec7 th\u1ed1ng b\u1ed9 nh\u1edb lu\u00f4n b\u1eadn x\u1eed l\u00fd y\u00eau c\u1ea7u trong khi c\u00e1c l\u00f5i b\u1eadn l\u00e0m to\u00e1n.</p>"},{"location":"cuda/pmpp/chapter-06/#vi-coarsening","title":"6.3 L\u00e0m th\u00f4 lu\u1ed3ng (Thread Coarsening)","text":"<p>\"Gi\u00e1 c\u1ee7a t\u00ednh song song\": \u0110\u00f4i khi, vi\u1ec7c \u0111\u1ec3 m\u1ed7i lu\u1ed3ng th\u1ef1c hi\u1ec7n \u0111\u01a1n v\u1ecb c\u00f4ng vi\u1ec7c nh\u1ecf nh\u1ea5t c\u00f3 th\u1ec3 d\u1eabn \u0111\u1ebfn t\u1ea3i d\u1eef li\u1ec7u d\u01b0 th\u1eeba ho\u1eb7c qu\u00e1 nhi\u1ec1u \u0111\u1ed3ng b\u1ed9 h\u00f3a.</p> <p>\u0110\u1ecbnh ngh\u0129a: Thread coarsening l\u00e0 t\u1ed1i \u01b0u h\u00f3a trong \u0111\u00f3 l\u1eadp tr\u00ecnh vi\u00ean l\u00e0m cho m\u1ed9t lu\u1ed3ng ch\u1ecbu tr\u00e1ch nhi\u1ec7m cho nhi\u1ec1u ph\u1ea7n t\u1eed \u0111\u1ea7u ra.</p> <p>L\u1ee3i \u00edch: Trong nh\u00e2n ma tr\u1eadn, hai tile \u0111\u1ea7u ra li\u1ec1n k\u1ec1 th\u01b0\u1eddng chia s\u1ebb c\u00f9ng m\u1ed9t h\u00e0ng \u0111\u1ea7u v\u00e0o. B\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng m\u1ed9t lu\u1ed3ng th\u00f4 \u0111\u1ec3 t\u00ednh hai \u0111i\u1ec3m \u0111\u1ea7u ra, h\u00e0ng \u0111\u00f3 \u0111\u01b0\u1ee3c t\u1ea3i t\u1eeb b\u1ed9 nh\u1edb global ch\u1ec9 m\u1ed9t l\u1ea7n thay v\u00ec hai l\u1ea7n, ti\u1ebft ki\u1ec7m b\u0103ng th\u00f4ng.</p> <p>R\u1ee7i ro: L\u00e0m th\u00f4 qu\u00e1 nhi\u1ec1u gi\u1ea3m t\u1ed5ng s\u1ed1 lu\u1ed3ng, c\u00f3 th\u1ec3 l\u00e0m gi\u1ea3m occupancy v\u00e0 ng\u0103n GPU che gi\u1ea5u \u0111\u1ed9 tr\u1ec5.</p>"},{"location":"cuda/pmpp/chapter-06/#vi-checklist","title":"6.4 Danh s\u00e1ch ki\u1ec3m tra t\u1ed1i \u01b0u h\u00f3a","text":"<p>C\u00e1c t\u00e1c gi\u1ea3 t\u1ed5ng h\u1ee3p c\u00e1c b\u00e0i h\u1ecdc n\u1ec1n t\u1ea3ng c\u1ee7a cu\u1ed1n s\u00e1ch th\u00e0nh \"Danh s\u00e1ch ki\u1ec3m tra ph\u1ed5 qu\u00e1t\":</p> <ol> <li>T\u1ed1i \u0111a h\u00f3a Occupancy: \u0110i\u1ec1u ch\u1ec9nh t\u00e0i nguy\u00ean SM (register/shared memory) \u0111\u1ec3 gi\u1eef nhi\u1ec1u warp ho\u1ea1t \u0111\u1ed9ng h\u01a1n.</li> <li>K\u00edch ho\u1ea1t Coalescing: S\u1eafp x\u1ebfp l\u1ea1i \u00e1nh x\u1ea1 lu\u1ed3ng-d\u1eef li\u1ec7u \u0111\u1ec3 truy c\u1eadp b\u1ed9 nh\u1edb global li\u1ec1n k\u1ec1.</li> <li>Gi\u1ea3m thi\u1ec3u ph\u00e2n k\u1ef3 \u0111i\u1ec1u khi\u1ec3n: \u0110\u1ea3m b\u1ea3o c\u00e1c lu\u1ed3ng trong warp \u0111i theo c\u00f9ng m\u1ed9t \u0111\u01b0\u1eddng th\u1ef1c thi.</li> <li>Tiling d\u1eef li\u1ec7u t\u00e1i s\u1eed d\u1ee5ng: S\u1eed d\u1ee5ng shared memory \u0111\u1ec3 gi\u1ea3m l\u01b0u l\u01b0\u1ee3ng b\u1ed9 nh\u1edb global.</li> <li>Privatization: (Gi\u1edbi thi\u1ec7u sau) Cung c\u1ea5p cho lu\u1ed3ng/block b\u1ea3n sao ri\u00eang c\u1ee7a d\u1eef li\u1ec7u \u0111\u1ec3 tr\u00e1nh tranh ch\u1ea5p thao t\u00e1c \"Atomic\".</li> <li>Thread Coarsening: Gi\u1ea3m c\u00f4ng vi\u1ec7c d\u01b0 th\u1eeba b\u1eb1ng c\u00e1ch nh\u00f3m t\u00e1c v\u1ee5 v\u00e0o m\u1ed9t lu\u1ed3ng duy nh\u1ea5t.</li> </ol>"},{"location":"cuda/pmpp/chapter-06/#vi-bottleneck","title":"6.5 Bi\u1ebft n\u00fat th\u1eaft c\u1ed5 chai c\u1ee7a t\u00ednh to\u00e1n","text":"<p>Gi\u1edbi h\u1ea1n t\u00e0i nguy\u00ean: M\u1ed7i \u1ee9ng d\u1ee5ng c\u00f3 y\u1ebfu t\u1ed1 gi\u1edbi h\u1ea1n ch\u00ednh (Memory-bound vs. Compute-bound).</p> <p>Profiler: C\u00e1c t\u00e1c gi\u1ea3 khuy\u1ebfn ngh\u1ecb s\u1eed d\u1ee5ng c\u00e1c c\u00f4ng c\u1ee5 nh\u01b0 NVIDIA Profiler \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \"v\u00e1ch \u0111\u00e1 hi\u1ec7u n\u0103ng\" ho\u1eb7c \"n\u00fat th\u1eaft c\u1ed5 chai\".</p> <p>Chi\u1ebfn l\u01b0\u1ee3c: T\u1ed1i \u01b0u h\u00f3a ch\u1ec9 h\u1eefu \u00edch n\u1ebfu n\u00f3 nh\u1eafm v\u00e0o n\u00fat th\u1eaft c\u1ed5 chai th\u1ef1c t\u1ebf. V\u00ed d\u1ee5: th\u00eam tiling shared memory s\u1ebd kh\u00f4ng gi\u00fap \u00edch n\u1ebfu kernel c\u1ee7a b\u1ea1n \u0111\u00e3 b\u1ecb gi\u1edbi h\u1ea1n b\u1edfi c\u00e1c ph\u00e9p to\u00e1n (compute-bound).</p> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 6 d\u1ea1y \"kinh t\u1ebf h\u1ecdc\" c\u1ee7a l\u1eadp tr\u00ecnh GPU. Kh\u00f4ng ch\u1ec9 v\u1ec1 vi\u1ebft code song song; m\u00e0 v\u1ec1 vi\u1ebft code t\u00f4n tr\u1ecdng c\u00e1ch ph\u1ea7n c\u1ee9ng di chuy\u1ec3n d\u1eef li\u1ec7u (Coalescing) v\u00e0 t\u00ecm s\u1ef1 c\u00e2n b\u1eb1ng \u0111\u00fang gi\u1eefa l\u00e0m c\u00f4ng vi\u1ec7c song song v\u00e0 l\u00e0m n\u00f3 tu\u1ea7n t\u1ef1 (Coarsening) \u0111\u1ec3 t\u1ed1i \u0111a h\u00f3a hi\u1ec7u qu\u1ea3.</p>"},{"location":"cuda/pmpp/chapter-07/","title":"Chapter 7: Convolution","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter begins Part II (Parallel Patterns). It uses the convolution operation\u2014widely used in image processing and signal analysis\u2014to introduce advanced memory management and the \"halo cell\" concept.</p> <p>Ch\u01b0\u01a1ng n\u00e0y b\u1eaft \u0111\u1ea7u Ph\u1ea7n II (C\u00e1c m\u1eabu song song). N\u00f3 s\u1eed d\u1ee5ng ph\u00e9p t\u00edch ch\u1eadp\u2014\u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng r\u1ed9ng r\u00e3i trong x\u1eed l\u00fd \u1ea3nh v\u00e0 ph\u00e2n t\u00edch t\u00edn hi\u1ec7u\u2014\u0111\u1ec3 gi\u1edbi thi\u1ec7u qu\u1ea3n l\u00fd b\u1ed9 nh\u1edb n\u00e2ng cao v\u00e0 kh\u00e1i ni\u1ec7m \"halo cell\".</p>"},{"location":"cuda/pmpp/chapter-07/#en-background","title":"7.1 Background","text":"<p>Definition: Convolution is an array operation where each output element is a weighted sum of a neighboring patch of input elements.</p> <p>The Filter (Mask): The weights are defined by a small array called a convolution filter (or mask).</p> <p>The Radius (\\(r\\)): The filter size is typically an odd number (\\(2r + 1\\)). The radius \\(r\\) determines how many neighbors on each side contribute to the center element.</p> <p>Dimensions: While 1D convolution is common in audio, the chapter focuses on 2D convolution for images.</p>"},{"location":"cuda/pmpp/chapter-07/#en-basic","title":"7.2 Parallel Convolution: A Basic Algorithm","text":"<p>Mapping: Each thread is assigned to calculate one output pixel.</p> <p>Ghost Cells: When calculating pixels near the edge of an image, the filter may \"overhang\" the data. These missing elements are called ghost cells.</p> <p>Boundary Handling: In the basic kernel, an <code>if</code> statement checks if a neighbor's coordinates are within the array bounds; if not, the value is typically treated as 0.0.</p> <p>Efficiency Problem: This basic approach has very low arithmetic intensity (0.25 OP/B) because every input pixel is loaded from global memory many times by different threads.</p>"},{"location":"cuda/pmpp/chapter-07/#en-constant","title":"7.3 Constant Memory and Caching","text":"<p>The Observation: The convolution filter is small (usually &lt; 64KB), stays constant during the kernel, and is accessed by all threads in a warp in the same order.</p> <p>Keyword <code>__constant__</code>: These properties make the filter a perfect fit for Constant Memory.</p> <p>Constant Cache: GPUs have a specialized \"constant cache.\" Because all threads in a warp access the same filter element at the same time, the hardware \"broadcasts\" the value, essentially making the access as fast as a register.</p> <p>API: Data is moved to constant memory using <code>cudaMemcpyToSymbol()</code>.</p>"},{"location":"cuda/pmpp/chapter-07/#en-halo","title":"7.4 Tiled Convolution with Halo Cells","text":"<p>The Challenge: Unlike matrix multiplication where input and output tiles are the same size, convolution requires an \"Input Tile\" that is larger than the \"Output Tile.\"</p> <p>Halo Cells: To calculate an output tile, you need the internal pixels PLUS a surrounding border of pixels. These border pixels are the Halo Cells.</p> <p>Thread Organization: The chapter explores two ways to load tiles:</p> <ol> <li>Block matches Input Tile: Some threads load data but are \"turned off\" for the actual math because they map to the halo.</li> <li>Block matches Output Tile: All threads do math, but the loading logic is more complex because some threads must load multiple data points to cover the halo.</li> </ol> <p>Performance Payoff: Tiling can increase the compute-to-memory ratio significantly (e.g., from 0.5 to 9.57 OP/B for a 5x5 filter).</p>"},{"location":"cuda/pmpp/chapter-07/#en-cache","title":"7.5 Tiled Convolution using Caches for Halo Cells","text":"<p>Simplification: In modern GPUs, the L2 cache is quite effective.</p> <p>The Strategy: Instead of manually loading halo cells into shared memory, the programmer only loads the \"internal\" pixels into shared memory and lets the L2 cache/Read-Only cache handle the halo cells.</p> <p>Benefit: This makes the code much simpler and more readable while still capturing most of the performance benefits of tiling.</p>"},{"location":"cuda/pmpp/chapter-07/#en-summary","title":"7.6 Summary of Concepts","text":"<p>Stencil Pattern: Introduces the idea that convolution is a form of the \"stencil\" pattern, which is used to solve differential equations (detailed further in Chapter 8).</p> <p>Data Reuse: Tiling for convolution is unique because it manages the overlap of input data needed by neighboring blocks.</p> <p>Key Takeaway: Chapter 7 teaches you that when data is accessed by many threads in a predictable way (like a filter), Constant Memory is the best tool. It also introduces the complexity of Halo Cells, which is essential for any algorithm that uses a \"sliding window\" over data.</p>"},{"location":"cuda/pmpp/chapter-07/#vi-background","title":"7.1 B\u1ed1i c\u1ea3nh","text":"<p>\u0110\u1ecbnh ngh\u0129a: T\u00edch ch\u1eadp l\u00e0 ph\u00e9p to\u00e1n m\u1ea3ng trong \u0111\u00f3 m\u1ed7i ph\u1ea7n t\u1eed \u0111\u1ea7u ra l\u00e0 t\u1ed5ng c\u00f3 tr\u1ecdng s\u1ed1 c\u1ee7a v\u00f9ng l\u00e2n c\u1eadn c\u00e1c ph\u1ea7n t\u1eed \u0111\u1ea7u v\u00e0o.</p> <p>B\u1ed9 l\u1ecdc (Mask): C\u00e1c tr\u1ecdng s\u1ed1 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a b\u1edfi m\u1ed9t m\u1ea3ng nh\u1ecf g\u1ecdi l\u00e0 b\u1ed9 l\u1ecdc t\u00edch ch\u1eadp (ho\u1eb7c mask).</p> <p>B\u00e1n k\u00ednh (\\(r\\)): K\u00edch th\u01b0\u1edbc b\u1ed9 l\u1ecdc th\u01b0\u1eddng l\u00e0 s\u1ed1 l\u1ebb (\\(2r + 1\\)). B\u00e1n k\u00ednh \\(r\\) x\u00e1c \u0111\u1ecbnh c\u00f3 bao nhi\u00eau l\u00e2n c\u1eadn \u1edf m\u1ed7i b\u00ean \u0111\u00f3ng g\u00f3p v\u00e0o ph\u1ea7n t\u1eed trung t\u00e2m.</p> <p>Chi\u1ec1u: Trong khi t\u00edch ch\u1eadp 1D ph\u1ed5 bi\u1ebfn trong \u00e2m thanh, ch\u01b0\u01a1ng n\u00e0y t\u1eadp trung v\u00e0o t\u00edch ch\u1eadp 2D cho \u1ea3nh.</p>"},{"location":"cuda/pmpp/chapter-07/#vi-basic","title":"7.2 T\u00edch ch\u1eadp song song: Thu\u1eadt to\u00e1n c\u01a1 b\u1ea3n","text":"<p>\u00c1nh x\u1ea1: M\u1ed7i lu\u1ed3ng \u0111\u01b0\u1ee3c g\u00e1n \u0111\u1ec3 t\u00ednh m\u1ed9t pixel \u0111\u1ea7u ra.</p> <p>Ghost Cell: Khi t\u00ednh c\u00e1c pixel g\u1ea7n c\u1ea1nh \u1ea3nh, b\u1ed9 l\u1ecdc c\u00f3 th\u1ec3 \"nh\u00f4 ra\" ngo\u00e0i d\u1eef li\u1ec7u. C\u00e1c ph\u1ea7n t\u1eed thi\u1ebfu n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 ghost cell.</p> <p>X\u1eed l\u00fd bi\u00ean: Trong kernel c\u01a1 b\u1ea3n, c\u00e2u l\u1ec7nh <code>if</code> ki\u1ec3m tra xem t\u1ecda \u0111\u1ed9 c\u1ee7a l\u00e2n c\u1eadn c\u00f3 n\u1eb1m trong gi\u1edbi h\u1ea1n m\u1ea3ng kh\u00f4ng; n\u1ebfu kh\u00f4ng, gi\u00e1 tr\u1ecb th\u01b0\u1eddng \u0111\u01b0\u1ee3c coi l\u00e0 0.0.</p> <p>V\u1ea5n \u0111\u1ec1 hi\u1ec7u qu\u1ea3: C\u00e1ch ti\u1ebfp c\u1eadn c\u01a1 b\u1ea3n n\u00e0y c\u00f3 c\u01b0\u1eddng \u0111\u1ed9 s\u1ed1 h\u1ecdc r\u1ea5t th\u1ea5p (0.25 OP/B) v\u00ec m\u1ed7i pixel \u0111\u1ea7u v\u00e0o \u0111\u01b0\u1ee3c t\u1ea3i t\u1eeb b\u1ed9 nh\u1edb global nhi\u1ec1u l\u1ea7n b\u1edfi c\u00e1c lu\u1ed3ng kh\u00e1c nhau.</p>"},{"location":"cuda/pmpp/chapter-07/#vi-constant","title":"7.3 B\u1ed9 nh\u1edb Constant v\u00e0 Caching","text":"<p>Quan s\u00e1t: B\u1ed9 l\u1ecdc t\u00edch ch\u1eadp nh\u1ecf (th\u01b0\u1eddng &lt; 64KB), gi\u1eef nguy\u00ean trong kernel v\u00e0 \u0111\u01b0\u1ee3c truy c\u1eadp b\u1edfi t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng trong warp theo c\u00f9ng th\u1ee9 t\u1ef1.</p> <p>T\u1eeb kh\u00f3a <code>__constant__</code>: C\u00e1c thu\u1ed9c t\u00ednh n\u00e0y l\u00e0m cho b\u1ed9 l\u1ecdc ph\u00f9 h\u1ee3p ho\u00e0n h\u1ea3o v\u1edbi Constant Memory.</p> <p>Constant Cache: GPU c\u00f3 \"constant cache\" chuy\u00ean bi\u1ec7t. V\u00ec t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng trong warp truy c\u1eadp c\u00f9ng m\u1ed9t ph\u1ea7n t\u1eed b\u1ed9 l\u1ecdc c\u00f9ng l\u00fac, ph\u1ea7n c\u1ee9ng \"ph\u00e1t s\u00f3ng\" gi\u00e1 tr\u1ecb, v\u1ec1 c\u01a1 b\u1ea3n l\u00e0m cho truy c\u1eadp nhanh nh\u01b0 register.</p> <p>API: D\u1eef li\u1ec7u \u0111\u01b0\u1ee3c chuy\u1ec3n \u0111\u1ebfn constant memory b\u1eb1ng <code>cudaMemcpyToSymbol()</code>.</p>"},{"location":"cuda/pmpp/chapter-07/#vi-halo","title":"7.4 T\u00edch ch\u1eadp Tiled v\u1edbi Halo Cell","text":"<p>Th\u00e1ch th\u1ee9c: Kh\u00f4ng gi\u1ed1ng nh\u01b0 nh\u00e2n ma tr\u1eadn n\u01a1i tile \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra c\u00f3 c\u00f9ng k\u00edch th\u01b0\u1edbc, t\u00edch ch\u1eadp y\u00eau c\u1ea7u \"Input Tile\" l\u1edbn h\u01a1n \"Output Tile\".</p> <p>Halo Cell: \u0110\u1ec3 t\u00ednh tile \u0111\u1ea7u ra, b\u1ea1n c\u1ea7n c\u00e1c pixel b\u00ean trong C\u1ed8NG v\u1edbi vi\u1ec1n xung quanh c\u00e1c pixel. C\u00e1c pixel vi\u1ec1n n\u00e0y l\u00e0 Halo Cell.</p> <p>T\u1ed5 ch\u1ee9c lu\u1ed3ng: Ch\u01b0\u01a1ng kh\u00e1m ph\u00e1 hai c\u00e1ch t\u1ea3i tile:</p> <ol> <li>Block kh\u1edbp Input Tile: M\u1ed9t s\u1ed1 lu\u1ed3ng t\u1ea3i d\u1eef li\u1ec7u nh\u01b0ng b\u1ecb \"t\u1eaft\" cho ph\u00e9p to\u00e1n th\u1ef1c t\u1ebf v\u00ec ch\u00fang \u00e1nh x\u1ea1 \u0111\u1ebfn halo.</li> <li>Block kh\u1edbp Output Tile: T\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng l\u00e0m to\u00e1n, nh\u01b0ng logic t\u1ea3i ph\u1ee9c t\u1ea1p h\u01a1n v\u00ec m\u1ed9t s\u1ed1 lu\u1ed3ng ph\u1ea3i t\u1ea3i nhi\u1ec1u \u0111i\u1ec3m d\u1eef li\u1ec7u \u0111\u1ec3 bao ph\u1ee7 halo.</li> </ol> <p>L\u1ee3i \u00edch hi\u1ec7u n\u0103ng: Tiling c\u00f3 th\u1ec3 t\u0103ng t\u1ef7 l\u1ec7 t\u00ednh to\u00e1n-b\u1ed9 nh\u1edb \u0111\u00e1ng k\u1ec3 (v\u00ed d\u1ee5: t\u1eeb 0.5 \u0111\u1ebfn 9.57 OP/B cho b\u1ed9 l\u1ecdc 5x5).</p>"},{"location":"cuda/pmpp/chapter-07/#vi-cache","title":"7.5 T\u00edch ch\u1eadp Tiled s\u1eed d\u1ee5ng Cache cho Halo Cell","text":"<p>\u0110\u01a1n gi\u1ea3n h\u00f3a: Trong GPU hi\u1ec7n \u0111\u1ea1i, L2 cache kh\u00e1 hi\u1ec7u qu\u1ea3.</p> <p>Chi\u1ebfn l\u01b0\u1ee3c: Thay v\u00ec t\u1ea3i th\u1ee7 c\u00f4ng halo cell v\u00e0o shared memory, l\u1eadp tr\u00ecnh vi\u00ean ch\u1ec9 t\u1ea3i c\u00e1c pixel \"b\u00ean trong\" v\u00e0o shared memory v\u00e0 \u0111\u1ec3 L2 cache/Read-Only cache x\u1eed l\u00fd halo cell.</p> <p>L\u1ee3i \u00edch: \u0110i\u1ec1u n\u00e0y l\u00e0m cho code \u0111\u01a1n gi\u1ea3n v\u00e0 d\u1ec5 \u0111\u1ecdc h\u01a1n nhi\u1ec1u trong khi v\u1eabn n\u1eafm b\u1eaft h\u1ea7u h\u1ebft l\u1ee3i \u00edch hi\u1ec7u n\u0103ng c\u1ee7a tiling.</p>"},{"location":"cuda/pmpp/chapter-07/#vi-summary","title":"7.6 T\u00f3m t\u1eaft kh\u00e1i ni\u1ec7m","text":"<p>M\u1eabu Stencil: Gi\u1edbi thi\u1ec7u \u00fd t\u01b0\u1edfng r\u1eb1ng t\u00edch ch\u1eadp l\u00e0 m\u1ed9t d\u1ea1ng c\u1ee7a m\u1eabu \"stencil\", \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 gi\u1ea3i ph\u01b0\u01a1ng tr\u00ecnh vi ph\u00e2n (chi ti\u1ebft h\u01a1n trong Ch\u01b0\u01a1ng 8).</p> <p>T\u00e1i s\u1eed d\u1ee5ng d\u1eef li\u1ec7u: Tiling cho t\u00edch ch\u1eadp \u0111\u1ed9c \u0111\u00e1o v\u00ec n\u00f3 qu\u1ea3n l\u00fd s\u1ef1 ch\u1ed3ng ch\u00e9o c\u1ee7a d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o c\u1ea7n thi\u1ebft b\u1edfi c\u00e1c block l\u00e2n c\u1eadn.</p> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 7 d\u1ea1y b\u1ea1n r\u1eb1ng khi d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c truy c\u1eadp b\u1edfi nhi\u1ec1u lu\u1ed3ng theo c\u00e1ch c\u00f3 th\u1ec3 d\u1ef1 \u0111o\u00e1n (nh\u01b0 b\u1ed9 l\u1ecdc), Constant Memory l\u00e0 c\u00f4ng c\u1ee5 t\u1ed1t nh\u1ea5t. N\u00f3 c\u0169ng gi\u1edbi thi\u1ec7u s\u1ef1 ph\u1ee9c t\u1ea1p c\u1ee7a Halo Cell, \u0111i\u1ec1u c\u1ea7n thi\u1ebft cho b\u1ea5t k\u1ef3 thu\u1eadt to\u00e1n n\u00e0o s\u1eed d\u1ee5ng \"c\u1eeda s\u1ed5 tr\u01b0\u1ee3t\" tr\u00ean d\u1eef li\u1ec7u.</p>"},{"location":"cuda/pmpp/chapter-08/","title":"Chapter 8: Stencil","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This is a new chapter in the 4<sup>th</sup> Edition. While stencils resemble convolution, they are primarily used in scientific computing to solve differential equations (e.g., fluid dynamics, heat conductance) and present unique 3D optimization challenges.</p> <p>\u0110\u00e2y l\u00e0 ch\u01b0\u01a1ng m\u1edbi trong \u1ea4n b\u1ea3n th\u1ee9 4. Trong khi stencil gi\u1ed1ng t\u00edch ch\u1eadp, ch\u00fang ch\u1ee7 y\u1ebfu \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong t\u00ednh to\u00e1n khoa h\u1ecdc \u0111\u1ec3 gi\u1ea3i ph\u01b0\u01a1ng tr\u00ecnh vi ph\u00e2n (v\u00ed d\u1ee5: \u0111\u1ed9ng l\u1ef1c h\u1ecdc ch\u1ea5t l\u1ecfng, d\u1eabn nhi\u1ec7t) v\u00e0 \u0111\u01b0a ra c\u00e1c th\u00e1ch th\u1ee9c t\u1ed1i \u01b0u h\u00f3a 3D \u0111\u1ed9c \u0111\u00e1o.</p>"},{"location":"cuda/pmpp/chapter-08/#en-background","title":"8.1 Background","text":"<p>Definition: A stencil is a geometric pattern of weights applied to each point of a structured grid to approximate derivatives (finite-difference methods).</p> <p>Stencil vs. Convolution:</p> <ul> <li>Similarities: Both use a neighbor-based weighted sum and must handle halo/ghost cells.</li> <li>Differences: Stencils are typically iterative (the output of one step becomes the input of the next) and often use high-precision data (double precision), which consumes more on-chip memory.</li> </ul> <p>Discretization: Explains how a continuous function (like a sine wave) is represented as discrete points on a grid with a specific spacing (\\(h\\)).</p>"},{"location":"cuda/pmpp/chapter-08/#en-basic","title":"8.2 Parallel Stencil: A Basic Algorithm","text":"<p>3D Stencil: Most real-world stencils are 3D. A common example is the 7-point stencil, where each point is calculated using itself plus 6 neighbors (North, South, East, West, Up, and Down).</p> <p>The Bottleneck: The basic parallel version has extremely low arithmetic intensity (~0.46 OP/B). Memory access is the primary limiting factor, as each data point is loaded multiple times from global memory.</p>"},{"location":"cuda/pmpp/chapter-08/#en-tiling","title":"8.3 Shared Memory Tiling for Stencil Sweep","text":"<p>The 3D Challenge: In 3D, thread blocks are limited by the 1024-thread maximum. An \\(8 \\times 8 \\times 8\\) cube uses 512 threads, but the \"Halo\" elements (border cells) account for a massive 58% of the data loaded.</p> <p>Inefficiency: This high halo-to-internal-data ratio means shared memory tiling is much less effective in 3D than in 2D unless further optimized.</p> <p>Coalescing: Small 3D tiles often lead to poor memory coalescing because threads in a warp end up accessing distant memory locations.</p>"},{"location":"cuda/pmpp/chapter-08/#en-coarsening","title":"8.4 Thread Coarsening (Coarsening in Z)","text":"<p>The Strategy: To overcome the 1024-thread limit and the high cost of halos, the authors introduce thread coarsening in the Z-direction.</p> <p>The Approach: Instead of one thread calculating one point, each thread calculates a vertical column of points.</p> <p>Benefit: In a 3D sweep, you only need to load one \"new\" plane into shared memory at each step. You reuse the \"current\" and \"previous\" planes already on the chip. This significantly reduces global memory traffic and increases the compute-to-memory ratio.</p>"},{"location":"cuda/pmpp/chapter-08/#en-register","title":"8.5 Register Tiling","text":"<p>The Insight: In a 7-point stencil, the \"Up\" and \"Down\" neighbors (along the Z-axis) are only used by the specific thread assigned to that \\((x, y)\\) coordinate.</p> <p>The Optimization:</p> <ul> <li>The \"North, South, East, West\" neighbors must stay in Shared Memory because they are shared across multiple threads.</li> <li>The \"Up\" and \"Down\" values can be stored in Registers, which are even faster and don't take up shared memory capacity.</li> </ul> <p>Result: This reduces shared memory usage to \u2153 of the original tiled version, allowing for larger tiles and higher occupancy.</p>"},{"location":"cuda/pmpp/chapter-08/#en-summary","title":"8.6 Summary of Stencil Optimizations","text":"<ul> <li>Tiling: Increases data reuse.</li> <li>Coarsening: Handles the dimensionality of 3D data efficiently.</li> <li>Register Tiling: Further reduces pressure on shared memory by utilizing the register file.</li> </ul> <p>Key Takeaway: Chapter 8 demonstrates that for 3D patterns, standard tiling isn't enough. High performance requires \"thinking in planes\"\u2014using thread coarsening to sweep through the volume while combining shared memory and registers to minimize the \"halo\" overhead.</p>"},{"location":"cuda/pmpp/chapter-08/#vi-background","title":"8.1 B\u1ed1i c\u1ea3nh","text":"<p>\u0110\u1ecbnh ngh\u0129a: Stencil l\u00e0 m\u1eabu h\u00ecnh h\u1ecdc c\u1ee7a c\u00e1c tr\u1ecdng s\u1ed1 \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng cho m\u1ed7i \u0111i\u1ec3m c\u1ee7a l\u01b0\u1edbi c\u00f3 c\u1ea5u tr\u00fac \u0111\u1ec3 x\u1ea5p x\u1ec9 \u0111\u1ea1o h\u00e0m (ph\u01b0\u01a1ng ph\u00e1p sai ph\u00e2n h\u1eefu h\u1ea1n).</p> <p>Stencil vs. T\u00edch ch\u1eadp:</p> <ul> <li>Gi\u1ed1ng nhau: C\u1ea3 hai \u0111\u1ec1u s\u1eed d\u1ee5ng t\u1ed5ng c\u00f3 tr\u1ecdng s\u1ed1 d\u1ef1a tr\u00ean l\u00e2n c\u1eadn v\u00e0 ph\u1ea3i x\u1eed l\u00fd halo/ghost cell.</li> <li>Kh\u00e1c nhau: Stencil th\u01b0\u1eddng l\u1eb7p (\u0111\u1ea7u ra c\u1ee7a m\u1ed9t b\u01b0\u1edbc tr\u1edf th\u00e0nh \u0111\u1ea7u v\u00e0o c\u1ee7a b\u01b0\u1edbc ti\u1ebfp theo) v\u00e0 th\u01b0\u1eddng s\u1eed d\u1ee5ng d\u1eef li\u1ec7u \u0111\u1ed9 ch\u00ednh x\u00e1c cao (double precision), ti\u00eau th\u1ee5 nhi\u1ec1u b\u1ed9 nh\u1edb tr\u00ean chip h\u01a1n.</li> </ul> <p>R\u1eddi r\u1ea1c h\u00f3a: Gi\u1ea3i th\u00edch c\u00e1ch m\u1ed9t h\u00e0m li\u00ean t\u1ee5c (nh\u01b0 s\u00f3ng sin) \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n d\u01b0\u1edbi d\u1ea1ng c\u00e1c \u0111i\u1ec3m r\u1eddi r\u1ea1c tr\u00ean l\u01b0\u1edbi v\u1edbi kho\u1ea3ng c\u00e1ch c\u1ee5 th\u1ec3 (\\(h\\)).</p>"},{"location":"cuda/pmpp/chapter-08/#vi-basic","title":"8.2 Stencil song song: Thu\u1eadt to\u00e1n c\u01a1 b\u1ea3n","text":"<p>Stencil 3D: H\u1ea7u h\u1ebft c\u00e1c stencil th\u1ef1c t\u1ebf l\u00e0 3D. M\u1ed9t v\u00ed d\u1ee5 ph\u1ed5 bi\u1ebfn l\u00e0 stencil 7 \u0111i\u1ec3m, trong \u0111\u00f3 m\u1ed7i \u0111i\u1ec3m \u0111\u01b0\u1ee3c t\u00ednh b\u1eb1ng ch\u00ednh n\u00f3 c\u1ed9ng v\u1edbi 6 l\u00e2n c\u1eadn (B\u1eafc, Nam, \u0110\u00f4ng, T\u00e2y, Tr\u00ean v\u00e0 D\u01b0\u1edbi).</p> <p>N\u00fat th\u1eaft c\u1ed5 chai: Phi\u00ean b\u1ea3n song song c\u01a1 b\u1ea3n c\u00f3 c\u01b0\u1eddng \u0111\u1ed9 s\u1ed1 h\u1ecdc c\u1ef1c th\u1ea5p (~0.46 OP/B). Truy c\u1eadp b\u1ed9 nh\u1edb l\u00e0 y\u1ebfu t\u1ed1 gi\u1edbi h\u1ea1n ch\u00ednh, v\u00ec m\u1ed7i \u0111i\u1ec3m d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c t\u1ea3i nhi\u1ec1u l\u1ea7n t\u1eeb b\u1ed9 nh\u1edb global.</p>"},{"location":"cuda/pmpp/chapter-08/#vi-tiling","title":"8.3 Tiling Shared Memory cho Stencil Sweep","text":"<p>Th\u00e1ch th\u1ee9c 3D: Trong 3D, thread block b\u1ecb gi\u1edbi h\u1ea1n b\u1edfi t\u1ed1i \u0111a 1024 lu\u1ed3ng. M\u1ed9t kh\u1ed1i \\(8 \\times 8 \\times 8\\) s\u1eed d\u1ee5ng 512 lu\u1ed3ng, nh\u01b0ng c\u00e1c ph\u1ea7n t\u1eed \"Halo\" (cell bi\u00ean) chi\u1ebfm 58% d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c t\u1ea3i.</p> <p>Kh\u00f4ng hi\u1ec7u qu\u1ea3: T\u1ef7 l\u1ec7 halo-d\u1eef li\u1ec7u-b\u00ean-trong cao n\u00e0y c\u00f3 ngh\u0129a l\u00e0 tiling shared memory \u00edt hi\u1ec7u qu\u1ea3 h\u01a1n nhi\u1ec1u trong 3D so v\u1edbi 2D tr\u1eeb khi \u0111\u01b0\u1ee3c t\u1ed1i \u01b0u h\u00f3a th\u00eam.</p> <p>Coalescing: Tile 3D nh\u1ecf th\u01b0\u1eddng d\u1eabn \u0111\u1ebfn coalescing b\u1ed9 nh\u1edb k\u00e9m v\u00ec c\u00e1c lu\u1ed3ng trong warp truy c\u1eadp c\u00e1c v\u1ecb tr\u00ed b\u1ed9 nh\u1edb xa nhau.</p>"},{"location":"cuda/pmpp/chapter-08/#vi-coarsening","title":"8.4 Thread Coarsening (L\u00e0m th\u00f4 theo Z)","text":"<p>Chi\u1ebfn l\u01b0\u1ee3c: \u0110\u1ec3 v\u01b0\u1ee3t qua gi\u1edbi h\u1ea1n 1024 lu\u1ed3ng v\u00e0 chi ph\u00ed cao c\u1ee7a halo, c\u00e1c t\u00e1c gi\u1ea3 gi\u1edbi thi\u1ec7u thread coarsening theo h\u01b0\u1edbng Z.</p> <p>C\u00e1ch ti\u1ebfp c\u1eadn: Thay v\u00ec m\u1ed9t lu\u1ed3ng t\u00ednh m\u1ed9t \u0111i\u1ec3m, m\u1ed7i lu\u1ed3ng t\u00ednh m\u1ed9t c\u1ed9t d\u1ecdc c\u00e1c \u0111i\u1ec3m.</p> <p>L\u1ee3i \u00edch: Trong sweep 3D, b\u1ea1n ch\u1ec9 c\u1ea7n t\u1ea3i m\u1ed9t m\u1eb7t ph\u1eb3ng \"m\u1edbi\" v\u00e0o shared memory \u1edf m\u1ed7i b\u01b0\u1edbc. B\u1ea1n t\u00e1i s\u1eed d\u1ee5ng c\u00e1c m\u1eb7t ph\u1eb3ng \"hi\u1ec7n t\u1ea1i\" v\u00e0 \"tr\u01b0\u1edbc \u0111\u00f3\" \u0111\u00e3 c\u00f3 tr\u00ean chip. \u0110i\u1ec1u n\u00e0y gi\u1ea3m \u0111\u00e1ng k\u1ec3 l\u01b0u l\u01b0\u1ee3ng b\u1ed9 nh\u1edb global v\u00e0 t\u0103ng t\u1ef7 l\u1ec7 t\u00ednh to\u00e1n-b\u1ed9 nh\u1edb.</p>"},{"location":"cuda/pmpp/chapter-08/#vi-register","title":"8.5 Register Tiling","text":"<p>Hi\u1ec3u bi\u1ebft: Trong stencil 7 \u0111i\u1ec3m, c\u00e1c l\u00e2n c\u1eadn \"Tr\u00ean\" v\u00e0 \"D\u01b0\u1edbi\" (d\u1ecdc theo tr\u1ee5c Z) ch\u1ec9 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng b\u1edfi lu\u1ed3ng c\u1ee5 th\u1ec3 \u0111\u01b0\u1ee3c g\u00e1n cho t\u1ecda \u0111\u1ed9 \\((x, y)\\) \u0111\u00f3.</p> <p>T\u1ed1i \u01b0u h\u00f3a:</p> <ul> <li>C\u00e1c l\u00e2n c\u1eadn \"B\u1eafc, Nam, \u0110\u00f4ng, T\u00e2y\" ph\u1ea3i \u1edf trong Shared Memory v\u00ec ch\u00fang \u0111\u01b0\u1ee3c chia s\u1ebb gi\u1eefa nhi\u1ec1u lu\u1ed3ng.</li> <li>C\u00e1c gi\u00e1 tr\u1ecb \"Tr\u00ean\" v\u00e0 \"D\u01b0\u1edbi\" c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef trong Register, nhanh h\u01a1n v\u00e0 kh\u00f4ng chi\u1ebfm dung l\u01b0\u1ee3ng shared memory.</li> </ul> <p>K\u1ebft qu\u1ea3: \u0110i\u1ec1u n\u00e0y gi\u1ea3m vi\u1ec7c s\u1eed d\u1ee5ng shared memory xu\u1ed1ng \u2153 phi\u00ean b\u1ea3n tiled ban \u0111\u1ea7u, cho ph\u00e9p tile l\u1edbn h\u01a1n v\u00e0 occupancy cao h\u01a1n.</p>"},{"location":"cuda/pmpp/chapter-08/#vi-summary","title":"8.6 T\u00f3m t\u1eaft t\u1ed1i \u01b0u h\u00f3a Stencil","text":"<ul> <li>Tiling: T\u0103ng t\u00e1i s\u1eed d\u1ee5ng d\u1eef li\u1ec7u.</li> <li>Coarsening: X\u1eed l\u00fd chi\u1ec1u c\u1ee7a d\u1eef li\u1ec7u 3D m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3.</li> <li>Register Tiling: Gi\u1ea3m th\u00eam \u00e1p l\u1ef1c l\u00ean shared memory b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng register file.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 8 ch\u1ee9ng minh r\u1eb1ng \u0111\u1ed1i v\u1edbi c\u00e1c m\u1eabu 3D, tiling ti\u00eau chu\u1ea9n l\u00e0 ch\u01b0a \u0111\u1ee7. Hi\u1ec7u n\u0103ng cao y\u00eau c\u1ea7u \"t\u01b0 duy theo m\u1eb7t ph\u1eb3ng\"\u2014s\u1eed d\u1ee5ng thread coarsening \u0111\u1ec3 qu\u00e9t qua kh\u1ed1i l\u01b0\u1ee3ng trong khi k\u1ebft h\u1ee3p shared memory v\u00e0 register \u0111\u1ec3 gi\u1ea3m thi\u1ec3u chi ph\u00ed \"halo\".</p>"},{"location":"cuda/pmpp/chapter-09/","title":"Chapter 9: Parallel Histogram","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter shifts focus from independent data processing to a pattern where multiple threads must update the same memory location, introducing the critical concepts of Atomic Operations and Privatization.</p> <p>Ch\u01b0\u01a1ng n\u00e0y chuy\u1ec3n tr\u1ecdng t\u00e2m t\u1eeb x\u1eed l\u00fd d\u1eef li\u1ec7u \u0111\u1ed9c l\u1eadp sang m\u1eabu trong \u0111\u00f3 nhi\u1ec1u lu\u1ed3ng ph\u1ea3i c\u1eadp nh\u1eadt c\u00f9ng m\u1ed9t v\u1ecb tr\u00ed b\u1ed9 nh\u1edb, gi\u1edbi thi\u1ec7u c\u00e1c kh\u00e1i ni\u1ec7m quan tr\u1ecdng v\u1ec1 Atomic Operations v\u00e0 Privatization.</p>"},{"location":"cuda/pmpp/chapter-09/#en-background","title":"9.1 Background","text":"<p>Definition: A histogram counts the frequency of data values within specific ranges (bins).</p> <p>The Sequential Approach: A simple <code>for</code> loop iterates through the data, calculates the bin index, and increments the counter. It is usually memory-bound on the CPU.</p> <p>Application: Essential for image feature extraction, speech recognition, and analyzing large datasets (like credit card fraud detection).</p>"},{"location":"cuda/pmpp/chapter-09/#en-atomic","title":"9.2 Atomic Operations and a Basic Histogram Kernel","text":"<p>The Problem (Output Interference): In parallel, multiple threads may try to increment the same bin at the same time. This is a Read-Modify-Write race condition. If two threads read \"5,\" both add \"1,\" and both write back \"6,\" one update is lost.</p> <p>The Solution: Atomic Operations (<code>atomicAdd</code>).</p> <p>Mechanism: An atomic operation is an \"undividable\" unit. The hardware ensures that while one thread is performing its read-modify-write on a memory address, no other thread can access that same address.</p> <p>Trade-off: Atomics guarantee correctness but force threads to wait in line (serialization), which can destroy parallel performance.</p>"},{"location":"cuda/pmpp/chapter-09/#en-latency","title":"9.3 Latency and Throughput of Atomic Operations","text":"<p>The Bottleneck: Performing atomics in Global Memory is very slow. The throughput is limited by the DRAM's high latency (hundreds of clock cycles).</p> <p>Contention: If the data is biased (e.g., an image of a blue sky where most pixels fall into the same \"blue\" bin), thousands of threads will queue up for one memory location, causing a massive performance drop.</p> <p>L2 Cache Atomics: Modern GPUs can perform atomics in the L2 cache, which is much faster than DRAM but still suffers when contention is high.</p>"},{"location":"cuda/pmpp/chapter-09/#en-privatization","title":"9.4 Privatization","text":"<p>The Strategy: To reduce contention, give each thread block its own private copy of the histogram in Shared Memory.</p> <p>The Process:</p> <ol> <li>Local Phase: Each block creates a \"sub-histogram\" in fast shared memory. Threads perform atomics locally.</li> <li>Global Phase: Once a block finishes its data, it \"commits\" its private results to the final global histogram using a second set of atomic operations.</li> </ol> <p>Benefit: Contention is reduced by a factor equal to the number of blocks, and shared memory atomics are significantly faster than global memory ones.</p>"},{"location":"cuda/pmpp/chapter-09/#en-coarsening","title":"9.5 Coarsening","text":"<p>Interleaved Partitioning: To keep global memory access efficient (Coalesced), coarsened threads should not take \"large contiguous chunks\" of data. Instead, they should use an interleaved approach where threads process adjacent elements in each step.</p> <p>Overhead Reduction: By having each thread process multiple elements, you reduce the total number of blocks needed, which in turn reduces the overhead of merging private histograms into the global memory.</p>"},{"location":"cuda/pmpp/chapter-09/#en-aggregation","title":"9.6 Aggregation","text":"<p>The \"Streak\" Optimization: If a dataset contains long sequences of the same value (e.g., a large patch of white pixels), a thread can count these occurrences in a local register first.</p> <p>The Result: Instead of calling <code>atomicAdd</code> 100 times for 100 white pixels, the thread calls it once with a value of 100. This further minimizes hardware contention.</p>"},{"location":"cuda/pmpp/chapter-09/#en-summary","title":"9.7 Summary of Histogram Optimizations","text":"<ul> <li>Atomics: Necessary for correctness when \"owner-computes\" isn't possible.</li> <li>Privatization: The primary technique to turn a global serial bottleneck into a distributed parallel task.</li> <li>Interleaved Partitioning: Crucial for maintaining memory coalescing when one thread handles multiple data points.</li> </ul> <p>Key Takeaway: Chapter 9 teaches you how to handle Output Interference. The lesson is that you should always try to move contention from slow global memory to fast shared memory (Privatization) and consolidate updates whenever possible (Aggregation) to keep the \"math-to-memory\" ratio high.</p>"},{"location":"cuda/pmpp/chapter-09/#vi-background","title":"9.1 B\u1ed1i c\u1ea3nh","text":"<p>\u0110\u1ecbnh ngh\u0129a: Histogram \u0111\u1ebfm t\u1ea7n su\u1ea5t c\u1ee7a c\u00e1c gi\u00e1 tr\u1ecb d\u1eef li\u1ec7u trong c\u00e1c ph\u1ea1m vi c\u1ee5 th\u1ec3 (bin).</p> <p>C\u00e1ch ti\u1ebfp c\u1eadn tu\u1ea7n t\u1ef1: V\u00f2ng l\u1eb7p <code>for</code> \u0111\u01a1n gi\u1ea3n l\u1eb7p qua d\u1eef li\u1ec7u, t\u00ednh ch\u1ec9 s\u1ed1 bin v\u00e0 t\u0103ng b\u1ed9 \u0111\u1ebfm. N\u00f3 th\u01b0\u1eddng b\u1ecb gi\u1edbi h\u1ea1n b\u1ed9 nh\u1edb tr\u00ean CPU.</p> <p>\u1ee8ng d\u1ee5ng: Thi\u1ebft y\u1ebfu cho tr\u00edch xu\u1ea5t \u0111\u1eb7c tr\u01b0ng \u1ea3nh, nh\u1eadn d\u1ea1ng gi\u1ecdng n\u00f3i v\u00e0 ph\u00e2n t\u00edch t\u1eadp d\u1eef li\u1ec7u l\u1edbn (nh\u01b0 ph\u00e1t hi\u1ec7n gian l\u1eadn th\u1ebb t\u00edn d\u1ee5ng).</p>"},{"location":"cuda/pmpp/chapter-09/#vi-atomic","title":"9.2 Atomic Operations v\u00e0 Kernel Histogram c\u01a1 b\u1ea3n","text":"<p>V\u1ea5n \u0111\u1ec1 (Xung \u0111\u1ed9t \u0111\u1ea7u ra): Trong song song, nhi\u1ec1u lu\u1ed3ng c\u00f3 th\u1ec3 c\u1ed1 g\u1eafng t\u0103ng c\u00f9ng m\u1ed9t bin c\u00f9ng l\u00fac. \u0110\u00e2y l\u00e0 \u0111i\u1ec1u ki\u1ec7n tranh ch\u1ea5p Read-Modify-Write. N\u1ebfu hai lu\u1ed3ng \u0111\u1ecdc \"5\", c\u1ea3 hai c\u1ed9ng \"1\" v\u00e0 c\u1ea3 hai ghi l\u1ea1i \"6\", m\u1ed9t c\u1eadp nh\u1eadt b\u1ecb m\u1ea5t.</p> <p>Gi\u1ea3i ph\u00e1p: Atomic Operations (<code>atomicAdd</code>).</p> <p>C\u01a1 ch\u1ebf: M\u1ed9t atomic operation l\u00e0 \u0111\u01a1n v\u1ecb \"kh\u00f4ng th\u1ec3 chia\". Ph\u1ea7n c\u1ee9ng \u0111\u1ea3m b\u1ea3o r\u1eb1ng trong khi m\u1ed9t lu\u1ed3ng \u0111ang th\u1ef1c hi\u1ec7n read-modify-write tr\u00ean m\u1ed9t \u0111\u1ecba ch\u1ec9 b\u1ed9 nh\u1edb, kh\u00f4ng c\u00f3 lu\u1ed3ng n\u00e0o kh\u00e1c c\u00f3 th\u1ec3 truy c\u1eadp \u0111\u1ecba ch\u1ec9 \u0111\u00f3.</p> <p>\u0110\u00e1nh \u0111\u1ed5i: Atomic \u0111\u1ea3m b\u1ea3o t\u00ednh \u0111\u00fang \u0111\u1eafn nh\u01b0ng bu\u1ed9c c\u00e1c lu\u1ed3ng ph\u1ea3i ch\u1edd \u0111\u1ee3i (tu\u1ea7n t\u1ef1 h\u00f3a), c\u00f3 th\u1ec3 ph\u00e1 h\u1ee7y hi\u1ec7u n\u0103ng song song.</p>"},{"location":"cuda/pmpp/chapter-09/#vi-latency","title":"9.3 \u0110\u1ed9 tr\u1ec5 v\u00e0 Th\u00f4ng l\u01b0\u1ee3ng c\u1ee7a Atomic Operations","text":"<p>N\u00fat th\u1eaft c\u1ed5 chai: Th\u1ef1c hi\u1ec7n atomic trong Global Memory r\u1ea5t ch\u1eadm. Th\u00f4ng l\u01b0\u1ee3ng b\u1ecb gi\u1edbi h\u1ea1n b\u1edfi \u0111\u1ed9 tr\u1ec5 cao c\u1ee7a DRAM (h\u00e0ng tr\u0103m chu k\u1ef3 \u0111\u1ed3ng h\u1ed3).</p> <p>Tranh ch\u1ea5p: N\u1ebfu d\u1eef li\u1ec7u b\u1ecb thi\u00ean l\u1ec7ch (v\u00ed d\u1ee5: \u1ea3nh b\u1ea7u tr\u1eddi xanh n\u01a1i h\u1ea7u h\u1ebft c\u00e1c pixel r\u01a1i v\u00e0o c\u00f9ng m\u1ed9t bin \"xanh\"), h\u00e0ng ngh\u00ecn lu\u1ed3ng s\u1ebd x\u1ebfp h\u00e0ng cho m\u1ed9t v\u1ecb tr\u00ed b\u1ed9 nh\u1edb, g\u00e2y ra s\u1ee5t gi\u1ea3m hi\u1ec7u n\u0103ng l\u1edbn.</p> <p>L2 Cache Atomics: GPU hi\u1ec7n \u0111\u1ea1i c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n atomic trong L2 cache, nhanh h\u01a1n nhi\u1ec1u so v\u1edbi DRAM nh\u01b0ng v\u1eabn b\u1ecb \u1ea3nh h\u01b0\u1edfng khi tranh ch\u1ea5p cao.</p>"},{"location":"cuda/pmpp/chapter-09/#vi-privatization","title":"9.4 Privatization","text":"<p>Chi\u1ebfn l\u01b0\u1ee3c: \u0110\u1ec3 gi\u1ea3m tranh ch\u1ea5p, cung c\u1ea5p cho m\u1ed7i thread block b\u1ea3n sao ri\u00eang c\u1ee7a histogram trong Shared Memory.</p> <p>Quy tr\u00ecnh:</p> <ol> <li>Giai \u0111o\u1ea1n c\u1ee5c b\u1ed9: M\u1ed7i block t\u1ea1o \"sub-histogram\" trong shared memory nhanh. C\u00e1c lu\u1ed3ng th\u1ef1c hi\u1ec7n atomic c\u1ee5c b\u1ed9.</li> <li>Giai \u0111o\u1ea1n to\u00e0n c\u1ee5c: Khi block ho\u00e0n th\u00e0nh d\u1eef li\u1ec7u c\u1ee7a n\u00f3, n\u00f3 \"commit\" k\u1ebft qu\u1ea3 ri\u00eang v\u00e0o histogram global cu\u1ed1i c\u00f9ng b\u1eb1ng t\u1eadp h\u1ee3p atomic operation th\u1ee9 hai.</li> </ol> <p>L\u1ee3i \u00edch: Tranh ch\u1ea5p \u0111\u01b0\u1ee3c gi\u1ea3m theo h\u1ec7 s\u1ed1 b\u1eb1ng s\u1ed1 l\u01b0\u1ee3ng block, v\u00e0 shared memory atomic nhanh h\u01a1n \u0111\u00e1ng k\u1ec3 so v\u1edbi global memory.</p>"},{"location":"cuda/pmpp/chapter-09/#vi-coarsening","title":"9.5 Coarsening","text":"<p>Ph\u00e2n v\u00f9ng xen k\u1ebd: \u0110\u1ec3 gi\u1eef truy c\u1eadp b\u1ed9 nh\u1edb global hi\u1ec7u qu\u1ea3 (Coalesced), c\u00e1c lu\u1ed3ng th\u00f4 kh\u00f4ng n\u00ean l\u1ea5y \"kh\u1ed1i li\u1ec1n k\u1ec1 l\u1edbn\" c\u1ee7a d\u1eef li\u1ec7u. Thay v\u00e0o \u0111\u00f3, ch\u00fang n\u00ean s\u1eed d\u1ee5ng c\u00e1ch ti\u1ebfp c\u1eadn xen k\u1ebd n\u01a1i c\u00e1c lu\u1ed3ng x\u1eed l\u00fd c\u00e1c ph\u1ea7n t\u1eed li\u1ec1n k\u1ec1 \u1edf m\u1ed7i b\u01b0\u1edbc.</p> <p>Gi\u1ea3m chi ph\u00ed qu\u1ea3n l\u00fd: B\u1eb1ng c\u00e1ch \u0111\u1ec3 m\u1ed7i lu\u1ed3ng x\u1eed l\u00fd nhi\u1ec1u ph\u1ea7n t\u1eed, b\u1ea1n gi\u1ea3m t\u1ed5ng s\u1ed1 block c\u1ea7n thi\u1ebft, t\u1eeb \u0111\u00f3 gi\u1ea3m chi ph\u00ed h\u1ee3p nh\u1ea5t histogram ri\u00eang v\u00e0o b\u1ed9 nh\u1edb global.</p>"},{"location":"cuda/pmpp/chapter-09/#vi-aggregation","title":"9.6 Aggregation","text":"<p>T\u1ed1i \u01b0u h\u00f3a \"Streak\": N\u1ebfu t\u1eadp d\u1eef li\u1ec7u ch\u1ee9a chu\u1ed7i d\u00e0i c\u00f9ng m\u1ed9t gi\u00e1 tr\u1ecb (v\u00ed d\u1ee5: v\u00f9ng l\u1edbn pixel tr\u1eafng), lu\u1ed3ng c\u00f3 th\u1ec3 \u0111\u1ebfm c\u00e1c l\u1ea7n xu\u1ea5t hi\u1ec7n n\u00e0y trong register c\u1ee5c b\u1ed9 tr\u01b0\u1edbc.</p> <p>K\u1ebft qu\u1ea3: Thay v\u00ec g\u1ecdi <code>atomicAdd</code> 100 l\u1ea7n cho 100 pixel tr\u1eafng, lu\u1ed3ng g\u1ecdi n\u00f3 m\u1ed9t l\u1ea7n v\u1edbi gi\u00e1 tr\u1ecb 100. \u0110i\u1ec1u n\u00e0y gi\u1ea3m thi\u1ec3u th\u00eam tranh ch\u1ea5p ph\u1ea7n c\u1ee9ng.</p>"},{"location":"cuda/pmpp/chapter-09/#vi-summary","title":"9.7 T\u00f3m t\u1eaft t\u1ed1i \u01b0u h\u00f3a Histogram","text":"<ul> <li>Atomic: C\u1ea7n thi\u1ebft cho t\u00ednh \u0111\u00fang \u0111\u1eafn khi \"owner-computes\" kh\u00f4ng kh\u1ea3 thi.</li> <li>Privatization: K\u1ef9 thu\u1eadt ch\u00ednh \u0111\u1ec3 bi\u1ebfn n\u00fat th\u1eaft c\u1ed5 chai tu\u1ea7n t\u1ef1 to\u00e0n c\u1ee5c th\u00e0nh t\u00e1c v\u1ee5 song song ph\u00e2n t\u00e1n.</li> <li>Interleaved Partitioning: Quan tr\u1ecdng \u0111\u1ec3 duy tr\u00ec coalescing b\u1ed9 nh\u1edb khi m\u1ed9t lu\u1ed3ng x\u1eed l\u00fd nhi\u1ec1u \u0111i\u1ec3m d\u1eef li\u1ec7u.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 9 d\u1ea1y b\u1ea1n c\u00e1ch x\u1eed l\u00fd Xung \u0111\u1ed9t \u0111\u1ea7u ra. B\u00e0i h\u1ecdc l\u00e0 b\u1ea1n n\u00ean lu\u00f4n c\u1ed1 g\u1eafng di chuy\u1ec3n tranh ch\u1ea5p t\u1eeb b\u1ed9 nh\u1edb global ch\u1eadm sang shared memory nhanh (Privatization) v\u00e0 h\u1ee3p nh\u1ea5t c\u1eadp nh\u1eadt b\u1ea5t c\u1ee9 khi n\u00e0o c\u00f3 th\u1ec3 (Aggregation) \u0111\u1ec3 gi\u1eef t\u1ef7 l\u1ec7 \"to\u00e1n-b\u1ed9 nh\u1edb\" cao.</p>"},{"location":"cuda/pmpp/chapter-10/","title":"Chapter 10: Reduction","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This is a newly added chapter in the 4<sup>th</sup> Edition. It focuses on the \"Reduction\" pattern\u2014taking an array of values and condensing them into a single result (e.g., sum, max, min)\u2014to teach the critical skill of minimizing thread and memory divergence.</p> <p>\u0110\u00e2y l\u00e0 ch\u01b0\u01a1ng m\u1edbi \u0111\u01b0\u1ee3c th\u00eam v\u00e0o \u1ea4n b\u1ea3n th\u1ee9 4. N\u00f3 t\u1eadp trung v\u00e0o m\u1eabu \"Reduction\"\u2014l\u1ea5y m\u1ed9t m\u1ea3ng gi\u00e1 tr\u1ecb v\u00e0 r\u00fat g\u1ecdn ch\u00fang th\u00e0nh m\u1ed9t k\u1ebft qu\u1ea3 duy nh\u1ea5t (v\u00ed d\u1ee5: t\u1ed5ng, max, min)\u2014\u0111\u1ec3 d\u1ea1y k\u1ef9 n\u0103ng quan tr\u1ecdng v\u1ec1 gi\u1ea3m thi\u1ec3u ph\u00e2n k\u1ef3 lu\u1ed3ng v\u00e0 b\u1ed9 nh\u1edb.</p>"},{"location":"cuda/pmpp/chapter-10/#en-background","title":"10.1 Background","text":"<p>Definition: A reduction derives a single value from an array using a binary associative operator (like \\(+\\) or \\(\\times\\)).</p> <p>Identity Values: Every operator needs an identity value (e.g., \\(0.0\\) for addition, \\(1.0\\) for multiplication, \\(-\\infty\\) for Max).</p> <p>Sequential vs. Parallel: Sequential reduction is \\(O(N)\\). Parallel reduction aims to reduce this to \\(O(\\log N)\\) steps using a tree structure.</p>"},{"location":"cuda/pmpp/chapter-10/#en-trees","title":"10.2 Reduction Trees","text":"<p>The Structure: Threads are organized into a \"tree\" where pairs of elements are summed in rounds.</p> <p>Mathematical Requirements:</p> <ul> <li>Associativity: \\((a+b)+c = a+(b+c)\\). This allows us to change the order of operations.</li> <li>Commutativity: \\(a+b = b+a\\). This allows us to rearrange the data for better hardware efficiency.</li> </ul> <p>Complexity: While the number of steps is low (\\(O(\\log N)\\)), the hardware must handle a massive drop in parallelism as the tree reaches the top (half the threads drop out every round).</p>"},{"location":"cuda/pmpp/chapter-10/#en-simple","title":"10.3 A Simple Reduction Kernel","text":"<p>Implementation: An initial kernel where each thread adds two adjacent elements.</p> <p>Limitations: This basic version is limited to a single thread block, meaning it can only process up to 2048 elements (since a block has 1024 threads).</p>"},{"location":"cuda/pmpp/chapter-10/#en-convergent","title":"10.4 Minimizing Control Divergence (The \"Convergent\" Kernel)","text":"<p>The Problem: The \"simple\" kernel uses a modulo operator (<code>%</code>) and strided indexing. This causes threads in the same warp to take different paths (some active, some idle), leading to heavy Control Divergence and wasting up to 65% of hardware potential.</p> <p>The Optimization: The authors introduce a \"Convergent\" indexing strategy. By rearranging which threads do the work, they ensure that all active threads are packed into the same warps while idle threads are packed into separate warps. This effectively doubles the efficiency.</p>"},{"location":"cuda/pmpp/chapter-10/#en-memory-divergence","title":"10.5 Minimizing Memory Divergence","text":"<p>Coalescing: The convergent indexing not only fixes the <code>if-else</code> pathing but also ensures that threads in a warp access adjacent memory locations.</p> <p>Result: This results in 3.9x fewer global memory requests compared to the unoptimized version.</p>"},{"location":"cuda/pmpp/chapter-10/#en-shared","title":"10.6 Minimizing Global Memory Accesses","text":"<p>Shared Memory Strategy: Instead of writing partial sums back to slow global memory at every level of the tree, threads load data into Shared Memory and perform the entire tree reduction there.</p> <p>Efficiency: This reduces global memory traffic to a single load per element and one final write.</p>"},{"location":"cuda/pmpp/chapter-10/#en-hierarchical","title":"10.7 Hierarchical Reduction for Arbitrary Length","text":"<p>The Scaling Problem: Single blocks cannot process millions of elements.</p> <p>Segmented Reduction: The input is divided into segments, each handled by a different block.</p> <p>Atomic Add: Each block computes its local sum and then uses <code>atomicAdd</code> to update a single global variable. This allows the pattern to scale to datasets of any size.</p>"},{"location":"cuda/pmpp/chapter-10/#en-coarsening","title":"10.8 Thread Coarsening for Reduced Overhead","text":"<p>The Strategy: Before starting the reduction tree, each thread sequentially sums a \"chunk\" of elements (e.g., 4 or 8 elements).</p> <p>Benefit: This reduces the total number of blocks and the amount of expensive synchronization (<code>__syncthreads</code>) required. It makes the kernel much more \"work-efficient\" and closer to the sequential speed for the initial phase.</p> <p>Key Takeaway: Chapter 10 is a masterclass in hardware-aware algorithm design. It teaches you that the order in which you process data (the tree structure) matters less for the math, but matters enormously for the hardware. By ensuring active threads stay together (Convergent indexing), you maximize the GPU's throughput.</p>"},{"location":"cuda/pmpp/chapter-10/#vi-background","title":"10.1 B\u1ed1i c\u1ea3nh","text":"<p>\u0110\u1ecbnh ngh\u0129a: Reduction t\u1ea1o ra m\u1ed9t gi\u00e1 tr\u1ecb duy nh\u1ea5t t\u1eeb m\u1ea3ng b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng to\u00e1n t\u1eed k\u1ebft h\u1ee3p nh\u1ecb ph\u00e2n (nh\u01b0 \\(+\\) ho\u1eb7c \\(\\times\\)).</p> <p>Gi\u00e1 tr\u1ecb \u0111\u01a1n v\u1ecb: M\u1ed7i to\u00e1n t\u1eed c\u1ea7n m\u1ed9t gi\u00e1 tr\u1ecb \u0111\u01a1n v\u1ecb (v\u00ed d\u1ee5: \\(0.0\\) cho ph\u00e9p c\u1ed9ng, \\(1.0\\) cho ph\u00e9p nh\u00e2n, \\(-\\infty\\) cho Max).</p> <p>Tu\u1ea7n t\u1ef1 vs. Song song: Reduction tu\u1ea7n t\u1ef1 l\u00e0 \\(O(N)\\). Reduction song song nh\u1eb1m gi\u1ea3m xu\u1ed1ng \\(O(\\log N)\\) b\u01b0\u1edbc b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng c\u1ea5u tr\u00fac c\u00e2y.</p>"},{"location":"cuda/pmpp/chapter-10/#vi-trees","title":"10.2 C\u00e2y Reduction","text":"<p>C\u1ea5u tr\u00fac: C\u00e1c lu\u1ed3ng \u0111\u01b0\u1ee3c t\u1ed5 ch\u1ee9c th\u00e0nh \"c\u00e2y\" n\u01a1i c\u00e1c c\u1eb7p ph\u1ea7n t\u1eed \u0111\u01b0\u1ee3c c\u1ed9ng trong c\u00e1c v\u00f2ng.</p> <p>Y\u00eau c\u1ea7u to\u00e1n h\u1ecdc:</p> <ul> <li>T\u00ednh k\u1ebft h\u1ee3p: \\((a+b)+c = a+(b+c)\\). \u0110i\u1ec1u n\u00e0y cho ph\u00e9p ch\u00fang ta thay \u0111\u1ed5i th\u1ee9 t\u1ef1 c\u00e1c ph\u00e9p to\u00e1n.</li> <li>T\u00ednh giao ho\u00e1n: \\(a+b = b+a\\). \u0110i\u1ec1u n\u00e0y cho ph\u00e9p ch\u00fang ta s\u1eafp x\u1ebfp l\u1ea1i d\u1eef li\u1ec7u \u0111\u1ec3 c\u00f3 hi\u1ec7u qu\u1ea3 ph\u1ea7n c\u1ee9ng t\u1ed1t h\u01a1n.</li> </ul> <p>\u0110\u1ed9 ph\u1ee9c t\u1ea1p: Trong khi s\u1ed1 b\u01b0\u1edbc th\u1ea5p (\\(O(\\log N)\\)), ph\u1ea7n c\u1ee9ng ph\u1ea3i x\u1eed l\u00fd s\u1ef1 s\u1ee5t gi\u1ea3m l\u1edbn v\u1ec1 t\u00ednh song song khi c\u00e2y \u0111\u1ea1t \u0111\u1ebfn \u0111\u1ec9nh (m\u1ed9t n\u1eeda s\u1ed1 lu\u1ed3ng r\u01a1i ra m\u1ed7i v\u00f2ng).</p>"},{"location":"cuda/pmpp/chapter-10/#vi-simple","title":"10.3 Kernel Reduction \u0111\u01a1n gi\u1ea3n","text":"<p>Tri\u1ec3n khai: Kernel ban \u0111\u1ea7u n\u01a1i m\u1ed7i lu\u1ed3ng c\u1ed9ng hai ph\u1ea7n t\u1eed li\u1ec1n k\u1ec1.</p> <p>Gi\u1edbi h\u1ea1n: Phi\u00ean b\u1ea3n c\u01a1 b\u1ea3n n\u00e0y b\u1ecb gi\u1edbi h\u1ea1n \u1edf m\u1ed9t thread block duy nh\u1ea5t, ngh\u0129a l\u00e0 n\u00f3 ch\u1ec9 c\u00f3 th\u1ec3 x\u1eed l\u00fd t\u1ed1i \u0111a 2048 ph\u1ea7n t\u1eed (v\u00ec m\u1ed9t block c\u00f3 1024 lu\u1ed3ng).</p>"},{"location":"cuda/pmpp/chapter-10/#vi-convergent","title":"10.4 Gi\u1ea3m thi\u1ec3u ph\u00e2n k\u1ef3 \u0111i\u1ec1u khi\u1ec3n (Kernel \"Convergent\")","text":"<p>V\u1ea5n \u0111\u1ec1: Kernel \"\u0111\u01a1n gi\u1ea3n\" s\u1eed d\u1ee5ng to\u00e1n t\u1eed modulo (<code>%</code>) v\u00e0 ch\u1ec9 s\u1ed1 b\u01b0\u1edbc nh\u1ea3y. \u0110i\u1ec1u n\u00e0y khi\u1ebfn c\u00e1c lu\u1ed3ng trong c\u00f9ng m\u1ed9t warp \u0111i theo c\u00e1c \u0111\u01b0\u1eddng kh\u00e1c nhau (m\u1ed9t s\u1ed1 ho\u1ea1t \u0111\u1ed9ng, m\u1ed9t s\u1ed1 nh\u00e0n r\u1ed7i), d\u1eabn \u0111\u1ebfn Ph\u00e2n k\u1ef3 \u0111i\u1ec1u khi\u1ec3n n\u1eb7ng v\u00e0 l\u00e3ng ph\u00ed t\u1edbi 65% ti\u1ec1m n\u0103ng ph\u1ea7n c\u1ee9ng.</p> <p>T\u1ed1i \u01b0u h\u00f3a: C\u00e1c t\u00e1c gi\u1ea3 gi\u1edbi thi\u1ec7u chi\u1ebfn l\u01b0\u1ee3c ch\u1ec9 s\u1ed1 \"Convergent\". B\u1eb1ng c\u00e1ch s\u1eafp x\u1ebfp l\u1ea1i lu\u1ed3ng n\u00e0o l\u00e0m vi\u1ec7c, h\u1ecd \u0111\u1ea3m b\u1ea3o r\u1eb1ng t\u1ea5t c\u1ea3 c\u00e1c lu\u1ed3ng ho\u1ea1t \u0111\u1ed9ng \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i v\u00e0o c\u00f9ng c\u00e1c warp trong khi c\u00e1c lu\u1ed3ng nh\u00e0n r\u1ed7i \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i v\u00e0o c\u00e1c warp ri\u00eang bi\u1ec7t. \u0110i\u1ec1u n\u00e0y t\u0103ng g\u1ea5p \u0111\u00f4i hi\u1ec7u qu\u1ea3.</p>"},{"location":"cuda/pmpp/chapter-10/#vi-memory-divergence","title":"10.5 Gi\u1ea3m thi\u1ec3u ph\u00e2n k\u1ef3 b\u1ed9 nh\u1edb","text":"<p>Coalescing: Ch\u1ec9 s\u1ed1 convergent kh\u00f4ng ch\u1ec9 s\u1eeda \u0111\u01b0\u1eddng d\u1eabn <code>if-else</code> m\u00e0 c\u00f2n \u0111\u1ea3m b\u1ea3o r\u1eb1ng c\u00e1c lu\u1ed3ng trong warp truy c\u1eadp c\u00e1c v\u1ecb tr\u00ed b\u1ed9 nh\u1edb li\u1ec1n k\u1ec1.</p> <p>K\u1ebft qu\u1ea3: \u0110i\u1ec1u n\u00e0y d\u1eabn \u0111\u1ebfn \u00edt h\u01a1n 3.9 l\u1ea7n y\u00eau c\u1ea7u b\u1ed9 nh\u1edb global so v\u1edbi phi\u00ean b\u1ea3n ch\u01b0a t\u1ed1i \u01b0u.</p>"},{"location":"cuda/pmpp/chapter-10/#vi-shared","title":"10.6 Gi\u1ea3m thi\u1ec3u truy c\u1eadp b\u1ed9 nh\u1edb Global","text":"<p>Chi\u1ebfn l\u01b0\u1ee3c Shared Memory: Thay v\u00ec ghi t\u1ed5ng m\u1ed9t ph\u1ea7n tr\u1edf l\u1ea1i b\u1ed9 nh\u1edb global ch\u1eadm \u1edf m\u1ecdi c\u1ea5p c\u1ee7a c\u00e2y, c\u00e1c lu\u1ed3ng t\u1ea3i d\u1eef li\u1ec7u v\u00e0o Shared Memory v\u00e0 th\u1ef1c hi\u1ec7n to\u00e0n b\u1ed9 reduction c\u00e2y \u1edf \u0111\u00f3.</p> <p>Hi\u1ec7u qu\u1ea3: \u0110i\u1ec1u n\u00e0y gi\u1ea3m l\u01b0u l\u01b0\u1ee3ng b\u1ed9 nh\u1edb global xu\u1ed1ng m\u1ed9t l\u1ea7n t\u1ea3i m\u1ed7i ph\u1ea7n t\u1eed v\u00e0 m\u1ed9t l\u1ea7n ghi cu\u1ed1i c\u00f9ng.</p>"},{"location":"cuda/pmpp/chapter-10/#vi-hierarchical","title":"10.7 Reduction ph\u00e2n c\u1ea5p cho \u0111\u1ed9 d\u00e0i t\u00f9y \u00fd","text":"<p>V\u1ea5n \u0111\u1ec1 m\u1edf r\u1ed9ng: Block \u0111\u01a1n l\u1ebb kh\u00f4ng th\u1ec3 x\u1eed l\u00fd h\u00e0ng tri\u1ec7u ph\u1ea7n t\u1eed.</p> <p>Reduction ph\u00e2n \u0111o\u1ea1n: \u0110\u1ea7u v\u00e0o \u0111\u01b0\u1ee3c chia th\u00e0nh c\u00e1c \u0111o\u1ea1n, m\u1ed7i \u0111o\u1ea1n \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi m\u1ed9t block kh\u00e1c nhau.</p> <p>Atomic Add: M\u1ed7i block t\u00ednh t\u1ed5ng c\u1ee5c b\u1ed9 c\u1ee7a n\u00f3 v\u00e0 sau \u0111\u00f3 s\u1eed d\u1ee5ng <code>atomicAdd</code> \u0111\u1ec3 c\u1eadp nh\u1eadt m\u1ed9t bi\u1ebfn global duy nh\u1ea5t. \u0110i\u1ec1u n\u00e0y cho ph\u00e9p m\u1eabu m\u1edf r\u1ed9ng \u0111\u1ebfn t\u1eadp d\u1eef li\u1ec7u c\u00f3 k\u00edch th\u01b0\u1edbc b\u1ea5t k\u1ef3.</p>"},{"location":"cuda/pmpp/chapter-10/#vi-coarsening","title":"10.8 Thread Coarsening \u0111\u1ec3 gi\u1ea3m chi ph\u00ed qu\u1ea3n l\u00fd","text":"<p>Chi\u1ebfn l\u01b0\u1ee3c: Tr\u01b0\u1edbc khi b\u1eaft \u0111\u1ea7u c\u00e2y reduction, m\u1ed7i lu\u1ed3ng tu\u1ea7n t\u1ef1 c\u1ed9ng m\u1ed9t \"kh\u1ed1i\" c\u00e1c ph\u1ea7n t\u1eed (v\u00ed d\u1ee5: 4 ho\u1eb7c 8 ph\u1ea7n t\u1eed).</p> <p>L\u1ee3i \u00edch: \u0110i\u1ec1u n\u00e0y gi\u1ea3m t\u1ed5ng s\u1ed1 block v\u00e0 l\u01b0\u1ee3ng \u0111\u1ed3ng b\u1ed9 h\u00f3a \u0111\u1eaft ti\u1ec1n (<code>__syncthreads</code>) c\u1ea7n thi\u1ebft. N\u00f3 l\u00e0m cho kernel \"hi\u1ec7u qu\u1ea3 c\u00f4ng vi\u1ec7c\" h\u01a1n nhi\u1ec1u v\u00e0 g\u1ea7n h\u01a1n v\u1edbi t\u1ed1c \u0111\u1ed9 tu\u1ea7n t\u1ef1 cho giai \u0111o\u1ea1n \u0111\u1ea7u.</p> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 10 l\u00e0 m\u1ed9t l\u1edbp h\u1ecdc chuy\u00ean s\u00e2u v\u1ec1 thi\u1ebft k\u1ebf thu\u1eadt to\u00e1n nh\u1eadn th\u1ee9c ph\u1ea7n c\u1ee9ng. N\u00f3 d\u1ea1y b\u1ea1n r\u1eb1ng th\u1ee9 t\u1ef1 m\u00e0 b\u1ea1n x\u1eed l\u00fd d\u1eef li\u1ec7u (c\u1ea5u tr\u00fac c\u00e2y) \u00edt quan tr\u1ecdng h\u01a1n cho to\u00e1n h\u1ecdc, nh\u01b0ng quan tr\u1ecdng c\u1ef1c k\u1ef3 cho ph\u1ea7n c\u1ee9ng. B\u1eb1ng c\u00e1ch \u0111\u1ea3m b\u1ea3o c\u00e1c lu\u1ed3ng ho\u1ea1t \u0111\u1ed9ng \u1edf c\u00f9ng nhau (Ch\u1ec9 s\u1ed1 convergent), b\u1ea1n t\u1ed1i \u0111a h\u00f3a th\u00f4ng l\u01b0\u1ee3ng c\u1ee7a GPU.</p>"},{"location":"cuda/pmpp/chapter-11/","title":"Chapter 11: Prefix Sum (Parallel Scan)","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter explores one of the most powerful parallel primitives. Scan is used to parallelize problems that appear to be purely sequential (recursions), such as resource allocation, polynomial evaluation, and sorting.</p> <p>Ch\u01b0\u01a1ng n\u00e0y kh\u00e1m ph\u00e1 m\u1ed9t trong nh\u1eefng nguy\u00ean th\u1ee7y song song m\u1ea1nh m\u1ebd nh\u1ea5t. Scan \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 song song h\u00f3a c\u00e1c b\u00e0i to\u00e1n c\u00f3 v\u1ebb ho\u00e0n to\u00e0n tu\u1ea7n t\u1ef1 (\u0111\u1ec7 quy), ch\u1eb3ng h\u1ea1n nh\u01b0 ph\u00e2n b\u1ed5 t\u00e0i nguy\u00ean, \u0111\u00e1nh gi\u00e1 \u0111a th\u1ee9c v\u00e0 s\u1eafp x\u1ebfp.</p>"},{"location":"cuda/pmpp/chapter-11/#en-background","title":"11.1 Background","text":"<p>Definition: Given an input \\([x_0, x_1, x_2, ...]\\), scan produces an output where each element is the sum of all preceding elements.</p> <p>Inclusive Scan: The \\(i\\)-th output includes \\(x_i\\) (e.g., \\([x_0, x_0+x_1, x_0+x_1+x_2, ...]\\)).</p> <p>Exclusive Scan: The \\(i\\)-th output excludes \\(x_i\\) and starts with an identity value (0) (e.g., \\([0, x_0, x_0+x_1, ...]\\)).</p> <p>Sequential Complexity: \\(O(N)\\). It is very efficient on a CPU but entirely serial.</p>"},{"location":"cuda/pmpp/chapter-11/#en-kogge-stone","title":"11.2 Parallel Scan: The Kogge-Stone Algorithm","text":"<p>The Concept: An in-place algorithm that doubles the range of the sum in each step. After step \\(k\\), each position contains the sum of \\(2^k\\) elements.</p> <p>Steps: Completes in \\(\\log_2 N\\) steps.</p> <p>The Race Condition (Write-After-Read): A major hardware hurdle. Because threads read from and write to the same array, a thread might read a value that was already updated by another thread in the current step, leading to wrong results.</p> <p>The Fix:</p> <ol> <li>Use a temporary variable (register) and an extra <code>__syncthreads()</code>.</li> <li>Use Double Buffering: Alternate between two different shared memory arrays in each iteration.</li> </ol>"},{"location":"cuda/pmpp/chapter-11/#en-work-efficiency","title":"11.3 Work Efficiency Consideration","text":"<p>The Downside of Kogge-Stone: It performs \\(O(N \\log N)\\) operations.</p> <p>Comparison: For 1,024 elements, a CPU does ~1,000 additions. Kogge-Stone does ~10,000.</p> <p>Conclusion: Kogge-Stone is not work-efficient. It is fast only if you have a massive surplus of execution units to \"waste\" on redundant additions.</p>"},{"location":"cuda/pmpp/chapter-11/#en-brent-kung","title":"11.4 Parallel Scan: The Brent-Kung Algorithm","text":"<p>The Goal: Achieve \\(O(N)\\) complexity to match the CPU's efficiency.</p> <p>The Two-Phase Approach:</p> <ol> <li>Reduction Phase (Up-sweep): Builds a reduction tree to calculate the total sum of the block.</li> <li>Distribution Phase (Down-sweep): Uses the partial sums from the tree to fill in the missing prefix sums for all other elements.</li> </ol> <p>Efficiency: It performs roughly \\(2N\\) operations. It is work-efficient and consumes less energy/bandwidth than Kogge-Stone, though it takes more steps (\\(2 \\log N\\)).</p>"},{"location":"cuda/pmpp/chapter-11/#en-coarsening","title":"11.5 Coarsening for Even More Efficiency","text":"<p>The Strategy: Each thread handles a segment of the data (e.g., 4 or 8 elements) sequentially first.</p> <p>Three-Phase Process:</p> <ol> <li>Local sequential scan of the segments.</li> <li>Parallel scan of the \"tails\" (last elements) of each segment.</li> <li>Local update to add the results back to the internal elements.</li> </ol> <p>Result: Drastically reduces the number of threads and synchronization points required.</p>"},{"location":"cuda/pmpp/chapter-11/#en-segmented","title":"11.6 Segmented Scan for Arbitrary Length","text":"<p>The Problem: Hardware limits block sizes to 1,024 threads.</p> <p>The Hierarchical Solution:</p> <ol> <li>Scan sections of the data independently.</li> <li>Write the \"last\" element of each section to an auxiliary array.</li> <li>Scan the auxiliary array.</li> <li>Add the scanned values back to the corresponding sections.</li> </ol>"},{"location":"cuda/pmpp/chapter-11/#en-domino","title":"11.7 Single-Pass Scan (Domino Scan)","text":"<p>The Advanced Optimization: Avoids multiple kernel launches by passing values between blocks while the kernel is still running.</p> <p>Adjacent Synchronization: Blocks use \"flags\" and atomic operations in global memory to signal to the \"next\" block that their partial sum is ready.</p> <p>Deadlock Prevention: Uses Dynamic Block Indexing to ensure that blocks are processed in the correct order, as the default hardware scheduler does not guarantee linear execution.</p> <p>Key Takeaway: Chapter 11 teaches that parallelizing a sequential recursion requires a fundamental change in the algorithm. You must choose between Kogge-Stone (fast but wasteful) and Brent-Kung (work-efficient) and use Hierarchical or Domino strategies to scale to real-world data sizes.</p>"},{"location":"cuda/pmpp/chapter-11/#vi-background","title":"11.1 B\u1ed1i c\u1ea3nh","text":"<p>\u0110\u1ecbnh ngh\u0129a: Cho \u0111\u1ea7u v\u00e0o \\([x_0, x_1, x_2, ...]\\), scan t\u1ea1o ra \u0111\u1ea7u ra trong \u0111\u00f3 m\u1ed7i ph\u1ea7n t\u1eed l\u00e0 t\u1ed5ng c\u1ee7a t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n t\u1eed tr\u01b0\u1edbc \u0111\u00f3.</p> <p>Inclusive Scan: \u0110\u1ea7u ra th\u1ee9 \\(i\\) bao g\u1ed3m \\(x_i\\) (v\u00ed d\u1ee5: \\([x_0, x_0+x_1, x_0+x_1+x_2, ...]\\)).</p> <p>Exclusive Scan: \u0110\u1ea7u ra th\u1ee9 \\(i\\) lo\u1ea1i tr\u1eeb \\(x_i\\) v\u00e0 b\u1eaft \u0111\u1ea7u b\u1eb1ng gi\u00e1 tr\u1ecb \u0111\u01a1n v\u1ecb (0) (v\u00ed d\u1ee5: \\([0, x_0, x_0+x_1, ...]\\)).</p> <p>\u0110\u1ed9 ph\u1ee9c t\u1ea1p tu\u1ea7n t\u1ef1: \\(O(N)\\). R\u1ea5t hi\u1ec7u qu\u1ea3 tr\u00ean CPU nh\u01b0ng ho\u00e0n to\u00e0n tu\u1ea7n t\u1ef1.</p>"},{"location":"cuda/pmpp/chapter-11/#vi-kogge-stone","title":"11.2 Scan song song: Thu\u1eadt to\u00e1n Kogge-Stone","text":"<p>Kh\u00e1i ni\u1ec7m: Thu\u1eadt to\u00e1n t\u1ea1i ch\u1ed7 t\u0103ng g\u1ea5p \u0111\u00f4i ph\u1ea1m vi t\u1ed5ng \u1edf m\u1ed7i b\u01b0\u1edbc. Sau b\u01b0\u1edbc \\(k\\), m\u1ed7i v\u1ecb tr\u00ed ch\u1ee9a t\u1ed5ng c\u1ee7a \\(2^k\\) ph\u1ea7n t\u1eed.</p> <p>C\u00e1c b\u01b0\u1edbc: Ho\u00e0n th\u00e0nh trong \\(\\log_2 N\\) b\u01b0\u1edbc.</p> <p>\u0110i\u1ec1u ki\u1ec7n tranh ch\u1ea5p (Write-After-Read): R\u00e0o c\u1ea3n ph\u1ea7n c\u1ee9ng l\u1edbn. V\u00ec c\u00e1c lu\u1ed3ng \u0111\u1ecdc v\u00e0 ghi v\u00e0o c\u00f9ng m\u1ed9t m\u1ea3ng, m\u1ed9t lu\u1ed3ng c\u00f3 th\u1ec3 \u0111\u1ecdc gi\u00e1 tr\u1ecb \u0111\u00e3 \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt b\u1edfi lu\u1ed3ng kh\u00e1c trong b\u01b0\u1edbc hi\u1ec7n t\u1ea1i, d\u1eabn \u0111\u1ebfn k\u1ebft qu\u1ea3 sai.</p> <p>Gi\u1ea3i ph\u00e1p:</p> <ol> <li>S\u1eed d\u1ee5ng bi\u1ebfn t\u1ea1m th\u1eddi (register) v\u00e0 th\u00eam <code>__syncthreads()</code>.</li> <li>S\u1eed d\u1ee5ng Double Buffering: Xen k\u1ebd gi\u1eefa hai m\u1ea3ng shared memory kh\u00e1c nhau trong m\u1ed7i l\u1ea7n l\u1eb7p.</li> </ol>"},{"location":"cuda/pmpp/chapter-11/#vi-work-efficiency","title":"11.3 C\u00e2n nh\u1eafc hi\u1ec7u qu\u1ea3 c\u00f4ng vi\u1ec7c","text":"<p>Nh\u01b0\u1ee3c \u0111i\u1ec3m c\u1ee7a Kogge-Stone: N\u00f3 th\u1ef1c hi\u1ec7n \\(O(N \\log N)\\) ph\u00e9p to\u00e1n.</p> <p>So s\u00e1nh: V\u1edbi 1,024 ph\u1ea7n t\u1eed, CPU th\u1ef1c hi\u1ec7n ~1,000 ph\u00e9p c\u1ed9ng. Kogge-Stone th\u1ef1c hi\u1ec7n ~10,000.</p> <p>K\u1ebft lu\u1eadn: Kogge-Stone kh\u00f4ng hi\u1ec7u qu\u1ea3 c\u00f4ng vi\u1ec7c. N\u00f3 ch\u1ec9 nhanh n\u1ebfu b\u1ea1n c\u00f3 th\u1eeba l\u1edbn c\u00e1c \u0111\u01a1n v\u1ecb th\u1ef1c thi \u0111\u1ec3 \"l\u00e3ng ph\u00ed\" v\u00e0o c\u00e1c ph\u00e9p c\u1ed9ng d\u01b0 th\u1eeba.</p>"},{"location":"cuda/pmpp/chapter-11/#vi-brent-kung","title":"11.4 Scan song song: Thu\u1eadt to\u00e1n Brent-Kung","text":"<p>M\u1ee5c ti\u00eau: \u0110\u1ea1t \u0111\u01b0\u1ee3c \u0111\u1ed9 ph\u1ee9c t\u1ea1p \\(O(N)\\) \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi hi\u1ec7u qu\u1ea3 c\u1ee7a CPU.</p> <p>C\u00e1ch ti\u1ebfp c\u1eadn hai giai \u0111o\u1ea1n:</p> <ol> <li>Giai \u0111o\u1ea1n Reduction (Up-sweep): X\u00e2y d\u1ef1ng c\u00e2y reduction \u0111\u1ec3 t\u00ednh t\u1ed5ng to\u00e0n b\u1ed9 c\u1ee7a block.</li> <li>Giai \u0111o\u1ea1n Distribution (Down-sweep): S\u1eed d\u1ee5ng c\u00e1c t\u1ed5ng m\u1ed9t ph\u1ea7n t\u1eeb c\u00e2y \u0111\u1ec3 \u0111i\u1ec1n c\u00e1c t\u1ed5ng ti\u1ec1n t\u1ed1 c\u00f2n thi\u1ebfu cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n t\u1eed kh\u00e1c.</li> </ol> <p>Hi\u1ec7u qu\u1ea3: N\u00f3 th\u1ef1c hi\u1ec7n kho\u1ea3ng \\(2N\\) ph\u00e9p to\u00e1n. N\u00f3 hi\u1ec7u qu\u1ea3 c\u00f4ng vi\u1ec7c v\u00e0 ti\u00eau th\u1ee5 \u00edt n\u0103ng l\u01b0\u1ee3ng/b\u0103ng th\u00f4ng h\u01a1n Kogge-Stone, m\u1eb7c d\u00f9 m\u1ea5t nhi\u1ec1u b\u01b0\u1edbc h\u01a1n (\\(2 \\log N\\)).</p>"},{"location":"cuda/pmpp/chapter-11/#vi-coarsening","title":"11.5 Coarsening \u0111\u1ec3 hi\u1ec7u qu\u1ea3 h\u01a1n n\u1eefa","text":"<p>Chi\u1ebfn l\u01b0\u1ee3c: M\u1ed7i lu\u1ed3ng x\u1eed l\u00fd m\u1ed9t \u0111o\u1ea1n d\u1eef li\u1ec7u (v\u00ed d\u1ee5: 4 ho\u1eb7c 8 ph\u1ea7n t\u1eed) tu\u1ea7n t\u1ef1 tr\u01b0\u1edbc.</p> <p>Quy tr\u00ecnh ba giai \u0111o\u1ea1n:</p> <ol> <li>Scan tu\u1ea7n t\u1ef1 c\u1ee5c b\u1ed9 c\u00e1c \u0111o\u1ea1n.</li> <li>Scan song song c\u00e1c \"\u0111u\u00f4i\" (ph\u1ea7n t\u1eed cu\u1ed1i) c\u1ee7a m\u1ed7i \u0111o\u1ea1n.</li> <li>C\u1eadp nh\u1eadt c\u1ee5c b\u1ed9 \u0111\u1ec3 th\u00eam k\u1ebft qu\u1ea3 tr\u1edf l\u1ea1i c\u00e1c ph\u1ea7n t\u1eed b\u00ean trong.</li> </ol> <p>K\u1ebft qu\u1ea3: Gi\u1ea3m \u0111\u00e1ng k\u1ec3 s\u1ed1 l\u01b0\u1ee3ng lu\u1ed3ng v\u00e0 \u0111i\u1ec3m \u0111\u1ed3ng b\u1ed9 h\u00f3a c\u1ea7n thi\u1ebft.</p>"},{"location":"cuda/pmpp/chapter-11/#vi-segmented","title":"11.6 Segmented Scan cho \u0111\u1ed9 d\u00e0i t\u00f9y \u00fd","text":"<p>V\u1ea5n \u0111\u1ec1: Ph\u1ea7n c\u1ee9ng gi\u1edbi h\u1ea1n k\u00edch th\u01b0\u1edbc block \u1edf 1,024 lu\u1ed3ng.</p> <p>Gi\u1ea3i ph\u00e1p ph\u00e2n c\u1ea5p:</p> <ol> <li>Scan c\u00e1c ph\u1ea7n c\u1ee7a d\u1eef li\u1ec7u \u0111\u1ed9c l\u1eadp.</li> <li>Ghi ph\u1ea7n t\u1eed \"cu\u1ed1i c\u00f9ng\" c\u1ee7a m\u1ed7i ph\u1ea7n v\u00e0o m\u1ea3ng ph\u1ee5.</li> <li>Scan m\u1ea3ng ph\u1ee5.</li> <li>Th\u00eam c\u00e1c gi\u00e1 tr\u1ecb \u0111\u00e3 scan tr\u1edf l\u1ea1i c\u00e1c ph\u1ea7n t\u01b0\u01a1ng \u1ee9ng.</li> </ol>"},{"location":"cuda/pmpp/chapter-11/#vi-domino","title":"11.7 Single-Pass Scan (Domino Scan)","text":"<p>T\u1ed1i \u01b0u h\u00f3a n\u00e2ng cao: Tr\u00e1nh nhi\u1ec1u l\u1ea7n kh\u1edfi ch\u1ea1y kernel b\u1eb1ng c\u00e1ch truy\u1ec1n gi\u00e1 tr\u1ecb gi\u1eefa c\u00e1c block trong khi kernel v\u1eabn \u0111ang ch\u1ea1y.</p> <p>\u0110\u1ed3ng b\u1ed9 h\u00f3a li\u1ec1n k\u1ec1: C\u00e1c block s\u1eed d\u1ee5ng \"c\u1edd\" v\u00e0 atomic operation trong global memory \u0111\u1ec3 b\u00e1o hi\u1ec7u cho block \"ti\u1ebfp theo\" r\u1eb1ng t\u1ed5ng m\u1ed9t ph\u1ea7n c\u1ee7a ch\u00fang \u0111\u00e3 s\u1eb5n s\u00e0ng.</p> <p>Ng\u0103n ch\u1eb7n Deadlock: S\u1eed d\u1ee5ng Dynamic Block Indexing \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o c\u00e1c block \u0111\u01b0\u1ee3c x\u1eed l\u00fd theo \u0111\u00fang th\u1ee9 t\u1ef1, v\u00ec b\u1ed9 l\u1eadp l\u1ecbch ph\u1ea7n c\u1ee9ng m\u1eb7c \u0111\u1ecbnh kh\u00f4ng \u0111\u1ea3m b\u1ea3o th\u1ef1c thi tuy\u1ebfn t\u00ednh.</p> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 11 d\u1ea1y r\u1eb1ng song song h\u00f3a \u0111\u1ec7 quy tu\u1ea7n t\u1ef1 y\u00eau c\u1ea7u thay \u0111\u1ed5i c\u01a1 b\u1ea3n trong thu\u1eadt to\u00e1n. B\u1ea1n ph\u1ea3i ch\u1ecdn gi\u1eefa Kogge-Stone (nhanh nh\u01b0ng l\u00e3ng ph\u00ed) v\u00e0 Brent-Kung (hi\u1ec7u qu\u1ea3 c\u00f4ng vi\u1ec7c) v\u00e0 s\u1eed d\u1ee5ng chi\u1ebfn l\u01b0\u1ee3c Ph\u00e2n c\u1ea5p ho\u1eb7c Domino \u0111\u1ec3 m\u1edf r\u1ed9ng \u0111\u1ebfn k\u00edch th\u01b0\u1edbc d\u1eef li\u1ec7u th\u1ef1c t\u1ebf.</p>"},{"location":"cuda/pmpp/chapter-12/","title":"Chapter 12: Parallel Merge","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter explores the Parallel Merge pattern, which is the foundation of many complex algorithms, including Parallel Merge Sort. It introduces the challenge of dynamic input identification\u2014where threads cannot know which data to process until they perform a search.</p> <p>Ch\u01b0\u01a1ng n\u00e0y kh\u00e1m ph\u00e1 m\u1eabu Parallel Merge, l\u00e0 n\u1ec1n t\u1ea3ng c\u1ee7a nhi\u1ec1u thu\u1eadt to\u00e1n ph\u1ee9c t\u1ea1p, bao g\u1ed3m Parallel Merge Sort. N\u00f3 gi\u1edbi thi\u1ec7u th\u00e1ch th\u1ee9c v\u1ec1 x\u00e1c \u0111\u1ecbnh \u0111\u1ea7u v\u00e0o \u0111\u1ed9ng\u2014n\u01a1i c\u00e1c lu\u1ed3ng kh\u00f4ng th\u1ec3 bi\u1ebft d\u1eef li\u1ec7u n\u00e0o c\u1ea7n x\u1eed l\u00fd cho \u0111\u1ebfn khi ch\u00fang th\u1ef1c hi\u1ec7n t\u00ecm ki\u1ebfm.</p>"},{"location":"cuda/pmpp/chapter-12/#en-background","title":"12.1 Background","text":"<p>Definition: An ordered merge takes two previously sorted lists (\\(A\\) and \\(B\\)) and combines them into a single sorted list (\\(C\\)).</p> <p>Stability: A \"stable\" merge ensures that if two elements have the same value, their relative order from the original lists is preserved.</p> <p>Importance: Merge is the core of the Merge Sort algorithm and is a critical component of modern MapReduce frameworks used in big data processing.</p>"},{"location":"cuda/pmpp/chapter-12/#en-sequential","title":"12.2 A Sequential Merge Algorithm","text":"<p>The Logic: A simple <code>while</code> loop compares the current head of list \\(A\\) with the current head of list \\(B\\), picking the smaller one and moving a pointer forward.</p> <p>Complexity: \\(O(m + n)\\), where \\(m\\) and \\(n\\) are the lengths of the lists. It is highly efficient for a single processor but entirely serial.</p>"},{"location":"cuda/pmpp/chapter-12/#en-parallelization","title":"12.3 A Parallelization Approach","text":"<p>The Strategy: Partition the output array (\\(C\\)) into equal-sized segments and assign each segment to a thread.</p> <p>The Problem: Because the lists are sorted but the values are unknown, a thread doesn't know where its assigned segment of \\(C\\) begins in the input lists \\(A\\) and \\(B\\).</p> <p>The Solution (Co-rank): Each thread must find its \"split points\" in the input arrays using a Co-rank function.</p>"},{"location":"cuda/pmpp/chapter-12/#en-co-rank","title":"12.4 Co-rank Function Implementation","text":"<p>The Concept: The co-rank function uses a Binary Search to find the unique \\(i\\) and \\(j\\) indices in arrays \\(A\\) and \\(B\\) that contribute to a specific position \\(k\\) in the output array \\(C\\).</p> <p>Logic: It searches for a point where \\(A[i-1] \\le B[j]\\) and \\(B[j-1] &lt; A[i]\\).</p> <p>Complexity: \\(O(\\log N)\\), where \\(N\\) is the length of the longer input list. This search is performed by every thread to determine its work boundaries.</p>"},{"location":"cuda/pmpp/chapter-12/#en-basic","title":"12.5 A Basic Parallel Merge Kernel","text":"<p>Execution: Each thread calls the co-rank function to find its starting and ending points in \\(A\\) and \\(B\\), then performs a standard sequential merge on those specific sub-segments.</p> <p>Bottleneck: This basic version suffers from uncoalesced memory accesses because threads in a warp are merging different data values at different speeds, jumping around the global memory.</p>"},{"location":"cuda/pmpp/chapter-12/#en-tiled","title":"12.6 A Tiled Merge Kernel to Improve Coalescing","text":"<p>The Optimization: Threads in a block collaborate to load tiles of \\(A\\) and \\(B\\) into Shared Memory.</p> <p>The Challenge: Unlike previous patterns, we don't know the \"A-to-B ratio\" for a tile. In the worst case, a tile's output might require only elements from \\(A\\) or only elements from \\(B\\).</p> <p>Handling Uncertainty: Each block must load a tile of \\(A\\) and a tile of \\(B\\). This ensures all necessary data is on-chip, but it results in only about 50% of the loaded data being used in each step.</p>"},{"location":"cuda/pmpp/chapter-12/#en-circular","title":"12.7 A Circular Buffer Merge Kernel","text":"<p>The Advanced Optimization: To fix the 50% data waste in standard tiling, the authors introduce a Circular Buffer in shared memory.</p> <p>Mechanism: Threads keep track of \"leftover\" elements in shared memory that weren't used in the previous phase. They only load enough new elements from global memory to refill the buffer.</p> <p>Payoff: This maximizes memory bandwidth utilization but significantly increases code complexity, requiring a \"simplified model\" for threads to index into the wrapped buffer.</p>"},{"location":"cuda/pmpp/chapter-12/#en-coarsening","title":"12.8 Thread Coarsening for Merge","text":"<p>Efficiency: The co-rank binary search is a high-overhead operation.</p> <p>The Strategy: By having each thread process more elements (coarsening), the \"cost\" of the binary search is amortized over a larger amount of work, improving the overall work efficiency of the kernel.</p> <p>Key Takeaway: Chapter 12 teaches you how to parallelize algorithms where workload boundaries are data-dependent. The core lesson is the Co-rank function, which uses binary search to let threads independently \"claim\" their portion of a global task, while Circular Buffers solve the unique memory efficiency problems created by this dynamic behavior.</p>"},{"location":"cuda/pmpp/chapter-12/#vi-background","title":"12.1 B\u1ed1i c\u1ea3nh","text":"<p>\u0110\u1ecbnh ngh\u0129a: M\u1ed9t ph\u00e9p h\u1ee3p nh\u1ea5t c\u00f3 th\u1ee9 t\u1ef1 l\u1ea5y hai danh s\u00e1ch \u0111\u00e3 \u0111\u01b0\u1ee3c s\u1eafp x\u1ebfp tr\u01b0\u1edbc \u0111\u00f3 (\\(A\\) v\u00e0 \\(B\\)) v\u00e0 k\u1ebft h\u1ee3p ch\u00fang th\u00e0nh m\u1ed9t danh s\u00e1ch s\u1eafp x\u1ebfp duy nh\u1ea5t (\\(C\\)).</p> <p>T\u00ednh \u1ed5n \u0111\u1ecbnh: H\u1ee3p nh\u1ea5t \"\u1ed5n \u0111\u1ecbnh\" \u0111\u1ea3m b\u1ea3o r\u1eb1ng n\u1ebfu hai ph\u1ea7n t\u1eed c\u00f3 c\u00f9ng gi\u00e1 tr\u1ecb, th\u1ee9 t\u1ef1 t\u01b0\u01a1ng \u0111\u1ed1i c\u1ee7a ch\u00fang t\u1eeb c\u00e1c danh s\u00e1ch ban \u0111\u1ea7u \u0111\u01b0\u1ee3c gi\u1eef nguy\u00ean.</p> <p>T\u1ea7m quan tr\u1ecdng: Merge l\u00e0 c\u1ed1t l\u00f5i c\u1ee7a thu\u1eadt to\u00e1n Merge Sort v\u00e0 l\u00e0 th\u00e0nh ph\u1ea7n quan tr\u1ecdng c\u1ee7a c\u00e1c khung MapReduce hi\u1ec7n \u0111\u1ea1i \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong x\u1eed l\u00fd d\u1eef li\u1ec7u l\u1edbn.</p>"},{"location":"cuda/pmpp/chapter-12/#vi-sequential","title":"12.2 Thu\u1eadt to\u00e1n h\u1ee3p nh\u1ea5t tu\u1ea7n t\u1ef1","text":"<p>Logic: V\u00f2ng l\u1eb7p <code>while</code> \u0111\u01a1n gi\u1ea3n so s\u00e1nh ph\u1ea7n \u0111\u1ea7u hi\u1ec7n t\u1ea1i c\u1ee7a danh s\u00e1ch \\(A\\) v\u1edbi ph\u1ea7n \u0111\u1ea7u hi\u1ec7n t\u1ea1i c\u1ee7a danh s\u00e1ch \\(B\\), ch\u1ecdn ph\u1ea7n t\u1eed nh\u1ecf h\u01a1n v\u00e0 di chuy\u1ec3n con tr\u1ecf v\u1ec1 ph\u00eda tr\u01b0\u1edbc.</p> <p>\u0110\u1ed9 ph\u1ee9c t\u1ea1p: \\(O(m + n)\\), trong \u0111\u00f3 \\(m\\) v\u00e0 \\(n\\) l\u00e0 \u0111\u1ed9 d\u00e0i c\u1ee7a c\u00e1c danh s\u00e1ch. N\u00f3 r\u1ea5t hi\u1ec7u qu\u1ea3 cho m\u1ed9t b\u1ed9 x\u1eed l\u00fd \u0111\u01a1n l\u1ebb nh\u01b0ng ho\u00e0n to\u00e0n tu\u1ea7n t\u1ef1.</p>"},{"location":"cuda/pmpp/chapter-12/#vi-parallelization","title":"12.3 C\u00e1ch ti\u1ebfp c\u1eadn song song h\u00f3a","text":"<p>Chi\u1ebfn l\u01b0\u1ee3c: Ph\u00e2n chia m\u1ea3ng \u0111\u1ea7u ra (\\(C\\)) th\u00e0nh c\u00e1c \u0111o\u1ea1n c\u00f3 k\u00edch th\u01b0\u1edbc b\u1eb1ng nhau v\u00e0 g\u00e1n m\u1ed7i \u0111o\u1ea1n cho m\u1ed9t lu\u1ed3ng.</p> <p>V\u1ea5n \u0111\u1ec1: V\u00ec c\u00e1c danh s\u00e1ch \u0111\u00e3 \u0111\u01b0\u1ee3c s\u1eafp x\u1ebfp nh\u01b0ng gi\u00e1 tr\u1ecb ch\u01b0a bi\u1ebft, m\u1ed9t lu\u1ed3ng kh\u00f4ng bi\u1ebft ph\u00e2n \u0111o\u1ea1n \\(C\\) \u0111\u01b0\u1ee3c g\u00e1n c\u1ee7a n\u00f3 b\u1eaft \u0111\u1ea7u t\u1eeb \u0111\u00e2u trong c\u00e1c danh s\u00e1ch \u0111\u1ea7u v\u00e0o \\(A\\) v\u00e0 \\(B\\).</p> <p>Gi\u1ea3i ph\u00e1p (Co-rank): M\u1ed7i lu\u1ed3ng ph\u1ea3i t\u00ecm \"\u0111i\u1ec3m chia\" c\u1ee7a n\u00f3 trong c\u00e1c m\u1ea3ng \u0111\u1ea7u v\u00e0o b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng h\u00e0m Co-rank.</p>"},{"location":"cuda/pmpp/chapter-12/#vi-co-rank","title":"12.4 Tri\u1ec3n khai h\u00e0m Co-rank","text":"<p>Kh\u00e1i ni\u1ec7m: H\u00e0m co-rank s\u1eed d\u1ee5ng T\u00ecm ki\u1ebfm nh\u1ecb ph\u00e2n \u0111\u1ec3 t\u00ecm c\u00e1c ch\u1ec9 s\u1ed1 \\(i\\) v\u00e0 \\(j\\) duy nh\u1ea5t trong c\u00e1c m\u1ea3ng \\(A\\) v\u00e0 \\(B\\) \u0111\u00f3ng g\u00f3p v\u00e0o m\u1ed9t v\u1ecb tr\u00ed \\(k\\) c\u1ee5 th\u1ec3 trong m\u1ea3ng \u0111\u1ea7u ra \\(C\\).</p> <p>Logic: N\u00f3 t\u00ecm ki\u1ebfm \u0111i\u1ec3m m\u00e0 \\(A[i-1] \\le B[j]\\) v\u00e0 \\(B[j-1] &lt; A[i]\\).</p> <p>\u0110\u1ed9 ph\u1ee9c t\u1ea1p: \\(O(\\log N)\\), trong \u0111\u00f3 \\(N\\) l\u00e0 \u0111\u1ed9 d\u00e0i c\u1ee7a danh s\u00e1ch \u0111\u1ea7u v\u00e0o d\u00e0i h\u01a1n. Vi\u1ec7c t\u00ecm ki\u1ebfm n\u00e0y \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n b\u1edfi m\u1ecdi lu\u1ed3ng \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh ranh gi\u1edbi c\u00f4ng vi\u1ec7c c\u1ee7a n\u00f3.</p>"},{"location":"cuda/pmpp/chapter-12/#vi-basic","title":"12.5 Kernel Parallel Merge c\u01a1 b\u1ea3n","text":"<p>Th\u1ef1c thi: M\u1ed7i lu\u1ed3ng g\u1ecdi h\u00e0m co-rank \u0111\u1ec3 t\u00ecm \u0111i\u1ec3m b\u1eaft \u0111\u1ea7u v\u00e0 \u0111i\u1ec3m k\u1ebft th\u00fac c\u1ee7a n\u00f3 trong \\(A\\) v\u00e0 \\(B\\), sau \u0111\u00f3 th\u1ef1c hi\u1ec7n h\u1ee3p nh\u1ea5t tu\u1ea7n t\u1ef1 ti\u00eau chu\u1ea9n tr\u00ean c\u00e1c ph\u00e2n \u0111o\u1ea1n c\u1ee5 th\u1ec3 \u0111\u00f3.</p> <p>N\u00fat th\u1eaft c\u1ed5 chai: Phi\u00ean b\u1ea3n c\u01a1 b\u1ea3n n\u00e0y b\u1ecb hi\u1ec7n t\u01b0\u1ee3ng truy c\u1eadp b\u1ed9 nh\u1edb kh\u00f4ng g\u1ed9p (uncoalesced) v\u00ec c\u00e1c lu\u1ed3ng trong c\u00f9ng m\u1ed9t warp h\u1ee3p nh\u1ea5t c\u00e1c gi\u00e1 tr\u1ecb d\u1eef li\u1ec7u kh\u00e1c nhau v\u1edbi t\u1ed1c \u0111\u1ed9 kh\u00e1c nhau, nh\u1ea3y xung quanh b\u1ed9 nh\u1edb global.</p>"},{"location":"cuda/pmpp/chapter-12/#vi-tiled","title":"12.6 Kernel Merge Tiled \u0111\u1ec3 c\u1ea3i thi\u1ec7n Coalescing","text":"<p>T\u1ed1i \u01b0u h\u00f3a: C\u00e1c lu\u1ed3ng trong m\u1ed9t block c\u1ed9ng t\u00e1c \u0111\u1ec3 t\u1ea3i c\u00e1c tile c\u1ee7a \\(A\\) v\u00e0 \\(B\\) v\u00e0o Shared Memory.</p> <p>Th\u00e1ch th\u1ee9c: Kh\u00f4ng gi\u1ed1ng nh\u01b0 c\u00e1c m\u1eabu tr\u01b0\u1edbc \u0111\u00f3, ch\u00fang ta kh\u00f4ng bi\u1ebft \"t\u1ef7 l\u1ec7 A-so-v\u1edbi-B\" cho m\u1ed9t tile. Trong tr\u01b0\u1eddng h\u1ee3p x\u1ea5u nh\u1ea5t, \u0111\u1ea7u ra c\u1ee7a m\u1ed9t tile c\u00f3 th\u1ec3 ch\u1ec9 y\u00eau c\u1ea7u c\u00e1c ph\u1ea7n t\u1eed t\u1eeb \\(A\\) ho\u1eb7c ch\u1ec9 t\u1eeb \\(B\\).</p> <p>X\u1eed l\u00fd s\u1ef1 kh\u00f4ng ch\u1eafc ch\u1eafn: M\u1ed7i block ph\u1ea3i t\u1ea3i m\u1ed9t tile c\u1ee7a \\(A\\) v\u00e0 m\u1ed9t tile c\u1ee7a \\(B\\). \u0110i\u1ec1u n\u00e0y \u0111\u1ea3m b\u1ea3o t\u1ea5t c\u1ea3 d\u1eef li\u1ec7u c\u1ea7n thi\u1ebft \u0111\u1ec1u c\u00f3 tr\u00ean chip, nh\u01b0ng d\u1eabn \u0111\u1ebfn vi\u1ec7c ch\u1ec9 kho\u1ea3ng 50% d\u1eef li\u1ec7u \u0111\u00e3 t\u1ea3i th\u1ef1c s\u1ef1 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong m\u1ed7i b\u01b0\u1edbc.</p>"},{"location":"cuda/pmpp/chapter-12/#vi-circular","title":"12.7 Kernel Merge Circular Buffer","text":"<p>T\u1ed1i \u01b0u h\u00f3a n\u00e2ng cao: \u0110\u1ec3 kh\u1eafc ph\u1ee5c vi\u1ec7c l\u00e3ng ph\u00ed 50% d\u1eef li\u1ec7u trong tiling ti\u00eau chu\u1ea9n, c\u00e1c t\u00e1c gi\u1ea3 gi\u1edbi thi\u1ec7u Circular Buffer trong shared memory.</p> <p>C\u01a1 ch\u1ebf: C\u00e1c lu\u1ed3ng theo d\u00f5i c\u00e1c ph\u1ea7n t\u1eed \"d\u01b0 th\u1eeba\" trong shared memory kh\u00f4ng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u1edf giai \u0111o\u1ea1n tr\u01b0\u1edbc. Ch\u00fang ch\u1ec9 t\u1ea3i \u0111\u1ee7 c\u00e1c ph\u1ea7n t\u1eed m\u1edbi t\u1eeb b\u1ed9 nh\u1edb global \u0111\u1ec3 l\u00e0m \u0111\u1ea7y l\u1ea1i buffer.</p> <p>L\u1ee3i \u00edch: \u0110i\u1ec1u n\u00e0y t\u1ed1i \u0111a h\u00f3a vi\u1ec7c s\u1eed d\u1ee5ng b\u0103ng th\u00f4ng b\u1ed9 nh\u1edb nh\u01b0ng l\u00e0m t\u0103ng \u0111\u00e1ng k\u1ec3 \u0111\u1ed9 ph\u1ee9c t\u1ea1p c\u1ee7a m\u00e3 ngu\u1ed3n, y\u00eau c\u1ea7u m\u1ed9t \"m\u00f4 h\u00ecnh \u0111\u01a1n gi\u1ea3n h\u00f3a\" \u0111\u1ec3 c\u00e1c lu\u1ed3ng \u0111\u00e1nh ch\u1ec9 s\u1ed1 v\u00e0o buffer v\u00f2ng.</p>"},{"location":"cuda/pmpp/chapter-12/#vi-coarsening","title":"12.8 Thread Coarsening cho Merge","text":"<p>Hi\u1ec7u qu\u1ea3: T\u00ecm ki\u1ebfm nh\u1ecb ph\u00e2n co-rank l\u00e0 m\u1ed9t thao t\u00e1c c\u00f3 chi ph\u00ed cao.</p> <p>Chi\u1ebfn l\u01b0\u1ee3c: B\u1eb1ng c\u00e1ch \u0111\u1ec3 m\u1ed7i lu\u1ed3ng x\u1eed l\u00fd nhi\u1ec1u ph\u1ea7n t\u1eed h\u01a1n (l\u00e0m th\u00f4), \"chi ph\u00ed\" c\u1ee7a vi\u1ec7c t\u00ecm ki\u1ebfm nh\u1ecb ph\u00e2n \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 cho m\u1ed9t l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c l\u1edbn h\u01a1n, c\u1ea3i thi\u1ec7n hi\u1ec7u qu\u1ea3 c\u00f4ng vi\u1ec7c t\u1ed5ng th\u1ec3 c\u1ee7a kernel.</p> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 12 d\u1ea1y b\u1ea1n c\u00e1ch song song h\u00f3a c\u00e1c thu\u1eadt to\u00e1n n\u01a1i ranh gi\u1edbi kh\u1ed1i l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c ph\u1ee5 thu\u1ed9c v\u00e0o d\u1eef li\u1ec7u. B\u00e0i h\u1ecdc c\u1ed1t l\u00f5i l\u00e0 h\u00e0m Co-rank, s\u1eed d\u1ee5ng t\u00ecm ki\u1ebfm nh\u1ecb ph\u00e2n \u0111\u1ec3 c\u00e1c lu\u1ed3ng \u0111\u1ed9c l\u1eadp \"x\u00e1c nh\u1eadn\" ph\u1ea7n vi\u1ec7c c\u1ee7a m\u00ecnh trong m\u1ed9t nhi\u1ec7m v\u1ee5 to\u00e0n c\u1ee5c, trong khi Circular Buffer gi\u1ea3i quy\u1ebft c\u00e1c v\u1ea5n \u0111\u1ec1 hi\u1ec7u qu\u1ea3 b\u1ed9 nh\u1edb duy nh\u1ea5t do h\u00e0nh vi \u0111\u1ed9ng n\u00e0y t\u1ea1o ra.</p>"},{"location":"cuda/pmpp/chapter-13/","title":"Chapter 13: Parallel Sorting","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>Sorting is one of the most fundamental operations in computer science. This chapter explores how to adapt various sorting algorithms for the GPU, focusing on balancing workload and memory efficiency.</p> <p>S\u1eafp x\u1ebfp l\u00e0 m\u1ed9t trong nh\u1eefng thao t\u00e1c c\u01a1 b\u1ea3n nh\u1ea5t trong khoa h\u1ecdc m\u00e1y t\u00ednh. Ch\u01b0\u01a1ng n\u00e0y kh\u00e1m ph\u00e1 c\u00e1ch \u0111i\u1ec1u ch\u1ec9nh c\u00e1c thu\u1eadt to\u00e1n s\u1eafp x\u1ebfp kh\u00e1c nhau cho GPU, t\u1eadp trung v\u00e0o vi\u1ec7c c\u00e2n b\u1eb1ng kh\u1ed1i l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c v\u00e0 hi\u1ec7u qu\u1ea3 b\u1ed9 nh\u1edb.</p>"},{"location":"cuda/pmpp/chapter-13/#en-background","title":"13.1 Background","text":"<p>Categories:</p> <ul> <li>Comparison-based: Lower bound of \\(O(N \\log N)\\) (e.g., Merge Sort).</li> <li>Non-comparison-based: Can achieve \\(O(N)\\) but is often limited to specific data types like integers (e.g., Radix Sort).</li> </ul>"},{"location":"cuda/pmpp/chapter-13/#en-radix-sort","title":"13.2 Radix Sort","text":"<p>The Concept: Distributes keys into \"buckets\" based on their individual digits or bits.</p> <p>LSD approach: The book focuses on the Least Significant Digit approach, starting from the rightmost bit and moving to the leftmost.</p> <p>Iterations: For \\(N\\)-bit keys, the algorithm requires \\(N\\) iterations if using a 1-bit radix.</p>"},{"location":"cuda/pmpp/chapter-13/#en-parallel-radix","title":"13.3 Parallel Radix Sort","text":"<p>Mapping: Assign one thread to each input key.</p> <p>The Challenge: Each thread must calculate where its key goes in the output array (the Destination Index).</p> <p>The Logic:</p> <ul> <li>If the key's bit is 0: Its index is the count of all \"0\" bits before it.</li> <li>If the key's bit is 1: Its index is the total count of \"0\"s in the list plus the count of all \"1\" bits before it.</li> </ul> <p>The Primitive: This is solved by performing an Exclusive Scan (from Chapter 11) on the bit values.</p>"},{"location":"cuda/pmpp/chapter-13/#en-coalescing","title":"13.4 Optimizing for Memory Coalescing","text":"<p>The Problem: The basic parallel radix sort has a \"scatter\" write pattern. Since threads in a warp have different bits (0 or 1), they try to write to distant parts of the global memory simultaneously, resulting in uncoalesced writes.</p> <p>The Optimization: Sort locally in Shared Memory first.</p> <p>The Process: Threads in a block perform a local sort to create two contiguous \"sub-buckets\" (one for 0s, one for 1s) in shared memory. Then, the block writes these sub-buckets to global memory in a perfectly coalesced manner.</p>"},{"location":"cuda/pmpp/chapter-13/#en-radix-value","title":"13.5 Choice of Radix Value","text":"<p>Trade-offs: You can use a larger radix (e.g., 4 bits at a time instead of 1).</p> <ul> <li>Pros: Fewer total kernel passes (e.g., 8 passes for 32-bit keys instead of 32).</li> <li>Cons: More buckets (\\(2^4 = 16\\) buckets). This fragments the memory writes, making coalescing harder and increasing the size of the auxiliary scan table.</li> </ul>"},{"location":"cuda/pmpp/chapter-13/#en-coarsening","title":"13.6 Thread Coarsening to Improve Coalescing","text":"<p>The Strategy: Assign multiple keys to each thread.</p> <p>Benefit: This creates larger local buckets within each block. Larger local buckets are more likely to fill up DRAM \"bursts,\" leading to higher effective memory bandwidth and reducing the total number of thread blocks (lowering scan overhead).</p>"},{"location":"cuda/pmpp/chapter-13/#en-merge-sort","title":"13.7 Parallel Merge Sort","text":"<p>The Concept: Use a \"Divide and Conquer\" approach.</p> <p>The Process:</p> <ol> <li>Sort small segments of the array locally (e.g., using a fast local sort).</li> <li>Iteratively merge these segments using the Parallel Merge pattern (from Chapter 12).</li> </ol> <p>Comparison: Unlike Radix Sort, Merge Sort is more general and can handle complex data types that only define a \"less than\" operator.</p>"},{"location":"cuda/pmpp/chapter-13/#en-other","title":"13.8 Other Parallel Sort Methods","text":"<ul> <li>Odd-Even Transposition Sort: Simple but inefficient (\\(O(N^2)\\)).</li> <li>Sorting Networks (Bitonic Sort): Uses a fixed pattern of comparisons; very efficient for small, fixed-size lists.</li> <li>Sample Sort: A \"Top-Down\" approach that partitions data into many buckets based on \"samples\"; excellent for very large scales and multi-GPU systems.</li> </ul> <p>Key Takeaway: Chapter 13 teaches that sorting on a GPU is less about \"sorting logic\" and more about efficient data movement. The most performant sorts (like Radix) rely heavily on Exclusive Scan to calculate indices and use Shared Memory Buffering to ensure that writes to global memory are coalesced.</p>"},{"location":"cuda/pmpp/chapter-13/#vi-background","title":"13.1 B\u1ed1i c\u1ea3nh","text":"<p>C\u00e1c lo\u1ea1i:</p> <ul> <li>D\u1ef1a tr\u00ean so s\u00e1nh: Gi\u1edbi h\u1ea1n d\u01b0\u1edbi c\u1ee7a \\(O(N \\log N)\\) (v\u00ed d\u1ee5: Merge Sort).</li> <li>Kh\u00f4ng d\u1ef1a tr\u00ean so s\u00e1nh: C\u00f3 th\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c \\(O(N)\\) nh\u01b0ng th\u01b0\u1eddng gi\u1edbi h\u1ea1n \u1edf c\u00e1c lo\u1ea1i d\u1eef li\u1ec7u c\u1ee5 th\u1ec3 nh\u01b0 s\u1ed1 nguy\u00ean (v\u00ed d\u1ee5: Radix Sort).</li> </ul>"},{"location":"cuda/pmpp/chapter-13/#vi-radix-sort","title":"13.2 Radix Sort","text":"<p>Kh\u00e1i ni\u1ec7m: Ph\u00e2n ph\u1ed1i c\u00e1c kh\u00f3a v\u00e0o c\u00e1c \"th\u00f9ng (bucket)\" d\u1ef1a tr\u00ean c\u00e1c ch\u1eef s\u1ed1 ho\u1eb7c bit ri\u00eang l\u1ebb c\u1ee7a ch\u00fang.</p> <p>C\u00e1ch ti\u1ebfp c\u1eadn LSD: Cu\u1ed1n s\u00e1ch t\u1eadp trung v\u00e0o c\u00e1ch ti\u1ebfp c\u1eadn Least Significant Digit (ch\u1eef s\u1ed1 \u00edt quan tr\u1ecdng nh\u1ea5t), b\u1eaft \u0111\u1ea7u t\u1eeb bit t\u1eadn c\u00f9ng b\u00ean ph\u1ea3i v\u00e0 di chuy\u1ec3n sang b\u00ean tr\u00e1i.</p> <p>S\u1ed1 l\u1ea7n l\u1eb7p: \u0110\u1ed1i v\u1edbi c\u00e1c kh\u00f3a \\(N\\)-bit, thu\u1eadt to\u00e1n y\u00eau c\u1ea7u \\(N\\) l\u1ea7n l\u1eb7p n\u1ebfu s\u1eed d\u1ee5ng c\u01a1 s\u1ed1 (radix) 1-bit.</p>"},{"location":"cuda/pmpp/chapter-13/#vi-parallel-radix","title":"13.3 Parallel Radix Sort","text":"<p>\u00c1nh x\u1ea1: G\u00e1n m\u1ed9t lu\u1ed3ng cho m\u1ed7i kh\u00f3a \u0111\u1ea7u v\u00e0o.</p> <p>Th\u00e1ch th\u1ee9c: M\u1ed7i lu\u1ed3ng ph\u1ea3i t\u00ednh to\u00e1n n\u01a1i kh\u00f3a c\u1ee7a n\u00f3 s\u1ebd \u0111\u1ebfn trong m\u1ea3ng \u0111\u1ea7u ra (Destination Index).</p> <p>Logic:</p> <ul> <li>N\u1ebfu bit c\u1ee7a kh\u00f3a l\u00e0 0: Ch\u1ec9 s\u1ed1 c\u1ee7a n\u00f3 l\u00e0 s\u1ed1 l\u01b0\u1ee3ng t\u1ea5t c\u1ea3 c\u00e1c bit \"0\" tr\u01b0\u1edbc n\u00f3.</li> <li>N\u1ebfu bit c\u1ee7a kh\u00f3a l\u00e0 1: Ch\u1ec9 s\u1ed1 c\u1ee7a n\u00f3 l\u00e0 t\u1ed5ng s\u1ed1 l\u01b0\u1ee3ng c\u00e1c bit \"0\" trong danh s\u00e1ch c\u1ed9ng v\u1edbi s\u1ed1 l\u01b0\u1ee3ng t\u1ea5t c\u1ea3 c\u00e1c bit \"1\" tr\u01b0\u1edbc n\u00f3.</li> </ul> <p>Nguy\u00ean th\u1ee7y: \u0110i\u1ec1u n\u00e0y \u0111\u01b0\u1ee3c gi\u1ea3i quy\u1ebft b\u1eb1ng c\u00e1ch th\u1ef1c hi\u1ec7n m\u1ed9t ph\u00e9p Exclusive Scan (t\u1eeb Ch\u01b0\u01a1ng 11) tr\u00ean c\u00e1c gi\u00e1 tr\u1ecb bit.</p>"},{"location":"cuda/pmpp/chapter-13/#vi-coalescing","title":"13.4 T\u1ed1i \u01b0u h\u00f3a cho Memory Coalescing","text":"<p>V\u1ea5n \u0111\u1ec1: S\u1eafp x\u1ebfp radix song song c\u01a1 b\u1ea3n c\u00f3 m\u1eabu ghi d\u1eef li\u1ec7u \"ph\u00e2n t\u00e1n (scatter)\". V\u00ec c\u00e1c lu\u1ed3ng trong c\u00f9ng m\u1ed9t warp c\u00f3 c\u00e1c bit kh\u00e1c nhau (0 ho\u1eb7c 1), ch\u00fang c\u1ed1 g\u1eafng ghi v\u00e0o c\u00e1c ph\u1ea7n c\u00e1ch xa nhau tr\u00ean b\u1ed9 nh\u1edb global \u0111\u1ed3ng th\u1eddi, d\u1eabn \u0111\u1ebfn c\u00e1c thao t\u00e1c ghi kh\u00f4ng g\u1ed9p (uncoalesced).</p> <p>T\u1ed1i \u01b0u h\u00f3a: S\u1eafp x\u1ebfp c\u1ee5c b\u1ed9 trong Shared Memory tr\u01b0\u1edbc.</p> <p>Quy tr\u00ecnh: C\u00e1c lu\u1ed3ng trong m\u1ed9t block th\u1ef1c hi\u1ec7n s\u1eafp x\u1ebfp c\u1ee5c b\u1ed9 \u0111\u1ec3 t\u1ea1o ra hai \"th\u00f9ng con\" li\u00ean ti\u1ebfp (m\u1ed9t cho bit 0, m\u1ed9t cho bit 1) trong shared memory. Sau \u0111\u00f3, block ghi c\u00e1c th\u00f9ng con n\u00e0y v\u00e0o b\u1ed9 nh\u1edb global theo c\u00e1ch g\u1ed9p (coalesced) ho\u00e0n h\u1ea3o.</p>"},{"location":"cuda/pmpp/chapter-13/#vi-radix-value","title":"13.5 L\u1ef1a ch\u1ecdn gi\u00e1 tr\u1ecb Radix","text":"<p>\u0110\u00e1nh \u0111\u1ed5i: B\u1ea1n c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng c\u01a1 s\u1ed1 l\u1edbn h\u01a1n (v\u00ed d\u1ee5: 4 bit m\u1ed9t l\u00fac thay v\u00ec 1).</p> <ul> <li>\u01afu \u0111i\u1ec3m: T\u1ed5ng s\u1ed1 l\u1ea7n ch\u1ea1y kernel \u00edt h\u01a1n (v\u00ed d\u1ee5: 8 l\u1ea7n cho kh\u00f3a 32-bit thay v\u00ec 32).</li> <li>Nh\u01b0\u1ee3c \u0111i\u1ec3m: Nhi\u1ec1u th\u00f9ng h\u01a1n (\\(2^4 = 16\\) th\u00f9ng). \u0110i\u1ec1u n\u00e0y l\u00e0m ph\u00e2n m\u1ea3nh c\u00e1c thao t\u00e1c ghi b\u1ed9 nh\u1edb, khi\u1ebfn vi\u1ec7c g\u1ed9p d\u1eef li\u1ec7u kh\u00f3 kh\u0103n h\u01a1n v\u00e0 l\u00e0m t\u0103ng k\u00edch th\u01b0\u1edbc c\u1ee7a b\u1ea3ng scan ph\u1ee5 tr\u1ee3.</li> </ul>"},{"location":"cuda/pmpp/chapter-13/#vi-coarsening","title":"13.6 Thread Coarsening \u0111\u1ec3 c\u1ea3i thi\u1ec7n Coalescing","text":"<p>Chi\u1ebfn l\u01b0\u1ee3c: G\u00e1n nhi\u1ec1u kh\u00f3a cho m\u1ed7i lu\u1ed3ng.</p> <p>L\u1ee3i \u00edch: \u0110i\u1ec1u n\u00e0y t\u1ea1o ra c\u00e1c th\u00f9ng c\u1ee5c b\u1ed9 l\u1edbn h\u01a1n trong m\u1ed7i block. C\u00e1c th\u00f9ng c\u1ee5c b\u1ed9 l\u1edbn h\u01a1n c\u00f3 nhi\u1ec1u kh\u1ea3 n\u0103ng l\u00e0m \u0111\u1ea7y c\u00e1c \"bursts\" c\u1ee7a DRAM, d\u1eabn \u0111\u1ebfn b\u0103ng th\u00f4ng b\u1ed9 nh\u1edb hi\u1ec7u d\u1ee5ng cao h\u01a1n v\u00e0 gi\u1ea3m t\u1ed5ng s\u1ed1 thread block (gi\u1ea3m chi ph\u00ed scan).</p>"},{"location":"cuda/pmpp/chapter-13/#vi-merge-sort","title":"13.7 Parallel Merge Sort","text":"<p>Kh\u00e1i ni\u1ec7m: S\u1eed d\u1ee5ng c\u00e1ch ti\u1ebfp c\u1eadn \"Chia \u0111\u1ec3 tr\u1ecb (Divide and Conquer)\".</p> <p>Quy tr\u00ecnh:</p> <ol> <li>S\u1eafp x\u1ebfp c\u00e1c \u0111o\u1ea1n nh\u1ecf c\u1ee7a m\u1ea3ng c\u1ee5c b\u1ed9 (v\u00ed d\u1ee5: s\u1eed d\u1ee5ng s\u1eafp x\u1ebfp c\u1ee5c b\u1ed9 nhanh).</li> <li>H\u1ee3p nh\u1ea5t l\u1eb7p \u0111i l\u1eb7p l\u1ea1i c\u00e1c \u0111o\u1ea1n n\u00e0y b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng m\u1eabu Parallel Merge (t\u1eeb Ch\u01b0\u01a1ng 12).</li> </ol> <p>So s\u00e1nh: Kh\u00f4ng gi\u1ed1ng nh\u01b0 Radix Sort, Merge Sort t\u1ed5ng qu\u00e1t h\u01a1n v\u00e0 c\u00f3 th\u1ec3 x\u1eed l\u00fd c\u00e1c ki\u1ec3u d\u1eef li\u1ec7u ph\u1ee9c t\u1ea1p ch\u1ec9 x\u00e1c \u0111\u1ecbnh to\u00e1n t\u1eed \"nh\u1ecf h\u01a1n\".</p>"},{"location":"cuda/pmpp/chapter-13/#vi-other","title":"13.8 C\u00e1c ph\u01b0\u01a1ng ph\u00e1p s\u1eafp x\u1ebfp song song kh\u00e1c","text":"<ul> <li>Odd-Even Transposition Sort: \u0110\u01a1n gi\u1ea3n nh\u01b0ng kh\u00f4ng hi\u1ec7u qu\u1ea3 (\\(O(N^2)\\)).</li> <li>Sorting Networks (Bitonic Sort): S\u1eed d\u1ee5ng m\u1ed9t m\u1eabu so s\u00e1nh c\u1ed1 \u0111\u1ecbnh; r\u1ea5t hi\u1ec7u qu\u1ea3 cho c\u00e1c danh s\u00e1ch c\u00f3 k\u00edch th\u01b0\u1edbc c\u1ed1 \u0111\u1ecbnh v\u00e0 nh\u1ecf.</li> <li>Sample Sort: M\u1ed9t c\u00e1ch ti\u1ebfp c\u1eadn \"T\u1eeb tr\u00ean xu\u1ed1ng\" ph\u00e2n chia d\u1eef li\u1ec7u th\u00e0nh nhi\u1ec1u th\u00f9ng d\u1ef1a tr\u00ean c\u00e1c \"m\u1eabu (samples)\"; xu\u1ea5t s\u1eafc cho quy m\u00f4 r\u1ea5t l\u1edbn v\u00e0 h\u1ec7 th\u1ed1ng \u0111a GPU.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 13 d\u1ea1y r\u1eb1ng s\u1eafp x\u1ebfp tr\u00ean GPU \u00edt quan tr\u1ecdng v\u1ec1 \"logic s\u1eafp x\u1ebfp\" m\u00e0 quan tr\u1ecdng h\u01a1n v\u1ec1 di chuy\u1ec3n d\u1eef li\u1ec7u hi\u1ec7u qu\u1ea3. C\u00e1c lo\u1ea1i s\u1eafp x\u1ebfp hi\u1ec7u su\u1ea5t cao nh\u1ea5t (nh\u01b0 Radix) d\u1ef1a tr\u00ean Exclusive Scan \u0111\u1ec3 t\u00ednh to\u00e1n ch\u1ec9 s\u1ed1 v\u00e0 s\u1eed d\u1ee5ng Shared Memory Buffering \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o c\u00e1c thao t\u00e1c ghi v\u00e0o b\u1ed9 nh\u1edb global \u0111\u01b0\u1ee3c g\u1ed9p l\u1ea1i.</p>"},{"location":"cuda/pmpp/chapter-14/","title":"Chapter 14: Sparse Matrix Computation","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter addresses the challenge of processing \"Sparse\" data\u2014matrices where the vast majority of elements are zero. Processing these like dense matrices is wasteful; however, compacting them introduces irregularity that can slow down a GPU.</p> <p>Ch\u01b0\u01a1ng n\u00e0y gi\u1ea3i quy\u1ebft th\u00e1ch th\u1ee9c trong vi\u1ec7c x\u1eed l\u00fd d\u1eef li\u1ec7u \"Th\u01b0a (Sparse)\"\u2014c\u00e1c ma tr\u1eadn m\u00e0 \u0111\u1ea1i \u0111a s\u1ed1 c\u00e1c ph\u1ea7n t\u1eed b\u1eb1ng kh\u00f4ng. X\u1eed l\u00fd ch\u00fang nh\u01b0 c\u00e1c ma tr\u1eadn \u0111\u1eb7c l\u00e0 m\u1ed9t s\u1ef1 l\u00e3ng ph\u00ed; tuy nhi\u00ean, vi\u1ec7c n\u00e9n ch\u00fang l\u1ea1i t\u1ea1o ra s\u1ef1 kh\u00f4ng \u0111\u1ec1u (irregularity) c\u00f3 th\u1ec3 l\u00e0m ch\u1eadm GPU.</p>"},{"location":"cuda/pmpp/chapter-14/#en-background","title":"14.1 Background","text":"<p>Definition: A sparse matrix is one in which most elements are zero. They occur frequently in engineering, physics, and financial modeling (e.g., linear systems like \\(Ax + y = z\\)).</p> <p>The Goal: Remove zeros from storage to save memory capacity and bandwidth.</p> <p>Design Considerations for Formats:</p> <ol> <li>Space Efficiency: How much memory is saved?</li> <li>Flexibility: How easy is it to add or remove non-zero elements?</li> <li>Accessibility: How easy is it to find all elements in a specific row or column?</li> <li>Memory Access Efficiency: Does the format support coalesced access?</li> <li>Load Balance: Does it distribute work evenly across threads?</li> </ol>"},{"location":"cuda/pmpp/chapter-14/#en-coo","title":"14.2 A Simple SpMV Kernel with the COO Format","text":"<p>Format (Coordinate List): Stores three arrays of equal length: <code>rowIdx</code>, <code>colIdx</code>, and <code>value</code>.</p> <p>Parallel Strategy: Assign one thread to each non-zero element.</p> <p>Pros: Perfectly load-balanced (every thread does one multiply-add) and memory accesses are coalesced.</p> <p>Cons: Requires Atomic Operations (<code>atomicAdd</code>) because multiple threads might belong to the same row and try to update the same output element simultaneously. Atomics significantly slow down execution.</p>"},{"location":"cuda/pmpp/chapter-14/#en-csr","title":"14.3 Grouping Row Non-zeros with the CSR Format","text":"<p>Format (Compressed Sparse Row): Groups non-zeros by row. It uses <code>value</code>, <code>colIdx</code>, and a special <code>rowPtrs</code> array that acts as a map to where each row starts.</p> <p>Parallel Strategy: Assign one thread to each row.</p> <p>Pros: Eliminates the need for atomics because each thread \"owns\" its output row. It is more space-efficient than COO.</p> <p>Cons:</p> <ul> <li>Uncoalesced Access: Since threads in a warp work on different rows, their first elements are far apart in memory.</li> <li>Load Imbalance: A thread assigned to a row with 100 elements will work much longer than a thread assigned to a row with 2 elements, causing warp divergence.</li> </ul>"},{"location":"cuda/pmpp/chapter-14/#en-ell","title":"14.4 Improving Memory Coalescing with the ELL Format","text":"<p>Format (ELLPACK): Pads all rows with zeros so they all match the length of the longest row, then transposes the matrix into column-major order.</p> <p>Parallel Strategy: Assign one thread to each row.</p> <p>Pros: Because of the transposition, threads in a warp access adjacent memory locations, enabling full memory coalescing.</p> <p>Cons: If one row is very long and others are short, ELL wastes massive amounts of memory on \"padding\" zeros.</p>"},{"location":"cuda/pmpp/chapter-14/#en-hybrid","title":"14.5 Regulating Padding: The Hybrid ELL-COO Format","text":"<p>The Strategy: A \"best of both worlds\" approach.</p> <p>Mechanism: Determine a \"typical\" row length. Most data is stored in ELL format to that length. Any elements that exceed that length (the \"extra-long\" rows) are moved to a separate COO structure.</p> <p>Benefit: Reduces the memory waste of ELL while keeping the performance of coalesced access for the majority of the data.</p>"},{"location":"cuda/pmpp/chapter-14/#en-jds","title":"14.6 Reducing Control Divergence with the JDS Format","text":"<p>Format (Jagged Diagonal Storage): Sorts the rows of the matrix by their number of non-zero elements (from longest to shortest) before storing them.</p> <p>Benefit: Threads in the same warp will now process rows of similar lengths. This significantly reduces control divergence and improves load balancing.</p> <p>Trade-off: Requires an extra step to reorder the results back to the original row indices after the math is done.</p>"},{"location":"cuda/pmpp/chapter-14/#en-summary","title":"14.7 Summary: Regularization vs. Compaction","text":"<ul> <li>The chapter concludes that there is no \"perfect\" sparse format.</li> <li>CSR is the general standard for storage.</li> <li>ELL/JDS are better for performance but require \"regularizing\" the data.</li> <li>SpMV (Sparse Matrix-Vector Multiplication) usually has a low arithmetic intensity (0.25 OP/B), making memory bandwidth the ultimate bottleneck regardless of the format.</li> </ul> <p>Key Takeaway: Chapter 14 teaches that \"irregularity is the enemy of performance.\" High-performance sparse computing on a GPU requires choosing a format that balances memory compaction (saving space) with regularization (ensuring threads work together and access memory contiguously).</p>"},{"location":"cuda/pmpp/chapter-14/#vi-background","title":"14.1 B\u1ed1i c\u1ea3nh","text":"<p>\u0110\u1ecbnh ngh\u0129a: M\u1ed9t ma tr\u1eadn th\u01b0a l\u00e0 ma tr\u1eadn m\u00e0 h\u1ea7u h\u1ebft c\u00e1c ph\u1ea7n t\u1eed c\u00f3 gi\u00e1 tr\u1ecb b\u1eb1ng kh\u00f4ng. Ch\u00fang xu\u1ea5t hi\u1ec7n th\u01b0\u1eddng xuy\u00ean trong k\u1ef9 thu\u1eadt, v\u1eadt l\u00fd v\u00e0 m\u00f4 h\u00ecnh t\u00e0i ch\u00ednh (v\u00ed d\u1ee5: c\u00e1c h\u1ec7 th\u1ed1ng tuy\u1ebfn t\u00ednh nh\u01b0 \\(Ax + y = z\\)).</p> <p>M\u1ee5c ti\u00eau: Lo\u1ea1i b\u1ecf c\u00e1c s\u1ed1 kh\u00f4ng kh\u1ecfi l\u01b0u tr\u1eef \u0111\u1ec3 ti\u1ebft ki\u1ec7m dung l\u01b0\u1ee3ng b\u1ed9 nh\u1edb v\u00e0 b\u0103ng th\u00f4ng.</p> <p>Xem x\u00e9t thi\u1ebft k\u1ebf c\u00e1c \u0111\u1ecbnh d\u1ea1ng:</p> <ol> <li>Hi\u1ec7u qu\u1ea3 kh\u00f4ng gian: Ti\u1ebft ki\u1ec7m \u0111\u01b0\u1ee3c bao nhi\u00eau b\u1ed9 nh\u1edb?</li> <li>T\u00ednh linh ho\u1ea1t: Vi\u1ec7c th\u00eam ho\u1eb7c x\u00f3a c\u00e1c ph\u1ea7n t\u1eed kh\u00e1c kh\u00f4ng d\u1ec5 d\u00e0ng nh\u01b0 th\u1ebf n\u00e0o?</li> <li>Kh\u1ea3 n\u0103ng truy c\u1eadp: Vi\u1ec7c t\u00ecm t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n t\u1eed trong m\u1ed9t h\u00e0ng ho\u1eb7c c\u1ed9t c\u1ee5 th\u1ec3 d\u1ec5 d\u00e0ng nh\u01b0 th\u1ebf n\u00e0o?</li> <li>Hi\u1ec7u qu\u1ea3 truy c\u1eadp b\u1ed9 nh\u1edb: \u0110\u1ecbnh d\u1ea1ng c\u00f3 h\u1ed7 tr\u1ee3 truy c\u1eadp g\u1ed9p (coalesced) kh\u00f4ng?</li> <li>C\u00e2n b\u1eb1ng t\u1ea3i: N\u00f3 c\u00f3 ph\u00e2n ph\u1ed1i c\u00f4ng vi\u1ec7c \u0111\u1ed3ng \u0111\u1ec1u gi\u1eefa c\u00e1c lu\u1ed3ng kh\u00f4ng?</li> </ol>"},{"location":"cuda/pmpp/chapter-14/#vi-coo","title":"14.2 Kernel SpMV \u0111\u01a1n gi\u1ea3n v\u1edbi \u0111\u1ecbnh d\u1ea1ng COO","text":"<p>\u0110\u1ecbnh d\u1ea1ng (Coordinate List): L\u01b0u tr\u1eef ba m\u1ea3ng c\u00f3 \u0111\u1ed9 d\u00e0i b\u1eb1ng nhau: <code>rowIdx</code>, <code>colIdx</code>, v\u00e0 <code>value</code>.</p> <p>Chi\u1ebfn l\u01b0\u1ee3c song song: G\u00e1n m\u1ed9t lu\u1ed3ng cho m\u1ed7i ph\u1ea7n t\u1eed kh\u00e1c kh\u00f4ng.</p> <p>\u01afu \u0111i\u1ec3m: C\u00e2n b\u1eb1ng t\u1ea3i ho\u00e0n h\u1ea3o (m\u1ed7i lu\u1ed3ng th\u1ef1c hi\u1ec7n m\u1ed9t ph\u00e9p nh\u00e2n-c\u1ed9ng) v\u00e0 c\u00e1c truy c\u1eadp b\u1ed9 nh\u1edb \u0111\u01b0\u1ee3c g\u1ed9p l\u1ea1i.</p> <p>Nh\u01b0\u1ee3c \u0111i\u1ec3m: Y\u00eau c\u1ea7u Atomic Operations (<code>atomicAdd</code>) v\u00ec nhi\u1ec1u lu\u1ed3ng c\u00f3 th\u1ec3 thu\u1ed9c c\u00f9ng m\u1ed9t h\u00e0ng v\u00e0 c\u1ed1 g\u1eafng c\u1eadp nh\u1eadt c\u00f9ng m\u1ed9t ph\u1ea7n t\u1eed \u0111\u1ea7u ra \u0111\u1ed3ng th\u1eddi. C\u00e1c thao t\u00e1c Atomic l\u00e0m ch\u1eadm \u0111\u00e1ng k\u1ec3 qu\u00e1 tr\u00ecnh th\u1ef1c thi.</p>"},{"location":"cuda/pmpp/chapter-14/#vi-csr","title":"14.3 Nh\u00f3m c\u00e1c ph\u1ea7n t\u1eed kh\u00e1c kh\u00f4ng theo h\u00e0ng v\u1edbi \u0111\u1ecbnh d\u1ea1ng CSR","text":"<p>\u0110\u1ecbnh d\u1ea1ng (Compressed Sparse Row): Nh\u00f3m c\u00e1c ph\u1ea7n t\u1eed kh\u00e1c kh\u00f4ng theo h\u00e0ng. N\u00f3 s\u1eed d\u1ee5ng <code>value</code>, <code>colIdx</code>, v\u00e0 m\u1ed9t m\u1ea3ng <code>rowPtrs</code> \u0111\u1eb7c bi\u1ec7t \u0111\u00f3ng vai tr\u00f2 nh\u01b0 m\u1ed9t b\u1ea3n \u0111\u1ed3 cho bi\u1ebft m\u1ed7i h\u00e0ng b\u1eaft \u0111\u1ea7u t\u1eeb \u0111\u00e2u.</p> <p>Chi\u1ebfn l\u01b0\u1ee3c song song: G\u00e1n m\u1ed9t lu\u1ed3ng cho m\u1ed7i h\u00e0ng.</p> <p>\u01afu \u0111i\u1ec3m: Lo\u1ea1i b\u1ecf nhu c\u1ea7u s\u1eed d\u1ee5ng atomic v\u00ec m\u1ed7i lu\u1ed3ng \"s\u1edf h\u1eefu\" h\u00e0ng \u0111\u1ea7u ra c\u1ee7a ch\u00ednh n\u00f3. N\u00f3 ti\u1ebft ki\u1ec7m kh\u00f4ng gian h\u01a1n COO.</p> <p>Nh\u01b0\u1ee3c \u0111i\u1ec3m:</p> <ul> <li>Truy c\u1eadp kh\u00f4ng g\u1ed9p: V\u00ec c\u00e1c lu\u1ed3ng trong c\u00f9ng m\u1ed9t warp l\u00e0m vi\u1ec7c tr\u00ean c\u00e1c h\u00e0ng kh\u00e1c nhau, c\u00e1c ph\u1ea7n t\u1eed \u0111\u1ea7u ti\u00ean c\u1ee7a ch\u00fang c\u00e1ch xa nhau trong b\u1ed9 nh\u1edb.</li> <li>M\u1ea5t c\u00e2n b\u1eb1ng t\u1ea3i: M\u1ed9t lu\u1ed3ng \u0111\u01b0\u1ee3c g\u00e1n cho m\u1ed9t h\u00e0ng c\u00f3 100 ph\u1ea7n t\u1eed s\u1ebd l\u00e0m vi\u1ec7c l\u00e2u h\u01a1n nhi\u1ec1u so v\u1edbi m\u1ed9t lu\u1ed3ng \u0111\u01b0\u1ee3c g\u00e1n cho h\u00e0ng c\u00f3 2 ph\u1ea7n t\u1eed, g\u00e2y ra hi\u1ec7n t\u01b0\u1ee3ng ph\u00e2n k\u1ef3 warp (warp divergence).</li> </ul>"},{"location":"cuda/pmpp/chapter-14/#vi-ell","title":"14.4 C\u1ea3i thi\u1ec7n Memory Coalescing v\u1edbi \u0111\u1ecbnh d\u1ea1ng ELL","text":"<p>\u0110\u1ecbnh d\u1ea1ng (ELLPACK): \u0110\u1ec7m t\u1ea5t c\u1ea3 c\u00e1c h\u00e0ng b\u1eb1ng s\u1ed1 kh\u00f4ng \u0111\u1ec3 ch\u00fang kh\u1edbp v\u1edbi \u0111\u1ed9 d\u00e0i c\u1ee7a h\u00e0ng d\u00e0i nh\u1ea5t, sau \u0111\u00f3 chuy\u1ec3n v\u1ecb (transpose) ma tr\u1eadn sang th\u1ee9 t\u1ef1 column-major.</p> <p>Chi\u1ebfn l\u01b0\u1ee3c song song: G\u00e1n m\u1ed9t lu\u1ed3ng cho m\u1ed7i h\u00e0ng.</p> <p>\u01afu \u0111i\u1ec3m: Nh\u1edd ph\u00e9p chuy\u1ec3n v\u1ecb, c\u00e1c lu\u1ed3ng trong c\u00f9ng m\u1ed9t warp truy c\u1eadp c\u00e1c v\u1ecb tr\u00ed b\u1ed9 nh\u1edb li\u1ec1n k\u1ec1, cho ph\u00e9p g\u1ed9p b\u1ed9 nh\u1edb ho\u00e0n to\u00e0n.</p> <p>Nh\u01b0\u1ee3c \u0111i\u1ec3m: N\u1ebfu m\u1ed9t h\u00e0ng r\u1ea5t d\u00e0i v\u00e0 c\u00e1c h\u00e0ng kh\u00e1c ng\u1eafn, ELL l\u00e3ng ph\u00ed m\u1ed9t l\u01b0\u1ee3ng l\u1edbn b\u1ed9 nh\u1edb cho c\u00e1c s\u1ed1 kh\u00f4ng \"\u0111\u1ec7m\".</p>"},{"location":"cuda/pmpp/chapter-14/#vi-hybrid","title":"14.5 \u0110i\u1ec1u ti\u1ebft vi\u1ec7c \u0111\u1ec7m: \u0110\u1ecbnh d\u1ea1ng Hybrid ELL-COO","text":"<p>Chi\u1ebfn l\u01b0\u1ee3c: C\u00e1ch ti\u1ebfp c\u1eadn \"t\u1ed1t nh\u1ea5t c\u1ee7a c\u1ea3 hai th\u1ebf gi\u1edbi\".</p> <p>C\u01a1 ch\u1ebf: X\u00e1c \u0111\u1ecbnh m\u1ed9t \u0111\u1ed9 d\u00e0i h\u00e0ng \"\u0111i\u1ec3n h\u00ecnh\". Ph\u1ea7n l\u1edbn d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef theo \u0111\u1ecbnh d\u1ea1ng ELL t\u1edbi \u0111\u1ed9 d\u00e0i \u0111\u00f3. B\u1ea5t k\u1ef3 ph\u1ea7n t\u1eed n\u00e0o v\u01b0\u1ee3t qu\u00e1 \u0111\u1ed9 d\u00e0i \u0111\u00f3 (c\u00e1c h\u00e0ng \"si\u00eau d\u00e0i\") s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n sang c\u1ea5u tr\u00fac COO ri\u00eang bi\u1ec7t.</p> <p>L\u1ee3i \u00edch: Gi\u1ea3m s\u1ef1 l\u00e3ng ph\u00ed b\u1ed9 nh\u1edb c\u1ee7a ELL trong khi v\u1eabn gi\u1eef \u0111\u01b0\u1ee3c hi\u1ec7u su\u1ea5t truy c\u1eadp g\u1ed9p cho ph\u1ea7n l\u1edbn d\u1eef li\u1ec7u.</p>"},{"location":"cuda/pmpp/chapter-14/#vi-jds","title":"14.6 Gi\u1ea3m ph\u00e2n k\u1ef3 \u0111i\u1ec1u khi\u1ec3n v\u1edbi \u0111\u1ecbnh d\u1ea1ng JDS","text":"<p>\u0110\u1ecbnh d\u1ea1ng (Jagged Diagonal Storage): S\u1eafp x\u1ebfp c\u00e1c h\u00e0ng c\u1ee7a ma tr\u1eadn theo s\u1ed1 l\u01b0\u1ee3ng ph\u1ea7n t\u1eed kh\u00e1c kh\u00f4ng (t\u1eeb d\u00e0i nh\u1ea5t \u0111\u1ebfn ng\u1eafn nh\u1ea5t) tr\u01b0\u1edbc khi l\u01b0u tr\u1eef ch\u00fang.</p> <p>L\u1ee3i \u00edch: C\u00e1c lu\u1ed3ng trong c\u00f9ng m\u1ed9t warp b\u00e2y gi\u1edd s\u1ebd x\u1eed l\u00fd c\u00e1c h\u00e0ng c\u00f3 \u0111\u1ed9 d\u00e0i t\u01b0\u01a1ng t\u1ef1 nhau. \u0110i\u1ec1u n\u00e0y l\u00e0m gi\u1ea3m \u0111\u00e1ng k\u1ec3 ph\u00e2n k\u1ef3 \u0111i\u1ec1u khi\u1ec3n v\u00e0 c\u1ea3i thi\u1ec7n c\u00e2n b\u1eb1ng t\u1ea3i.</p> <p>\u0110\u00e1nh \u0111\u1ed5i: Y\u00eau c\u1ea7u th\u00eam m\u1ed9t b\u01b0\u1edbc \u0111\u1ec3 s\u1eafp x\u1ebfp l\u1ea1i k\u1ebft qu\u1ea3 v\u1ec1 ch\u1ec9 s\u1ed1 h\u00e0ng ban \u0111\u1ea7u sau khi t\u00ednh to\u00e1n xong.</p>"},{"location":"cuda/pmpp/chapter-14/#vi-summary","title":"14.7 T\u00f3m t\u1eaft: Quy chu\u1ea9n h\u00f3a vs. N\u00e9n","text":"<ul> <li>Ch\u01b0\u01a1ng k\u1ebft lu\u1eadn r\u1eb1ng kh\u00f4ng c\u00f3 \u0111\u1ecbnh d\u1ea1ng th\u01b0a n\u00e0o l\u00e0 \"ho\u00e0n h\u1ea3o\".</li> <li>CSR l\u00e0 ti\u00eau chu\u1ea9n chung cho l\u01b0u tr\u1eef.</li> <li>ELL/JDS t\u1ed1t h\u01a1n cho hi\u1ec7u su\u1ea5t nh\u01b0ng y\u00eau c\u1ea7u \"quy chu\u1ea9n h\u00f3a\" d\u1eef li\u1ec7u.</li> <li>SpMV (Sparse Matrix-Vector Multiplication) th\u01b0\u1eddng c\u00f3 c\u01b0\u1eddng \u0111\u1ed9 s\u1ed1 h\u1ecdc th\u1ea5p (0.25 OP/B), khi\u1ebfn b\u0103ng th\u00f4ng b\u1ed9 nh\u1edb tr\u1edf th\u00e0nh n\u00fat th\u1eaft c\u1ed5 chai cu\u1ed1i c\u00f9ng b\u1ea5t k\u1ec3 \u0111\u1ecbnh d\u1ea1ng n\u00e0o.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 14 d\u1ea1y r\u1eb1ng \"s\u1ef1 kh\u00f4ng \u0111\u1ed3ng \u0111\u1ec1u l\u00e0 k\u1ebb th\u00f9 c\u1ee7a hi\u1ec7u su\u1ea5t.\" T\u00ednh to\u00e1n ma tr\u1eadn th\u01b0a hi\u1ec7u su\u1ea5t cao tr\u00ean GPU y\u00eau c\u1ea7u ch\u1ecdn m\u1ed9t \u0111\u1ecbnh d\u1ea1ng c\u00e2n b\u1eb1ng gi\u1eefa vi\u1ec7c n\u00e9n b\u1ed9 nh\u1edb (ti\u1ebft ki\u1ec7m kh\u00f4ng gian) v\u1edbi vi\u1ec7c quy chu\u1ea9n h\u00f3a (\u0111\u1ea3m b\u1ea3o c\u00e1c lu\u1ed3ng l\u00e0m vi\u1ec7c c\u00f9ng nhau v\u00e0 truy c\u1eadp b\u1ed9 nh\u1edb li\u00ean t\u1ee5c).</p>"},{"location":"cuda/pmpp/chapter-15/","title":"Chapter 15: Parallel Graph Algorithms","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter focuses on processing graphs (networks of vertices and edges), which are the foundation of social networks, map services, and circuit design. It highlights how graph problems are essentially \"dynamic sparse matrix problems.\"</p> <p>Ch\u01b0\u01a1ng n\u00e0y t\u1eadp trung v\u00e0o x\u1eed l\u00fd \u0111\u1ed3 th\u1ecb (m\u1ea1ng l\u01b0\u1edbi c\u00e1c \u0111\u1ec9nh v\u00e0 c\u1ea1nh), l\u00e0 n\u1ec1n t\u1ea3ng c\u1ee7a c\u00e1c m\u1ea1ng x\u00e3 h\u1ed9i, d\u1ecbch v\u1ee5 b\u1ea3n \u0111\u1ed3 v\u00e0 thi\u1ebft k\u1ebf m\u1ea1ch \u0111i\u1ec7n. N\u00f3 nh\u1ea5n m\u1ea1nh c\u00e1ch c\u00e1c b\u00e0i to\u00e1n \u0111\u1ed3 th\u1ecb th\u1ef1c ch\u1ea5t l\u00e0 c\u00e1c \"b\u00e0i to\u00e1n ma tr\u1eadn th\u01b0a \u0111\u1ed9ng\".</p>"},{"location":"cuda/pmpp/chapter-15/#en-background","title":"15.1 Background","text":"<p>Definitions: Entities are Vertices and their relationships are Edges.</p> <p>Adjacency Matrix: A grid where a \"1\" at <code>A[i][j]</code> indicates an edge from vertex \\(i\\) to vertex \\(j\\).</p> <p>Sparsity: Real-world graphs (like Facebook) are sparsely connected; most vertices have few neighbors.</p> <p>Storage: Graphs are stored using the sparse formats from Chapter 14:</p> <ul> <li>CSR: Best for finding all outgoing edges of a vertex.</li> <li>CSC: Best for finding all incoming edges to a vertex.</li> <li>COO: Simple list of edges; good for edge-centric processing.</li> </ul>"},{"location":"cuda/pmpp/chapter-15/#en-bfs","title":"15.2 Breadth-First Search (BFS)","text":"<p>The Goal: Discover the shortest distance (in \"hops\") from a root vertex to all other vertices.</p> <p>Wavefronts: BFS proceeds in levels (Level 0 \\(\\rightarrow\\) Level 1 \\(\\rightarrow\\) ...). Each level forms a \"wavefront\" of newly discovered vertices.</p> <p>Application (CAD): Explains Maze Routing, where BFS finds the shortest path for a wire on a microchip while avoiding obstacles.</p>"},{"location":"cuda/pmpp/chapter-15/#en-push-pull","title":"15.3 Vertex-Centric Parallelization (Push vs. Pull)","text":"<p>Push (Top-Down): Threads are assigned to vertices in the current level. They \"push\" their status to their neighbors.</p> <ul> <li>Pros: Efficient when the wavefront is small (early levels).</li> <li>Cons: High contention as many parents try to update the same child.</li> </ul> <p>Pull (Bottom-Up): Threads are assigned to unvisited vertices. They \"pull\" status from neighbors to see if any are in the previous level.</p> <ul> <li>Pros: Excellent for \"Small World\" graphs (like social networks) in later levels where most vertices are already visited.</li> </ul> <p>Direction-Optimized BFS: A key optimization that switches from Push to Pull mid-execution to maximize efficiency.</p>"},{"location":"cuda/pmpp/chapter-15/#en-edge-centric","title":"15.4 Edge-Centric Parallelization","text":"<p>The Approach: Assign one thread to every edge in the graph.</p> <p>Benefit: Provides better load balancing for graphs with a massive variation in vertex degrees (e.g., a \"celebrity\" vertex with millions of edges vs. a \"normal\" vertex with ten).</p> <p>Drawback: Every single edge is checked in every level, which is wasteful for large, deep graphs.</p>"},{"location":"cuda/pmpp/chapter-15/#en-frontiers","title":"15.5 Improving Efficiency with Frontiers","text":"<p>The Problem: Launching a thread for every vertex in the graph is wasteful if only 1% are active.</p> <p>The Solution: Use a Frontier (a list of only the currently active vertices).</p> <p>Atomics: Requires <code>atomicCAS</code> (Compare-And-Swap) to ensure a vertex is added to the frontier only once, even if multiple neighbors discover it at the same time.</p>"},{"location":"cuda/pmpp/chapter-15/#en-privatization","title":"15.6 Reducing Contention with Privatization","text":"<p>The Bottleneck: Thousands of threads trying to <code>atomicAdd</code> to the global frontier causes a massive \"hot spot\" in memory.</p> <p>The Strategy: Each thread block builds a Private Frontier in Shared Memory. Once full, the block performs a single global atomic operation to merge its results.</p> <p>Result: Drastically reduces the number of global memory conflicts.</p>"},{"location":"cuda/pmpp/chapter-15/#en-other","title":"15.7 Other Optimizations","text":"<ul> <li>Reducing Launch Overhead: For small frontiers, multiple levels can be processed within a single kernel launch using <code>__syncthreads()</code>, rather than returning to the CPU.</li> <li>Improving Load Balance: Vertices can be \"bucketed\" by their degree. \"Celebrity\" vertices are processed by entire blocks, while \"low-degree\" vertices are handled by single threads.</li> </ul> <p>Key Takeaway: Chapter 15 teaches that there is no \"one-size-fits-all\" algorithm for graphs. Performance depends on the graph's topology. You must use Frontiers to limit work, Privatization to handle contention, and Direction-Optimization to adapt to the growing wavefront of the search.</p>"},{"location":"cuda/pmpp/chapter-15/#vi-background","title":"15.1 B\u1ed1i c\u1ea3nh","text":"<p>\u0110\u1ecbnh ngh\u0129a: C\u00e1c th\u1ef1c th\u1ec3 l\u00e0 \u0110\u1ec9nh (Vertices) v\u00e0 m\u1ed1i quan h\u1ec7 c\u1ee7a ch\u00fang l\u00e0 C\u1ea1nh (Edges).</p> <p>Ma tr\u1eadn k\u1ec1 (Adjacency Matrix): M\u1ed9t l\u01b0\u1edbi n\u01a1i gi\u00e1 tr\u1ecb \"1\" t\u1ea1i <code>A[i][j]</code> cho bi\u1ebft c\u00f3 m\u1ed9t c\u1ea1nh t\u1eeb \u0111\u1ec9nh \\(i\\) \u0111\u1ebfn \u0111\u1ec9nh \\(j\\).</p> <p>\u0110\u1ed9 th\u01b0a: C\u00e1c \u0111\u1ed3 th\u1ecb th\u1ef1c t\u1ebf (nh\u01b0 Facebook) c\u00f3 k\u1ebft n\u1ed1i th\u01b0a th\u1edbt; h\u1ea7u h\u1ebft c\u00e1c \u0111\u1ec9nh c\u00f3 \u00edt n\u00fat l\u00e2n c\u1eadn.</p> <p>L\u01b0u tr\u1eef: \u0110\u1ed3 th\u1ecb \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef b\u1eb1ng c\u00e1c \u0111\u1ecbnh d\u1ea1ng th\u01b0a t\u1eeb Ch\u01b0\u01a1ng 14:</p> <ul> <li>CSR: T\u1ed1t nh\u1ea5t \u0111\u1ec3 t\u00ecm t\u1ea5t c\u1ea3 c\u00e1c c\u1ea1nh \u0111i ra t\u1eeb m\u1ed9t \u0111\u1ec9nh.</li> <li>CSC: T\u1ed1t nh\u1ea5t \u0111\u1ec3 t\u00ecm t\u1ea5t c\u1ea3 c\u00e1c c\u1ea1nh \u0111i v\u00e0o m\u1ed9t \u0111\u1ec9nh.</li> <li>COO: Danh s\u00e1ch \u0111\u01a1n gi\u1ea3n c\u00e1c c\u1ea1nh; t\u1ed1t cho x\u1eed l\u00fd t\u1eadp trung v\u00e0o c\u1ea1nh.</li> </ul>"},{"location":"cuda/pmpp/chapter-15/#vi-bfs","title":"15.2 T\u00ecm ki\u1ebfm theo chi\u1ec1u r\u1ed9ng (BFS)","text":"<p>M\u1ee5c ti\u00eau: Kh\u00e1m ph\u00e1 kho\u1ea3ng c\u00e1ch ng\u1eafn nh\u1ea5t (t\u00ednh theo \"s\u1ed1 b\u01b0\u1edbc nh\u1ea3y - hops\") t\u1eeb m\u1ed9t \u0111\u1ec9nh g\u1ed1c \u0111\u1ebfn t\u1ea5t c\u1ea3 c\u00e1c \u0111\u1ec9nh kh\u00e1c.</p> <p>C\u00e1c m\u1eb7t s\u00f3ng (Wavefronts): BFS ti\u1ebfn h\u00e0nh theo c\u00e1c c\u1ea5p \u0111\u1ed9 (C\u1ea5p 0 \\(\\rightarrow\\) C\u1ea5p 1 \\(\\rightarrow\\) ...). M\u1ed7i c\u1ea5p \u0111\u1ed9 t\u1ea1o th\u00e0nh m\u1ed9t \"m\u1eb7t s\u00f3ng\" c\u1ee7a c\u00e1c \u0111\u1ec9nh m\u1edbi \u0111\u01b0\u1ee3c kh\u00e1m ph\u00e1.</p> <p>\u1ee8ng d\u1ee5ng (CAD): Gi\u1ea3i th\u00edch v\u1ec1 Maze Routing (\u0110\u1ecbnh tuy\u1ebfn m\u00ea cung), n\u01a1i BFS t\u00ecm \u0111\u01b0\u1eddng ng\u1eafn nh\u1ea5t cho m\u1ed9t s\u1ee3i d\u00e2y tr\u00ean vi m\u1ea1ch trong khi tr\u00e1nh c\u00e1c ch\u01b0\u1edbng ng\u1ea1i v\u1eadt.</p>"},{"location":"cuda/pmpp/chapter-15/#vi-push-pull","title":"15.3 Song song h\u00f3a l\u1ea5y \u0111\u1ec9nh l\u00e0m trung t\u00e2m (Push vs. Pull)","text":"<p>Push (Top-Down): C\u00e1c lu\u1ed3ng \u0111\u01b0\u1ee3c g\u00e1n cho c\u00e1c \u0111\u1ec9nh \u1edf c\u1ea5p \u0111\u1ed9 hi\u1ec7n t\u1ea1i. Ch\u00fang \"\u0111\u1ea9y (push)\" tr\u1ea1ng th\u00e1i c\u1ee7a m\u00ecnh t\u1edbi c\u00e1c n\u00fat l\u00e2n c\u1eadn.</p> <ul> <li>\u01afu \u0111i\u1ec3m: Hi\u1ec7u qu\u1ea3 khi m\u1eb7t s\u00f3ng nh\u1ecf (c\u00e1c c\u1ea5p \u0111\u1ed9 \u0111\u1ea7u).</li> <li>Nh\u01b0\u1ee3c \u0111i\u1ec3m: Tranh ch\u1ea5p cao khi nhi\u1ec1u n\u00fat cha c\u1ed1 g\u1eafng c\u1eadp nh\u1eadt c\u00f9ng m\u1ed9t n\u00fat con.</li> </ul> <p>Pull (Bottom-Up): C\u00e1c lu\u1ed3ng \u0111\u01b0\u1ee3c g\u00e1n cho c\u00e1c \u0111\u1ec9nh ch\u01b0a \u0111\u01b0\u1ee3c th\u0103m. Ch\u00fang \"k\u00e9o (pull)\" tr\u1ea1ng th\u00e1i t\u1eeb c\u00e1c n\u00fat l\u00e2n c\u1eadn \u0111\u1ec3 xem c\u00f3 n\u00fat n\u00e0o thu\u1ed9c c\u1ea5p \u0111\u1ed9 tr\u01b0\u1edbc \u0111\u00f3 kh\u00f4ng.</p> <ul> <li>\u01afu \u0111i\u1ec3m: Tuy\u1ec7t v\u1eddi cho c\u00e1c \u0111\u1ed3 th\u1ecb \"Th\u1ebf gi\u1edbi nh\u1ecf\" (nh\u01b0 m\u1ea1ng x\u00e3 h\u1ed9i) \u1edf c\u00e1c c\u1ea5p \u0111\u1ed9 sau khi h\u1ea7u h\u1ebft c\u00e1c \u0111\u1ec9nh \u0111\u00e3 \u0111\u01b0\u1ee3c th\u0103m.</li> </ul> <p>Direction-Optimized BFS: M\u1ed9t t\u1ed1i \u01b0u h\u00f3a quan tr\u1ecdng gi\u00fap chuy\u1ec3n \u0111\u1ed5i t\u1eeb Push sang Pull gi\u1eefa qu\u00e1 tr\u00ecnh th\u1ef1c thi \u0111\u1ec3 t\u1ed1i \u0111a h\u00f3a hi\u1ec7u qu\u1ea3.</p>"},{"location":"cuda/pmpp/chapter-15/#vi-edge-centric","title":"15.4 Song song h\u00f3a l\u1ea5y c\u1ea1nh l\u00e0m trung t\u00e2m","text":"<p>C\u00e1ch ti\u1ebfp c\u1eadn: G\u00e1n m\u1ed9t lu\u1ed3ng cho m\u1ecdi c\u1ea1nh trong \u0111\u1ed3 th\u1ecb.</p> <p>L\u1ee3i \u00edch: Cung c\u1ea5p kh\u1ea3 n\u0103ng c\u00e2n b\u1eb1ng t\u1ea3i t\u1ed1t h\u01a1n cho c\u00e1c \u0111\u1ed3 th\u1ecb c\u00f3 s\u1ef1 thay \u0111\u1ed5i l\u1edbn v\u1ec1 b\u1eadc c\u1ee7a \u0111\u1ec9nh (v\u00ed d\u1ee5: m\u1ed9t \u0111\u1ec9nh \"ng\u01b0\u1eddi n\u1ed5i ti\u1ebfng\" v\u1edbi h\u00e0ng tri\u1ec7u c\u1ea1nh v\u00e0 m\u1ed9t \u0111\u1ec9nh \"b\u00ecnh th\u01b0\u1eddng\" v\u1edbi m\u01b0\u1eddi c\u1ea1nh).</p> <p>H\u1ea1n ch\u1ebf: T\u1eebng c\u1ea1nh m\u1ed9t \u0111\u1ec1u b\u1ecb ki\u1ec3m tra \u1edf m\u1ecdi c\u1ea5p \u0111\u1ed9, \u0111i\u1ec1u n\u00e0y g\u00e2y l\u00e3ng ph\u00ed cho c\u00e1c \u0111\u1ed3 th\u1ecb l\u1edbn v\u00e0 s\u00e2u.</p>"},{"location":"cuda/pmpp/chapter-15/#vi-frontiers","title":"15.5 C\u1ea3i thi\u1ec7n hi\u1ec7u qu\u1ea3 v\u1edbi Frontiers (Bi\u00ean)","text":"<p>V\u1ea5n \u0111\u1ec1: Kh\u1edfi ch\u1ea1y m\u1ed9t lu\u1ed3ng cho m\u1ecdi \u0111\u1ec9nh trong \u0111\u1ed3 th\u1ecb l\u00e0 l\u00e3ng ph\u00ed n\u1ebfu ch\u1ec9 c\u00f3 1% \u0111ang ho\u1ea1t \u0111\u1ed9ng.</p> <p>Gi\u1ea3i ph\u00e1p: S\u1eed d\u1ee5ng m\u1ed9t Frontier (m\u1ed9t danh s\u00e1ch ch\u1ec9 ch\u1ee9a c\u00e1c \u0111\u1ec9nh hi\u1ec7n \u0111ang ho\u1ea1t \u0111\u1ed9ng).</p> <p>Tranh ch\u1ea5p (Atomics): Y\u00eau c\u1ea7u <code>atomicCAS</code> (Compare-And-Swap) \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o m\u1ed9t \u0111\u1ec9nh ch\u1ec9 \u0111\u01b0\u1ee3c th\u00eam v\u00e0o frontier m\u1ed9t l\u1ea7n, ngay c\u1ea3 khi nhi\u1ec1u n\u00fat l\u00e2n c\u1eadn c\u00f9ng l\u00fac kh\u00e1m ph\u00e1 ra n\u00f3.</p>"},{"location":"cuda/pmpp/chapter-15/#vi-privatization","title":"15.6 Gi\u1ea3m tranh ch\u1ea5p v\u1edbi Privatization","text":"<p>N\u00fat th\u1eaft c\u1ed5 chai: H\u00e0ng ngh\u00ecn lu\u1ed3ng c\u1ed1 g\u1eafng <code>atomicAdd</code> v\u00e0o frontier to\u00e0n c\u1ee5c g\u00e2y ra m\u1ed9t \"\u0111i\u1ec3m n\u00f3ng\" l\u1edbn trong b\u1ed9 nh\u1edb.</p> <p>Chi\u1ebfn l\u01b0\u1ee3c: M\u1ed7i kh\u1ed1i lu\u1ed3ng (thread block) x\u00e2y d\u1ef1ng m\u1ed9t Frontier ri\u00eang trong Shared Memory. Sau khi \u0111\u1ea7y, kh\u1ed1i th\u1ef1c hi\u1ec7n m\u1ed9t thao t\u00e1c atomic to\u00e0n c\u1ee5c duy nh\u1ea5t \u0111\u1ec3 h\u1ee3p nh\u1ea5t c\u00e1c k\u1ebft qu\u1ea3 c\u1ee7a n\u00f3.</p> <p>K\u1ebft qu\u1ea3: Gi\u1ea3m \u0111\u00e1ng k\u1ec3 s\u1ed1 l\u01b0\u1ee3ng xung \u0111\u1ed9t b\u1ed9 nh\u1edb to\u00e0n c\u1ee5c.</p>"},{"location":"cuda/pmpp/chapter-15/#vi-other","title":"15.7 C\u00e1c t\u1ed1i \u01b0u h\u00f3a kh\u00e1c","text":"<ul> <li>Gi\u1ea3m chi ph\u00ed kh\u1edfi ch\u1ea1y: \u0110\u1ed1i v\u1edbi c\u00e1c frontier nh\u1ecf, nhi\u1ec1u c\u1ea5p \u0111\u1ed9 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c x\u1eed l\u00fd trong m\u1ed9t l\u1ea7n kh\u1edfi ch\u1ea1y kernel duy nh\u1ea5t b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng <code>__syncthreads()</code>, thay v\u00ec quay l\u1ea1i CPU.</li> <li>C\u1ea3i thi\u1ec7n c\u00e2n b\u1eb1ng t\u1ea3i: C\u00e1c \u0111\u1ec9nh c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c \"ph\u00e2n nh\u00f3m\" theo b\u1eadc c\u1ee7a ch\u00fang. C\u00e1c \u0111\u1ec9nh \"ng\u01b0\u1eddi n\u1ed5i ti\u1ebfng\" \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi to\u00e0n b\u1ed9 c\u00e1c kh\u1ed1i, trong khi c\u00e1c \u0111\u1ec9nh \"b\u1eadc th\u1ea5p\" \u0111\u01b0\u1ee3c x\u1eed l\u00fd b\u1edfi c\u00e1c lu\u1ed3ng \u0111\u01a1n l\u1ebb.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 15 d\u1ea1y r\u1eb1ng kh\u00f4ng c\u00f3 thu\u1eadt to\u00e1n \"v\u1ea1n n\u0103ng\" cho \u0111\u1ed3 th\u1ecb. Hi\u1ec7u su\u1ea5t ph\u1ee5 thu\u1ed9c v\u00e0o c\u1ea5u tr\u00fac (topology) c\u1ee7a \u0111\u1ed3 th\u1ecb. B\u1ea1n ph\u1ea3i s\u1eed d\u1ee5ng Frontiers \u0111\u1ec3 gi\u1edbi h\u1ea1n c\u00f4ng vi\u1ec7c, Privatization \u0111\u1ec3 x\u1eed l\u00fd tranh ch\u1ea5p, v\u00e0 Direction-Optimization \u0111\u1ec3 th\u00edch \u1ee9ng v\u1edbi m\u1eb7t s\u00f3ng ng\u00e0y c\u00e0ng m\u1edf r\u1ed9ng c\u1ee7a qu\u00e1 tr\u00ecnh t\u00ecm ki\u1ebfm.</p>"},{"location":"cuda/pmpp/chapter-16/","title":"Chapter 16: Deep Learning","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter acts as a major application case study, showing how the parallel patterns learned in previous chapters (specifically convolution and matrix multiplication) form the backbone of modern Artificial Intelligence.</p> <p>Ch\u01b0\u01a1ng n\u00e0y \u0111\u00f3ng vai tr\u00f2 nh\u01b0 m\u1ed9t nghi\u00ean c\u1ee9u \u0111i\u1ec3n h\u00ecnh v\u1ec1 \u1ee9ng d\u1ee5ng quan tr\u1ecdng, ch\u1ec9 ra c\u00e1ch c\u00e1c m\u1eabu song song \u0111\u00e3 h\u1ecdc \u1edf c\u00e1c ch\u01b0\u01a1ng tr\u01b0\u1edbc (c\u1ee5 th\u1ec3 l\u00e0 ph\u00e9p t\u00edch ch\u1eadp v\u00e0 nh\u00e2n ma tr\u1eadn) t\u1ea1o n\u00ean khung x\u01b0\u01a1ng cho Tr\u00ed tu\u1ec7 Nh\u00e2n t\u1ea1o hi\u1ec7n \u0111\u1ea1i.</p>"},{"location":"cuda/pmpp/chapter-16/#en-background","title":"16.1 Background","text":"<p>Machine Learning Definition: A field of study where computers learn logic from data rather than being explicitly programmed.</p> <p>The Perceptron: The simplest linear classifier (\\(y = \\text{sign}(W \\cdot x + b)\\)). It uses weights (\\(W\\)) and a bias (\\(b\\)) to categorize data.</p> <p>Activation Functions: Functions like Sigmoid or ReLU (Rectified Linear Unit) that introduce nonlinearity, allowing the network to learn complex patterns.</p> <p>Multilayer Perceptrons (MLP): Stacking layers of neurons where the output of one layer is the input to the next.</p> <p>Fully Connected (FC) Layers: A layer where every input is connected to every output. Computationally, this is a Matrix-Vector Multiplication.</p> <p>Training and Backpropagation:</p> <ul> <li>Loss/Error Function: Measures the difference between the network's guess and the correct label.</li> <li>Stochastic Gradient Descent (SGD): The process of iteratively updating weights to minimize error.</li> <li>Chain Rule: Used in Backpropagation to calculate how much each weight contributed to the final error.</li> </ul>"},{"location":"cuda/pmpp/chapter-16/#en-cnn","title":"16.2 Convolutional Neural Networks (CNN)","text":"<p>Why CNNs?: Fully connected layers are too expensive for high-resolution images. CNNs reduce cost by using Convolutional Layers that look at small patches of an image.</p> <p>Structure: Typically consists of Convolutional layers (feature extraction), Pooling/Subsampling layers (size reduction), and FC layers (final classification).</p> <p>Feature Maps: The input and output \"images\" of each layer.</p> <p>3D Filter Banks: In deep learning, convolution is 3D; a filter bank (\\(W\\)) is applied across multiple input channels (\\(C\\)) to produce an output feature map.</p>"},{"location":"cuda/pmpp/chapter-16/#en-inference","title":"16.3 Convolutional Layer: A CUDA Inference Kernel","text":"<p>Parallelism Levels: CNNs offer massive parallelism across:</p> <ol> <li>Samples (\\(N\\)): Different images in a minibatch.</li> <li>Feature Maps (\\(M\\)): Different filters applied to the same image.</li> <li>Pixels (\\(h, w\\)): Different locations in the output image.</li> </ol> <p>Thread Mapping: Assigning 2D thread blocks to output pixels and using the 3D grid dimensions to handle different feature maps and minibatch samples.</p>"},{"location":"cuda/pmpp/chapter-16/#en-gemm","title":"16.4 Formulating a Convolutional Layer as GEMM","text":"<p>The Problem: Writing a custom kernel for every possible filter size is difficult and often less efficient than standard math libraries.</p> <p>The Solution (im2col): Unrolling and duplicating the input feature map pixels into a large matrix (\\(X_{\\text{unrolled}}\\)).</p> <p>Mechanism: By rearranging the data, a 3D convolution can be performed as a single, massive GEMM (General Matrix Multiply) operation.</p> <p>Trade-off: This uses significantly more memory (due to pixel duplication) but allows the GPU to use highly optimized libraries like cuBLAS, which achieve near-peak hardware performance.</p>"},{"location":"cuda/pmpp/chapter-16/#en-cudnn","title":"16.5 cuDNN Library","text":"<p>Overview: NVIDIA's library of highly optimized routines for deep learning.</p> <p>Features: It handles the complexity of \"lazy\" memory management (generating unrolled matrices on the fly in on-chip memory) to avoid the memory waste described in the im2col approach.</p> <p>Utility: Most frameworks (PyTorch, TensorFlow) use cuDNN under the hood to ensure maximum performance without requiring engineers to write their own CUDA kernels.</p> <p>Key Takeaway: Chapter 16 bridges theory and practice. It shows that while the \"math\" of AI involves complex neural structures, the \"execution\" on a GPU relies on transforming these structures into Matrix Multiplications and Tiled Convolutions, utilizing the exact performance optimizations (coalescing, tiling, and latency hiding) taught in Part I.</p>"},{"location":"cuda/pmpp/chapter-16/#vi-background","title":"16.1 B\u1ed1i c\u1ea3nh","text":"<p>\u0110\u1ecbnh ngh\u0129a H\u1ecdc m\u00e1y: M\u1ed9t l\u0129nh v\u1ef1c nghi\u00ean c\u1ee9u n\u01a1i m\u00e1y t\u00ednh h\u1ecdc logic t\u1eeb d\u1eef li\u1ec7u thay v\u00ec \u0111\u01b0\u1ee3c l\u1eadp tr\u00ecnh m\u1ed9t c\u00e1ch r\u00f5 r\u00e0ng.</p> <p>Perceptron: B\u1ed9 ph\u00e2n lo\u1ea1i tuy\u1ebfn t\u00ednh \u0111\u01a1n gi\u1ea3n nh\u1ea5t (\\(y = \\text{sign}(W \\cdot x + b)\\)). N\u00f3 s\u1eed d\u1ee5ng c\u00e1c tr\u1ecdng s\u1ed1 (\\(W\\)) v\u00e0 m\u1ed9t \u0111\u1ed9 l\u1ec7ch (bias - \\(b\\)) \u0111\u1ec3 ph\u00e2n lo\u1ea1i d\u1eef li\u1ec7u.</p> <p>H\u00e0m k\u00edch ho\u1ea1t: C\u00e1c h\u00e0m nh\u01b0 Sigmoid ho\u1eb7c ReLU (Rectified Linear Unit) gi\u00fap \u0111\u01b0a t\u00ednh phi tuy\u1ebfn t\u00ednh v\u00e0o, cho ph\u00e9p m\u1ea1ng h\u1ecdc c\u00e1c m\u1eabu ph\u1ee9c t\u1ea1p.</p> <p>Multilayer Perceptrons (MLP): Vi\u1ec7c x\u1ebfp ch\u1ed3ng c\u00e1c l\u1edbp n\u01a1-ron n\u01a1i \u0111\u1ea7u ra c\u1ee7a l\u1edbp n\u00e0y l\u00e0 \u0111\u1ea7u v\u00e0o c\u1ee7a l\u1edbp ti\u1ebfp theo.</p> <p>L\u1edbp k\u1ebft n\u1ed1i \u0111\u1ea7y \u0111\u1ee7 (Fully Connected - FC): M\u1ed9t l\u1edbp m\u00e0 m\u1ecdi \u0111\u1ea7u v\u00e0o \u0111\u1ec1u \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i v\u1edbi m\u1ecdi \u0111\u1ea7u ra. V\u1ec1 m\u1eb7t t\u00ednh to\u00e1n, \u0111\u00e2y l\u00e0 m\u1ed9t ph\u00e9p Nh\u00e2n Ma tr\u1eadn - Vector.</p> <p>Hu\u1ea5n luy\u1ec7n v\u00e0 Lan truy\u1ec1n ng\u01b0\u1ee3c (Backpropagation):</p> <ul> <li>H\u00e0m m\u1ea5t m\u00e1t/sai s\u1ed1 (Loss/Error Function): \u0110o l\u01b0\u1eddng s\u1ef1 kh\u00e1c bi\u1ec7t gi\u1eefa d\u1ef1 \u0111o\u00e1n c\u1ee7a m\u1ea1ng v\u00e0 nh\u00e3n ch\u00ednh x\u00e1c.</li> <li>Stochastic Gradient Descent (SGD): Qu\u00e1 tr\u00ecnh c\u1eadp nh\u1eadt c\u00e1c tr\u1ecdng s\u1ed1 theo c\u00e1ch l\u1eb7p l\u1ea1i \u0111\u1ec3 gi\u1ea3m thi\u1ec3u sai s\u1ed1.</li> <li>Quy t\u1eafc chu\u1ed7i (Chain Rule): \u0110\u01b0\u1ee3c s\u1eed d\u1ee5ng trong Lan truy\u1ec1n ng\u01b0\u1ee3c \u0111\u1ec3 t\u00ednh to\u00e1n xem m\u1ed7i tr\u1ecdng s\u1ed1 \u0111\u00e3 \u0111\u00f3ng g\u00f3p bao nhi\u00eau v\u00e0o sai s\u1ed1 cu\u1ed1i c\u00f9ng.</li> </ul>"},{"location":"cuda/pmpp/chapter-16/#vi-cnn","title":"16.2 M\u1ea1ng n\u01a1-ron t\u00edch ch\u1eadp (CNN)","text":"<p>T\u1ea1i sao l\u1ea1i l\u00e0 CNN?: C\u00e1c l\u1edbp k\u1ebft n\u1ed1i \u0111\u1ea7y \u0111\u1ee7 qu\u00e1 t\u1ed1n k\u00e9m \u0111\u1ed1i v\u1edbi c\u00e1c h\u00ecnh \u1ea3nh c\u00f3 \u0111\u1ed9 ph\u00e2n gi\u1ea3i cao. CNN gi\u1ea3m chi ph\u00ed b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng c\u00e1c L\u1edbp t\u00edch ch\u1eadp qu\u00e9t qua c\u00e1c v\u00f9ng nh\u1ecf c\u1ee7a h\u00ecnh \u1ea3nh.</p> <p>C\u1ea5u tr\u00fac: Th\u01b0\u1eddng bao g\u1ed3m c\u00e1c l\u1edbp T\u00edch ch\u1eadp (tr\u00edch xu\u1ea5t \u0111\u1eb7c tr\u01b0ng), c\u00e1c l\u1edbp Pooling/Subsampling (gi\u1ea3m k\u00edch th\u01b0\u1edbc), v\u00e0 c\u00e1c l\u1edbp FC (ph\u00e2n lo\u1ea1i cu\u1ed1i c\u00f9ng).</p> <p>B\u1ea3n \u0111\u1ed3 \u0111\u1eb7c tr\u01b0ng (Feature Maps): \"H\u00ecnh \u1ea3nh\" \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra c\u1ee7a m\u1ed7i l\u1edbp.</p> <p>B\u1ed9 l\u1ecdc 3D (3D Filter Banks): Trong h\u1ecdc s\u00e2u, ph\u00e9p t\u00edch ch\u1eadp l\u00e0 3D; m\u1ed9t b\u1ed9 l\u1ecdc (\\(W\\)) \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng tr\u00ean nhi\u1ec1u k\u00eanh \u0111\u1ea7u v\u00e0o (\\(C\\)) \u0111\u1ec3 t\u1ea1o ra m\u1ed9t b\u1ea3n \u0111\u1ed3 \u0111\u1eb7c tr\u01b0ng \u0111\u1ea7u ra.</p>"},{"location":"cuda/pmpp/chapter-16/#vi-inference","title":"16.3 L\u1edbp t\u00edch ch\u1eadp: M\u1ed9t Kernel suy lu\u1eadn CUDA","text":"<p>C\u00e1c c\u1ea5p \u0111\u1ed9 song song: CNN cung c\u1ea5p kh\u1ea3 n\u0103ng song song h\u00f3a kh\u1ed5ng l\u1ed3 tr\u00ean:</p> <ol> <li>M\u1eabu (\\(N\\)): C\u00e1c h\u00ecnh \u1ea3nh kh\u00e1c nhau trong m\u1ed9t minibatch.</li> <li>B\u1ea3n \u0111\u1ed3 \u0111\u1eb7c tr\u01b0ng (\\(M\\)): C\u00e1c b\u1ed9 l\u1ecdc kh\u00e1c nhau \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng cho c\u00f9ng m\u1ed9t h\u00ecnh \u1ea3nh.</li> <li>Pixel (\\(h, w\\)): C\u00e1c v\u1ecb tr\u00ed kh\u00e1c nhau trong h\u00ecnh \u1ea3nh \u0111\u1ea7u ra.</li> </ol> <p>\u00c1nh x\u1ea1 lu\u1ed3ng: G\u00e1n c\u00e1c kh\u1ed1i lu\u1ed3ng (thread blocks) 2D cho c\u00e1c pixel \u0111\u1ea7u ra v\u00e0 s\u1eed d\u1ee5ng k\u00edch th\u01b0\u1edbc l\u01b0\u1edbi (grid) 3D \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c b\u1ea3n \u0111\u1ed3 \u0111\u1eb7c tr\u01b0ng v\u00e0 c\u00e1c m\u1eabu minibatch kh\u00e1c nhau.</p>"},{"location":"cuda/pmpp/chapter-16/#vi-gemm","title":"16.4 X\u00e2y d\u1ef1ng L\u1edbp t\u00edch ch\u1eadp d\u01b0\u1edbi d\u1ea1ng GEMM","text":"<p>V\u1ea5n \u0111\u1ec1: Vi\u1ec7c vi\u1ebft m\u1ed9t kernel t\u00f9y ch\u1ec9nh cho m\u1ecdi k\u00edch th\u01b0\u1edbc b\u1ed9 l\u1ecdc c\u00f3 th\u1ec3 l\u00e0 r\u1ea5t kh\u00f3 kh\u0103n v\u00e0 th\u01b0\u1eddng k\u00e9m hi\u1ec7u qu\u1ea3 h\u01a1n c\u00e1c th\u01b0 vi\u1ec7n to\u00e1n h\u1ecdc ti\u00eau chu\u1ea9n.</p> <p>Gi\u1ea3i ph\u00e1p (im2col): Tr\u1ea3i ph\u1eb3ng v\u00e0 nh\u00e2n b\u1ea3n c\u00e1c pixel c\u1ee7a b\u1ea3n \u0111\u1ed3 \u0111\u1eb7c tr\u01b0ng \u0111\u1ea7u v\u00e0o th\u00e0nh m\u1ed9t ma tr\u1eadn l\u1edbn (\\(X_{\\text{unrolled}}\\)).</p> <p>C\u01a1 ch\u1ebf: B\u1eb1ng c\u00e1ch s\u1eafp x\u1ebfp l\u1ea1i d\u1eef li\u1ec7u, m\u1ed9t ph\u00e9p t\u00edch ch\u1eadp 3D c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n nh\u01b0 m\u1ed9t ph\u00e9p to\u00e1n GEMM (General Matrix Multiply) duy nh\u1ea5t v\u00e0 kh\u1ed5ng l\u1ed3.</p> <p>\u0110\u00e1nh \u0111\u1ed5i: C\u00e1ch n\u00e0y s\u1eed d\u1ee5ng nhi\u1ec1u b\u1ed9 nh\u1edb h\u01a1n \u0111\u00e1ng k\u1ec3 (do nh\u00e2n b\u1ea3n pixel) nh\u01b0ng cho ph\u00e9p GPU s\u1eed d\u1ee5ng c\u00e1c th\u01b0 vi\u1ec7n t\u1ed1i \u01b0u h\u00f3a cao nh\u01b0 cuBLAS, \u0111\u1ea1t \u0111\u01b0\u1ee3c hi\u1ec7u su\u1ea5t ph\u1ea7n c\u1ee9ng g\u1ea7n m\u1ee9c t\u1ed1i \u0111a.</p>"},{"location":"cuda/pmpp/chapter-16/#vi-cudnn","title":"16.5 Th\u01b0 vi\u1ec7n cuDNN","text":"<p>T\u1ed5ng quan: Th\u01b0 vi\u1ec7n c\u1ee7a NVIDIA ch\u1ee9a c\u00e1c quy tr\u00ecnh \u0111\u01b0\u1ee3c t\u1ed1i \u01b0u h\u00f3a cao cho h\u1ecdc s\u00e2u.</p> <p>T\u00ednh n\u0103ng: N\u00f3 x\u1eed l\u00fd s\u1ef1 ph\u1ee9c t\u1ea1p c\u1ee7a vi\u1ec7c qu\u1ea3n l\u00fd b\u1ed9 nh\u1edb \"lazy\" (t\u1ea1o c\u00e1c ma tr\u1eadn tr\u1ea3i ph\u1eb3ng ngay l\u1eadp t\u1ee9c trong b\u1ed9 nh\u1edb tr\u00ean chip) \u0111\u1ec3 tr\u00e1nh l\u00e3ng ph\u00ed b\u1ed9 nh\u1edb nh\u01b0 m\u00f4 t\u1ea3 trong c\u00e1ch ti\u1ebfp c\u1eadn im2col.</p> <p>Ti\u1ec7n \u00edch: H\u1ea7u h\u1ebft c\u00e1c khung (PyTorch, TensorFlow) \u0111\u1ec1u s\u1eed d\u1ee5ng cuDNN b\u00ean d\u01b0\u1edbi \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o hi\u1ec7u su\u1ea5t t\u1ed1i \u0111a m\u00e0 kh\u00f4ng y\u00eau c\u1ea7u c\u00e1c k\u1ef9 s\u01b0 ph\u1ea3i t\u1ef1 vi\u1ebft c\u00e1c kernel CUDA.</p> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 16 k\u1ebft n\u1ed1i l\u00fd thuy\u1ebft v\u00e0 th\u1ef1c h\u00e0nh. N\u00f3 ch\u1ec9 ra r\u1eb1ng m\u1eb7c d\u00f9 \"to\u00e1n h\u1ecdc\" c\u1ee7a AI li\u00ean quan \u0111\u1ebfn c\u00e1c c\u1ea5u tr\u00fac n\u01a1-ron ph\u1ee9c t\u1ea1p, vi\u1ec7c \"th\u1ef1c thi\" tr\u00ean GPU d\u1ef1a tr\u00ean vi\u1ec7c chuy\u1ec3n \u0111\u1ed5i c\u00e1c c\u1ea5u tr\u00fac n\u00e0y th\u00e0nh c\u00e1c ph\u00e9p Nh\u00e2n Ma tr\u1eadn v\u00e0 T\u00edch ch\u1eadp Tiled, s\u1eed d\u1ee5ng ch\u00ednh x\u00e1c c\u00e1c t\u1ed1i \u01b0u h\u00f3a hi\u1ec7u su\u1ea5t (coalescing, tiling v\u00e0 che gi\u1ea5u \u0111\u1ed9 tr\u1ec5) \u0111\u00e3 \u0111\u01b0\u1ee3c d\u1ea1y \u1edf Ph\u1ea7n I.</p>"},{"location":"cuda/pmpp/chapter-17/","title":"Chapter 17: MRI Reconstruction","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>Magnetic Resonance Imaging (MRI) is a vital medical diagnostic tool. This chapter uses MRI reconstruction to demonstrate how to optimize kernels that involve complex mathematical formulas and high memory bandwidth requirements.</p> <p>Ch\u1ee5p c\u1ed9ng h\u01b0\u1edfng t\u1eeb (MRI) l\u00e0 m\u1ed9t c\u00f4ng c\u1ee5 ch\u1ea9n \u0111o\u00e1n y t\u1ebf quan tr\u1ecdng. Ch\u01b0\u01a1ng n\u00e0y s\u1eed d\u1ee5ng qu\u00e1 tr\u00ecnh t\u00e1i t\u1ea1o h\u00ecnh \u1ea3nh MRI \u0111\u1ec3 minh h\u1ecda c\u00e1ch t\u1ed1i \u01b0u h\u00f3a c\u00e1c kernel li\u00ean quan \u0111\u1ebfn c\u00e1c c\u00f4ng th\u1ee9c to\u00e1n h\u1ecdc ph\u1ee9c t\u1ea1p v\u00e0 y\u00eau c\u1ea7u b\u0103ng th\u00f4ng b\u1ed9 nh\u1edb cao.</p>"},{"location":"cuda/pmpp/chapter-17/#en-background","title":"17.1 Background","text":"<ul> <li>MRI Process: Consists of two phases: Acquisition (scanning) and Reconstruction (creating the image).</li> <li>K-Space: Data is sampled in the frequency domain (k-space).</li> <li>Cartesian vs. Non-Cartesian:<ul> <li>Cartesian scans are on a uniform grid and can be solved quickly using Fast Fourier Transforms (FFT).</li> <li>Non-Cartesian scans (e.g., spirals) are better for imaging moving organs or patients but are much harder to solve. They require Iterative Reconstruction.</li> </ul> </li> <li>The Bottleneck: On a high-end sequential CPU, a single 3D reconstruction can take 3 hours, which is too slow for clinical use.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#en-iterative","title":"17.2 Iterative Reconstruction","text":"<ul> <li>Mathematical Model: Uses a linear solver approach to estimate voxel values (\\(\\rho\\)) from irregular samples.</li> <li>Problem Scale: Even a modest \\(128^3\\) voxel reconstruction involves millions of calculations.</li> <li>Objective: Reduce reconstruction time from hours to minutes using the GPU.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#en-optimization","title":"17.3 Computing \\(F^H D\\) (Step-by-Step Optimization)","text":"<p>The core of the chapter involves optimizing the most expensive part of the solver, the calculation of the \\(F^H D\\) vector.</p>"},{"location":"cuda/pmpp/chapter-17/#step-1-parallelism-structure-scatter-vs-gather","title":"Step 1: Parallelism Structure (Scatter vs. Gather)","text":"<ul> <li>Scatter Approach: Each thread takes one input (k-space sample) and updates all output voxels. This requires heavy use of Atomic Operations, making it very slow.</li> <li>Gather Approach (Preferred): Each thread is assigned to one output voxel and \"gathers\" the contributions from all input samples. This eliminates the need for atomics and is much faster.</li> <li>Loop Fission: To enable the gather approach, the authors use \"loop fission\" to split the calculation into two separate kernels, ensuring data is ready when the threads need to gather it.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#step-2-managing-memory-bandwidth","title":"Step 2: Managing Memory Bandwidth","text":"<ul> <li>Register Usage: In the original loop, the thread repeatedly reads voxel coordinates \\((x, y, z)\\) from global memory.</li> <li>The Fix: Load these coordinates into Registers once before the loop starts. This increases the compute-to-memory ratio from 0.23 to 0.46 OP/B.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#step-3-hardware-trigonometry-sfus","title":"Step 3: Hardware Trigonometry (SFUs)","text":"<ul> <li>Trigonometry Bottleneck: The math requires constant <code>sin()</code> and <code>cos()</code> calls.</li> <li>The Fix: Use Intrinsic Functions (<code>__sin()</code>, <code>__cos()</code>). These are executed by the GPU's Special Function Units (SFU).</li> <li>Trade-off: These are much faster but slightly less accurate. The authors use PSNR (Peak Signal-to-Noise Ratio) to prove the accuracy loss is negligible for medical diagnosis.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#step-4-constant-memory-cache-efficiency","title":"Step 4: Constant Memory &amp; Cache Efficiency","text":"<ul> <li>Chunking: K-space data is too large for constant memory. The code breaks data into 64KB \"chunks\" and transfers them one by one.</li> <li>AoS (Array of Structures): Storing \\(k_x, k_y, k_z\\) in three separate arrays is inefficient for the constant cache. By using an Array of Structures, all three values fit into a single cache line, drastically reducing DRAM requests.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#en-summary","title":"17.4 Summary","text":"<ul> <li>Performance Gain: The final optimized version is roughly 10x faster than the basic GPU version and orders of magnitude faster than the CPU.</li> <li>Clinical Impact: By reducing reconstruction time to approximately one minute, advanced non-Cartesian MRI becomes a viable tool for doctors to use in real-time.</li> <li>Lesson: Successful optimization requires understanding the math (Gather vs. Scatter) and the hardware (SFUs and Constant Cache).</li> </ul> <p>Key Takeaway: Chapter 17 teaches that \"Porting\" code isn't enough. You must reformulate the algorithm (using Loop Fission and the Gather approach) to match GPU hardware strengths like the Special Function Units and Constant Cache.</p>"},{"location":"cuda/pmpp/chapter-17/#vi-background","title":"17.1 B\u1ed1i c\u1ea3nh","text":"<ul> <li>Quy tr\u00ecnh MRI: Bao g\u1ed3m hai giai \u0111o\u1ea1n: Thu nh\u1eadn (Acquisition) (qu\u00e9t) v\u00e0 T\u00e1i t\u1ea1o (Reconstruction) (t\u1ea1o ra h\u00ecnh \u1ea3nh).</li> <li>K-Space: D\u1eef li\u1ec7u \u0111\u01b0\u1ee3c l\u1ea5y m\u1eabu trong mi\u1ec1n t\u1ea7n s\u1ed1 (k-space).</li> <li>Cartesian vs. Non-Cartesian:<ul> <li>Qu\u00e9t Cartesian n\u1eb1m tr\u00ean m\u1ed9t l\u01b0\u1edbi \u0111\u1ed3ng nh\u1ea5t v\u00e0 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c gi\u1ea3i nhanh ch\u00f3ng b\u1eb1ng ph\u00e9p bi\u1ebfn \u0111\u1ed5i Fourier nhanh (FFT).</li> <li>Qu\u00e9t Non-Cartesian (v\u00ed d\u1ee5: xo\u1eafn \u1ed1c) t\u1ed1t h\u01a1n \u0111\u1ec3 ch\u1ee5p c\u00e1c c\u01a1 quan \u0111ang chuy\u1ec3n \u0111\u1ed9ng ho\u1eb7c b\u1ec7nh nh\u00e2n nh\u01b0ng kh\u00f3 gi\u1ea3i h\u01a1n nhi\u1ec1u. Ch\u00fang y\u00eau c\u1ea7u T\u00e1i t\u1ea1o l\u1eb7p (Iterative Reconstruction).</li> </ul> </li> <li>N\u00fat th\u1eaft c\u1ed5 chai: Tr\u00ean m\u1ed9t CPU tu\u1ea7n t\u1ef1 cao c\u1ea5p, m\u1ed9t l\u1ea7n t\u00e1i t\u1ea1o 3D duy nh\u1ea5t c\u00f3 th\u1ec3 m\u1ea5t 3 gi\u1edd, hi\u1ec7u su\u1ea5t n\u00e0y qu\u00e1 ch\u1eadm \u0111\u1ec3 s\u1eed d\u1ee5ng trong l\u00e2m s\u00e0ng.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#vi-iterative","title":"17.2 T\u00e1i t\u1ea1o l\u1eb7p","text":"<ul> <li>M\u00f4 h\u00ecnh to\u00e1n h\u1ecdc: S\u1eed d\u1ee5ng c\u00e1ch ti\u1ebfp c\u1eadn b\u1ed9 gi\u1ea3i tuy\u1ebfn t\u00ednh \u0111\u1ec3 \u01b0\u1edbc t\u00ednh gi\u00e1 tr\u1ecb voxel (\\(\\rho\\)) t\u1eeb c\u00e1c m\u1eabu kh\u00f4ng \u0111\u1ec1u.</li> <li>Quy m\u00f4 v\u1ea5n \u0111\u1ec1: Ngay c\u1ea3 m\u1ed9t b\u1ea3n t\u00e1i t\u1ea1o voxel \\(128^3\\) khi\u00eam t\u1ed1n c\u0169ng li\u00ean quan \u0111\u1ebfn h\u00e0ng tri\u1ec7u ph\u00e9p t\u00ednh.</li> <li>M\u1ee5c ti\u00eau: Gi\u1ea3m th\u1eddi gian t\u00e1i t\u1ea1o t\u1eeb h\u00e0ng gi\u1edd xu\u1ed1ng c\u00f2n v\u00e0i ph\u00fat b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng GPU.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#vi-optimization","title":"17.3 T\u00ednh to\u00e1n \\(F^H D\\) (T\u1ed1i \u01b0u h\u00f3a t\u1eebng b\u01b0\u1edbc)","text":"<p>Tr\u1ecdng t\u00e2m c\u1ee7a ch\u01b0\u01a1ng li\u00ean quan \u0111\u1ebfn vi\u1ec7c t\u1ed1i \u01b0u h\u00f3a ph\u1ea7n t\u1ed1n k\u00e9m nh\u1ea5t c\u1ee7a b\u1ed9 gi\u1ea3i, ph\u00e9p t\u00ednh vector \\(F^H D\\).</p>"},{"location":"cuda/pmpp/chapter-17/#buoc-1-cau-truc-song-song-scatter-vs-gather","title":"B\u01b0\u1edbc 1: C\u1ea5u tr\u00fac song song (Scatter vs. Gather)","text":"<ul> <li>C\u00e1ch ti\u1ebfp c\u1eadn Scatter (Ph\u00e2n t\u00e1n): M\u1ed7i lu\u1ed3ng l\u1ea5y m\u1ed9t \u0111\u1ea7u v\u00e0o (m\u1eabu k-space) v\u00e0 c\u1eadp nh\u1eadt t\u1ea5t c\u1ea3 c\u00e1c voxel \u0111\u1ea7u ra. \u0110i\u1ec1u n\u00e0y \u0111\u00f2i h\u1ecfi s\u1eed d\u1ee5ng nhi\u1ec1u Atomic Operations, khi\u1ebfn n\u00f3 r\u1ea5t ch\u1eadm.</li> <li>C\u00e1ch ti\u1ebfp c\u1eadn Gather (T\u1eadp h\u1ee3p - \u0110\u01b0\u1ee3c \u01b0u ti\u00ean): M\u1ed7i lu\u1ed3ng \u0111\u01b0\u1ee3c g\u00e1n cho m\u1ed9t voxel \u0111\u1ea7u ra v\u00e0 \"t\u1eadp h\u1ee3p\" c\u00e1c \u0111\u00f3ng g\u00f3p t\u1eeb t\u1ea5t c\u1ea3 c\u00e1c m\u1eabu \u0111\u1ea7u v\u00e0o. \u0110i\u1ec1u n\u00e0y lo\u1ea1i b\u1ecf nhu c\u1ea7u v\u1ec1 atomic v\u00e0 nhanh h\u01a1n nhi\u1ec1u.</li> <li>Loop Fission (Ph\u00e2n t\u00e1ch v\u00f2ng l\u1eb7p): \u0110\u1ec3 k\u00edch ho\u1ea1t c\u00e1ch ti\u1ebfp c\u1eadn Gather, c\u00e1c t\u00e1c gi\u1ea3 s\u1eed d\u1ee5ng \"loop fission\" \u0111\u1ec3 chia ph\u00e9p t\u00ednh th\u00e0nh hai kernel ri\u00eang bi\u1ec7t, \u0111\u1ea3m b\u1ea3o d\u1eef li\u1ec7u s\u1eb5n s\u00e0ng khi c\u00e1c lu\u1ed3ng c\u1ea7n t\u1eadp h\u1ee3p n\u00f3.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#buoc-2-quan-ly-bang-thong-bo-nho","title":"B\u01b0\u1edbc 2: Qu\u1ea3n l\u00fd b\u0103ng th\u00f4ng b\u1ed9 nh\u1edb","text":"<ul> <li>S\u1eed d\u1ee5ng Register: Trong v\u00f2ng l\u1eb7p ban \u0111\u1ea7u, lu\u1ed3ng \u0111\u1ecdc \u0111i \u0111\u1ecdc l\u1ea1i c\u00e1c t\u1ecda \u0111\u1ed9 voxel \\((x, y, z)\\) t\u1eeb b\u1ed9 nh\u1edb global.</li> <li>Gi\u1ea3i ph\u00e1p: T\u1ea3i c\u00e1c t\u1ecda \u0111\u1ed9 n\u00e0y v\u00e0o Registers m\u1ed9t l\u1ea7n tr\u01b0\u1edbc khi v\u00f2ng l\u1eb7p b\u1eaft \u0111\u1ea7u. \u0110i\u1ec1u n\u00e0y l\u00e0m t\u0103ng t\u1ef7 l\u1ec7 t\u00ednh to\u00e1n tr\u00ean b\u1ed9 nh\u1edb t\u1eeb 0.23 l\u00ean 0.46 OP/B.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#buoc-3-luong-giac-phan-cung-sfus","title":"B\u01b0\u1edbc 3: L\u01b0\u1ee3ng gi\u00e1c ph\u1ea7n c\u1ee9ng (SFUs)","text":"<ul> <li>N\u00fat th\u1eaft l\u01b0\u1ee3ng gi\u00e1c: C\u00e1c ph\u00e9p to\u00e1n y\u00eau c\u1ea7u c\u00e1c l\u1ec7nh g\u1ecdi <code>sin()</code> v\u00e0 <code>cos()</code> li\u00ean t\u1ee5c.</li> <li>Gi\u1ea3i ph\u00e1p: S\u1eed d\u1ee5ng c\u00e1c H\u00e0m n\u1ed9i t\u1ea1i (Intrinsic Functions) (<code>__sin()</code>, <code>__cos()</code>). C\u00e1c h\u00e0m n\u00e0y \u0111\u01b0\u1ee3c th\u1ef1c thi b\u1edfi c\u00e1c \u0110\u01a1n v\u1ecb ch\u1ee9c n\u0103ng \u0111\u1eb7c bi\u1ec7t (SFU) c\u1ee7a GPU.</li> <li>\u0110\u00e1nh \u0111\u1ed5i: C\u00e1c h\u00e0m n\u00e0y nhanh h\u01a1n nhi\u1ec1u nh\u01b0ng \u0111\u1ed9 ch\u00ednh x\u00e1c th\u1ea5p h\u01a1n m\u1ed9t ch\u00fat. C\u00e1c t\u00e1c gi\u1ea3 s\u1eed d\u1ee5ng PSNR (Peak Signal-to-Noise Ratio) \u0111\u1ec3 ch\u1ee9ng minh t\u1ed5n th\u1ea5t \u0111\u1ed9 ch\u00ednh x\u00e1c l\u00e0 kh\u00f4ng \u0111\u00e1ng k\u1ec3 \u0111\u1ed1i v\u1edbi ch\u1ea9n \u0111o\u00e1n y t\u1ebf.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#buoc-4-constant-memory-hieu-qua-cache","title":"B\u01b0\u1edbc 4: Constant Memory &amp; Hi\u1ec7u qu\u1ea3 Cache","text":"<ul> <li>Chia nh\u1ecf (Chunking): D\u1eef li\u1ec7u k-space qu\u00e1 l\u1edbn \u0111\u1ed1i v\u1edbi b\u1ed9 nh\u1edb constant. M\u00e3 ngu\u1ed3n chia d\u1eef li\u1ec7u th\u00e0nh c\u00e1c \"kh\u1ed1i\" 64KB v\u00e0 chuy\u1ec3n ch\u00fang t\u1eebng c\u00e1i m\u1ed9t.</li> <li>AoS (Array of Structures): L\u01b0u tr\u1eef \\(k_x, k_y, k_z\\) trong ba m\u1ea3ng ri\u00eang bi\u1ec7t l\u00e0 kh\u00f4ng hi\u1ec7u qu\u1ea3 cho b\u1ed9 nh\u1edb cache constant. B\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng M\u1ea3ng c\u00e1c c\u1ea5u tr\u00fac, c\u1ea3 ba gi\u00e1 tr\u1ecb n\u1eb1m g\u1ecdn trong m\u1ed9t d\u00f2ng cache duy nh\u1ea5t, gi\u1ea3m \u0111\u00e1ng k\u1ec3 c\u00e1c y\u00eau c\u1ea7u DRAM.</li> </ul>"},{"location":"cuda/pmpp/chapter-17/#vi-summary","title":"17.4 T\u00f3m t\u1eaft","text":"<ul> <li>C\u1ea3i thi\u1ec7n hi\u1ec7u su\u1ea5t: Phi\u00ean b\u1ea3n t\u1ed1i \u01b0u h\u00f3a cu\u1ed1i c\u00f9ng nhanh h\u01a1n kho\u1ea3ng 10 l\u1ea7n so v\u1edbi phi\u00ean b\u1ea3n GPU c\u01a1 b\u1ea3n v\u00e0 nhanh h\u01a1n nhi\u1ec1u b\u1eadc so v\u1edbi CPU.</li> <li>T\u00e1c \u0111\u1ed9ng l\u00e2m s\u00e0ng: B\u1eb1ng c\u00e1ch gi\u1ea3m th\u1eddi gian t\u00e1i t\u1ea1o xu\u1ed1ng c\u00f2n kho\u1ea3ng m\u1ed9t ph\u00fat, MRI non-Cartesian n\u00e2ng cao tr\u1edf th\u00e0nh m\u1ed9t c\u00f4ng c\u1ee5 kh\u1ea3 thi \u0111\u1ec3 c\u00e1c b\u00e1c s\u0129 s\u1eed d\u1ee5ng trong th\u1eddi gian th\u1ef1c.</li> <li>B\u00e0i h\u1ecdc: T\u1ed1i \u01b0u h\u00f3a th\u00e0nh c\u00f4ng \u0111\u00f2i h\u1ecfi s\u1ef1 hi\u1ec3u bi\u1ebft v\u1ec1 to\u00e1n h\u1ecdc (Gather vs. Scatter) v\u00e0 ph\u1ea7n c\u1ee9ng (SFUs v\u00e0 Constant Cache).</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 17 d\u1ea1y r\u1eb1ng vi\u1ec7c \"chuy\u1ec3n \u0111\u1ed5i\" m\u00e3 ngu\u1ed3n l\u00e0 kh\u00f4ng \u0111\u1ee7. B\u1ea1n ph\u1ea3i x\u00e2y d\u1ef1ng l\u1ea1i thu\u1eadt to\u00e1n (s\u1eed d\u1ee5ng Loop Fission v\u00e0 c\u00e1ch ti\u1ebfp c\u1eadn Gather) \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi th\u1ebf m\u1ea1nh ph\u1ea7n c\u1ee9ng c\u1ee7a GPU nh\u01b0 c\u00e1c \u0110\u01a1n v\u1ecb ch\u1ee9c n\u0103ng \u0111\u1eb7c bi\u1ec7t v\u00e0 Constant Cache.</p>"},{"location":"cuda/pmpp/chapter-18/","title":"Chapter 18: Molecular Dynamics and Spatial Binning","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter provides a case study in molecular dynamics. It demonstrates how to handle algorithms that have massive data sizes and how to transition from an accurate but slow algorithm to a highly scalable one.</p> <p>Ch\u01b0\u01a1ng n\u00e0y cung c\u1ea5p m\u1ed9t nghi\u00ean c\u1ee9u \u0111i\u1ec3n h\u00ecnh trong \u0111\u1ed9ng h\u1ecdc ph\u00e2n t\u1eed. N\u00f3 minh h\u1ecda c\u00e1ch x\u1eed l\u00fd c\u00e1c thu\u1eadt to\u00e1n c\u00f3 k\u00edch th\u01b0\u1edbc d\u1eef li\u1ec7u kh\u1ed5ng l\u1ed3 v\u00e0 c\u00e1ch chuy\u1ec3n \u0111\u1ed5i t\u1eeb m\u1ed9t thu\u1eadt to\u00e1n ch\u00ednh x\u00e1c nh\u01b0ng ch\u1eadm sang m\u1ed9t thu\u1eadt to\u00e1n c\u00f3 kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng cao.</p>"},{"location":"cuda/pmpp/chapter-18/#en-background","title":"18.1 Background","text":"<ul> <li>Visual Molecular Dynamics (VMD): A tool used by biologists to visualize biomolecular systems (viruses, proteins).</li> <li>The Problem: Calculating the \"Electrostatic Potential Map\"\u2014a grid where each point represents the electrical potential energy exerted by all atoms in a system.</li> <li>Direct Coulomb Summation (DCS): The potential at grid point \\(j\\) is the sum of (charge of atom \\(i\\) / distance between \\(i\\) and \\(j\\)).</li> <li>Computational Challenge: The complexity is \\(O(\\text{Atoms} \\times \\text{GridPoints})\\). As the volume of a system grows, the number of calculations grows quadratically, making it too slow for large biological systems.</li> </ul>"},{"location":"cuda/pmpp/chapter-18/#en-scatter-gather","title":"18.2 Scatter versus Gather in Kernel Design","text":"<ul> <li>Scatter Approach: Assign one thread to each atom. Each thread \"scatters\" its charge contribution to all grid points.<ul> <li>Problem: Multiple threads try to update the same grid point at once, requiring Atomic Operations which are extremely slow in this context.</li> </ul> </li> <li>Gather Approach: Assign one thread to each grid point. Each thread \"gathers\" the contribution from all atoms.<ul> <li>Benefit: No atomic operations are needed.</li> <li>Optimization: Since all grid points in a 2D slice share the same \\(Z\\) coordinate, the \\(Z\\)-distance of an atom only needs to be calculated once per slice and can be reused.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/chapter-18/#en-coarsening","title":"18.3 Thread Coarsening","text":"<ul> <li>Observation: All grid points in a single row share the same \\(Y\\) coordinate.</li> <li>The Optimization: Coarsen the thread so that one thread calculates four adjacent grid points in a row.</li> <li>Result: By calculating the \\(Y\\) and \\(Z\\) components of the distance once and reusing them for four points, the kernel drastically reduces the number of constant memory accesses and redundant math operations.</li> </ul>"},{"location":"cuda/pmpp/chapter-18/#en-coalescing","title":"18.4 Memory Coalescing","text":"<ul> <li>The Problem: If coarsened threads write to their four points in a simple sequence (Point 0, 1, 2, 3), the writes across the warp will be \"strided\" and uncoalesced.</li> <li>The Fix: Reorganize the thread mapping so that adjacent threads in a warp write to adjacent memory locations.</li> <li>Impact: This ensures the GPU can use a single memory transaction to write the results of 32 threads, maximizing write bandwidth.</li> </ul>"},{"location":"cuda/pmpp/chapter-18/#en-cutoff","title":"18.5 Cutoff Binning for Data Size Scalability","text":"<ul> <li>The Scaling Wall: For millions of atoms, even an optimized Gather kernel is too slow because it still checks every atom for every grid point.</li> <li>The Insight: The influence of an atom decreases with distance. Contributions from atoms far away are negligible.</li> <li>Cutoff Summation: Only calculate contributions from atoms within a fixed radius (e.g., 12 \u00c5ngstr\u00f6ms). This changes the complexity from \\(O(N^2)\\) to \\(O(N)\\).</li> <li>Spatial Binning: To avoid checking every atom to see if it is \"close,\" the system partitions the space into Bins (cubical boxes).</li> <li> <p>The Parallel Algorithm:</p> <ol> <li>Sort atoms into bins.</li> <li>For a block of grid points, identify a \"neighborhood\" of bins.</li> <li>Threads only iterate through the atoms contained in those specific neighbor bins.</li> </ol> </li> <li> <p>Overflow Handling: Since some bins might have more atoms than others, the system uses an \"overflow list\" for dense areas to maintain a regular workload for the GPU.</p> </li> </ul>"},{"location":"cuda/pmpp/chapter-18/#en-summary","title":"18.6 Summary","text":"<ul> <li>Transformation: The chapter tracks the journey from a basic \"Scatter\" kernel to a \"Gather\" kernel, then adds \"Coarsening\" and \"Coalescing.\"</li> <li>Final Result: The implementation of Cutoff Binning allows the application to handle massive molecular systems that were previously impossible to simulate.</li> <li>Lesson: Higher-level algorithmic changes (like moving to Bins and Cutoffs) often yield much larger speedups than low-level code tuning once the data size reaches a certain threshold.</li> </ul> <p>Key Takeaway: Chapter 18 teaches you how to manage Computational Complexity. It shows that while low-level hardware tuning (coalescing/registers) is important, scaling to \"Big Data\" requires smart data structures like Spatial Binning to avoid doing unnecessary work.</p>"},{"location":"cuda/pmpp/chapter-18/#vi-background","title":"18.1 B\u1ed1i c\u1ea3nh","text":"<ul> <li>Visual Molecular Dynamics (VMD): M\u1ed9t c\u00f4ng c\u1ee5 \u0111\u01b0\u1ee3c c\u00e1c nh\u00e0 sinh h\u1ecdc s\u1eed d\u1ee5ng \u0111\u1ec3 h\u00ecnh \u1ea3nh h\u00f3a c\u00e1c h\u1ec7 th\u1ed1ng ph\u00e2n t\u1eed sinh h\u1ecdc (virus, protein).</li> <li>V\u1ea5n \u0111\u1ec1: T\u00ednh to\u00e1n \"B\u1ea3n \u0111\u1ed3 ti\u1ec1m n\u0103ng t\u0129nh \u0111i\u1ec7n (Electrostatic Potential Map)\"\u2014m\u1ed9t l\u01b0\u1edbi n\u01a1i m\u1ed7i \u0111i\u1ec3m \u0111\u1ea1i di\u1ec7n cho th\u1ebf n\u0103ng \u0111i\u1ec7n \u0111\u01b0\u1ee3c t\u1ea1o ra b\u1edfi t\u1ea5t c\u1ea3 c\u00e1c nguy\u00ean t\u1eed trong m\u1ed9t h\u1ec7 th\u1ed1ng.</li> <li>Direct Coulomb Summation (DCS): Ti\u1ec1m n\u0103ng t\u1ea1i \u0111i\u1ec3m l\u01b0\u1edbi \\(j\\) l\u00e0 t\u1ed5ng c\u1ee7a (\u0111i\u1ec7n t\u00edch c\u1ee7a nguy\u00ean t\u1eed \\(i\\) / kho\u1ea3ng c\u00e1ch gi\u1eefa \\(i\\) v\u00e0 \\(j\\)).</li> <li>Th\u00e1ch th\u1ee9c t\u00ednh to\u00e1n: \u0110\u1ed9 ph\u1ee9c t\u1ea1p l\u00e0 \\(O(\\text{Nguy\u00ean t\u1eed} \\times \\text{\u0110i\u1ec3m l\u01b0\u1edbi})\\). Khi th\u1ec3 t\u00edch c\u1ee7a m\u1ed9t h\u1ec7 th\u1ed1ng t\u0103ng l\u00ean, s\u1ed1 l\u01b0\u1ee3ng ph\u00e9p t\u00ednh t\u0103ng theo c\u1ea5p s\u1ed1 nh\u00e2n, khi\u1ebfn n\u00f3 qu\u00e1 ch\u1eadm \u0111\u1ed1i v\u1edbi c\u00e1c h\u1ec7 th\u1ed1ng sinh h\u1ecdc l\u1edbn.</li> </ul>"},{"location":"cuda/pmpp/chapter-18/#vi-scatter-gather","title":"18.2 Scatter vs. Gather trong thi\u1ebft k\u1ebf Kernel","text":"<ul> <li>C\u00e1ch ti\u1ebfp c\u1eadn Scatter (Ph\u00e2n t\u00e1n): G\u00e1n m\u1ed9t lu\u1ed3ng cho m\u1ed7i nguy\u00ean t\u1eed. M\u1ed7i lu\u1ed3ng \"ph\u00e2n t\u00e1n\" \u0111\u00f3ng g\u00f3p \u0111i\u1ec7n t\u00edch c\u1ee7a n\u00f3 cho t\u1ea5t c\u1ea3 c\u00e1c \u0111i\u1ec3m l\u01b0\u1edbi.<ul> <li>V\u1ea5n \u0111\u1ec1: Nhi\u1ec1u lu\u1ed3ng c\u1ed1 g\u1eafng c\u1eadp nh\u1eadt c\u00f9ng m\u1ed9t \u0111i\u1ec3m l\u01b0\u1edbi c\u00f9ng l\u00fac, y\u00eau c\u1ea7u c\u00e1c Atomic Operations v\u1ed1n c\u1ef1c k\u1ef3 ch\u1eadm trong b\u1ed1i c\u1ea3nh n\u00e0y.</li> </ul> </li> <li>C\u00e1ch ti\u1ebfp c\u1eadn Gather (T\u1eadp h\u1ee3p): G\u00e1n m\u1ed9t lu\u1ed3ng cho m\u1ed7i \u0111i\u1ec3m l\u01b0\u1edbi. M\u1ed7i lu\u1ed3ng \"t\u1eadp h\u1ee3p\" \u0111\u00f3ng g\u00f3p t\u1eeb t\u1ea5t c\u1ea3 c\u00e1c nguy\u00ean t\u1eed.<ul> <li>L\u1ee3i \u00edch: Kh\u00f4ng c\u1ea7n c\u00e1c thao t\u00e1c atomic.</li> <li>T\u1ed1i \u01b0u h\u00f3a: V\u00ec t\u1ea5t c\u1ea3 c\u00e1c \u0111i\u1ec3m l\u01b0\u1edbi trong m\u1ed9t l\u00e1t c\u1eaft 2D chia s\u1ebb c\u00f9ng m\u1ed9t t\u1ecda \u0111\u1ed9 \\(Z\\), kho\u1ea3ng c\u00e1ch \\(Z\\) c\u1ee7a m\u1ed9t nguy\u00ean t\u1eed ch\u1ec9 c\u1ea7n \u0111\u01b0\u1ee3c t\u00ednh m\u1ed9t l\u1ea7n cho m\u1ed7i l\u00e1t c\u1eaft v\u00e0 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u1ea1i.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/chapter-18/#vi-coarsening","title":"18.3 Thread Coarsening (L\u00e0m th\u00f4 lu\u1ed3ng)","text":"<ul> <li>Quan s\u00e1t: T\u1ea5t c\u1ea3 c\u00e1c \u0111i\u1ec3m l\u01b0\u1edbi trong m\u1ed9t h\u00e0ng duy nh\u1ea5t chia s\u1ebb c\u00f9ng m\u1ed9t t\u1ecda \u0111\u1ed9 \\(Y\\).</li> <li>T\u1ed1i \u01b0u h\u00f3a: L\u00e0m th\u00f4 lu\u1ed3ng \u0111\u1ec3 m\u1ed9t lu\u1ed3ng t\u00ednh to\u00e1n b\u1ed1n \u0111i\u1ec3m l\u01b0\u1edbi li\u1ec1n k\u1ec1 trong m\u1ed9t h\u00e0ng.</li> <li>K\u1ebft qu\u1ea3: B\u1eb1ng c\u00e1ch t\u00ednh to\u00e1n c\u00e1c th\u00e0nh ph\u1ea7n \\(Y\\) v\u00e0 \\(Z\\) c\u1ee7a kho\u1ea3ng c\u00e1ch m\u1ed9t l\u1ea7n v\u00e0 s\u1eed d\u1ee5ng l\u1ea1i ch\u00fang cho b\u1ed1n \u0111i\u1ec3m, kernel gi\u1ea3m \u0111\u00e1ng k\u1ec3 s\u1ed1 l\u01b0\u1ee3ng truy c\u1eadp b\u1ed9 nh\u1edb constant v\u00e0 c\u00e1c ph\u00e9p to\u00e1n th\u1eeba.</li> </ul>"},{"location":"cuda/pmpp/chapter-18/#vi-coalescing","title":"18.4 Memory Coalescing (G\u1ed9p b\u1ed9 nh\u1edb)","text":"<ul> <li>V\u1ea5n \u0111\u1ec1: N\u1ebfu c\u00e1c lu\u1ed3ng \u0111\u00e3 \u0111\u01b0\u1ee3c l\u00e0m th\u00f4 ghi v\u00e0o b\u1ed1n \u0111i\u1ec3m c\u1ee7a ch\u00fang theo m\u1ed9t tr\u00ecnh t\u1ef1 \u0111\u01a1n gi\u1ea3n (\u0110i\u1ec3m 0, 1, 2, 3), c\u00e1c thao t\u00e1c ghi tr\u00ean warp s\u1ebd b\u1ecb \"strided\" (c\u00e1ch qu\u00e3ng) v\u00e0 kh\u00f4ng \u0111\u01b0\u1ee3c g\u1ed9p l\u1ea1i.</li> <li>Gi\u1ea3i ph\u00e1p: T\u1ed5 ch\u1ee9c l\u1ea1i vi\u1ec7c \u00e1nh x\u1ea1 lu\u1ed3ng sao cho c\u00e1c lu\u1ed3ng li\u1ec1n k\u1ec1 trong m\u1ed9t warp ghi v\u00e0o c\u00e1c v\u1ecb tr\u00ed b\u1ed9 nh\u1edb li\u1ec1n k\u1ec1.</li> <li>T\u00e1c \u0111\u1ed9ng: \u0110i\u1ec1u n\u00e0y \u0111\u1ea3m b\u1ea3o GPU c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng m\u1ed9t giao d\u1ecbch b\u1ed9 nh\u1edb duy nh\u1ea5t \u0111\u1ec3 ghi k\u1ebft qu\u1ea3 c\u1ee7a 32 lu\u1ed3ng, t\u1ed1i \u0111a h\u00f3a b\u0103ng th\u00f4ng ghi.</li> </ul>"},{"location":"cuda/pmpp/chapter-18/#vi-cutoff","title":"18.5 Cutoff Binning cho kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng k\u00edch th\u01b0\u1edbc d\u1eef li\u1ec7u","text":"<ul> <li>B\u1ee9c t\u01b0\u1eddng m\u1edf r\u1ed9ng: \u0110\u1ed1i v\u1edbi h\u00e0ng tri\u1ec7u nguy\u00ean t\u1eed, ngay c\u1ea3 m\u1ed9t kernel Gather \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ed1i \u01b0u h\u00f3a c\u0169ng qu\u00e1 ch\u1eadm v\u00ec n\u00f3 v\u1eabn ph\u1ea3i ki\u1ec3m tra m\u1ecdi nguy\u00ean t\u1eed cho m\u1ecdi \u0111i\u1ec3m l\u01b0\u1edbi.</li> <li>C\u01a1 s\u1edf khoa h\u1ecdc: \u1ea2nh h\u01b0\u1edfng c\u1ee7a m\u1ed9t nguy\u00ean t\u1eed gi\u1ea3m d\u1ea7n theo kho\u1ea3ng c\u00e1ch. \u0110\u00f3ng g\u00f3p t\u1eeb c\u00e1c nguy\u00ean t\u1eed \u1edf xa l\u00e0 kh\u00f4ng \u0111\u00e1ng k\u1ec3.</li> <li>Cutoff Summation (T\u1ed5ng c\u00f3 ng\u01b0\u1ee1ng): Ch\u1ec9 t\u00ednh to\u00e1n \u0111\u00f3ng g\u00f3p t\u1eeb c\u00e1c nguy\u00ean t\u1eed trong m\u1ed9t b\u00e1n k\u00ednh c\u1ed1 \u0111\u1ecbnh (v\u00ed d\u1ee5: 12 \u00c5ngstr\u00f6ms). \u0110i\u1ec1u n\u00e0y thay \u0111\u1ed5i \u0111\u1ed9 ph\u1ee9c t\u1ea1p t\u1eeb \\(O(N^2)\\) sang \\(O(N)\\).</li> <li>Spatial Binning (Ph\u00e2n th\u00f9ng kh\u00f4ng gian): \u0110\u1ec3 tr\u00e1nh vi\u1ec7c ph\u1ea3i ki\u1ec3m tra m\u1ecdi nguy\u00ean t\u1eed xem n\u00f3 c\u00f3 \"g\u1ea7n\" hay kh\u00f4ng, h\u1ec7 th\u1ed1ng chia kh\u00f4ng gian th\u00e0nh c\u00e1c Th\u00f9ng (Bins) (c\u00e1c h\u1ed9p h\u00ecnh l\u1eadp ph\u01b0\u01a1ng).</li> <li> <p>Thu\u1eadt to\u00e1n song song:</p> <ol> <li>S\u1eafp x\u1ebfp c\u00e1c nguy\u00ean t\u1eed v\u00e0o c\u00e1c th\u00f9ng.</li> <li>\u0110\u1ed1i v\u1edbi m\u1ed9t kh\u1ed1i c\u00e1c \u0111i\u1ec3m l\u01b0\u1edbi, x\u00e1c \u0111\u1ecbnh m\u1ed9t \"v\u00f9ng l\u00e2n c\u1eadn\" c\u1ee7a c\u00e1c th\u00f9ng.</li> <li>C\u00e1c lu\u1ed3ng ch\u1ec9 l\u1eb7p qua c\u00e1c nguy\u00ean t\u1eed c\u00f3 trong c\u00e1c th\u00f9ng l\u00e2n c\u1eadn c\u1ee5 th\u1ec3 \u0111\u00f3.</li> </ol> </li> <li> <p>X\u1eed l\u00fd tr\u00e0n: V\u00ec m\u1ed9t s\u1ed1 th\u00f9ng c\u00f3 th\u1ec3 c\u00f3 nhi\u1ec1u nguy\u00ean t\u1eed h\u01a1n nh\u1eefng th\u00f9ng kh\u00e1c, h\u1ec7 th\u1ed1ng s\u1eed d\u1ee5ng m\u1ed9t \"danh s\u00e1ch tr\u00e0n\" cho c\u00e1c khu v\u1ef1c d\u00e0y \u0111\u1eb7c \u0111\u1ec3 duy tr\u00ec kh\u1ed1i l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c \u0111\u1ec1u \u0111\u1eb7n cho GPU.</p> </li> </ul>"},{"location":"cuda/pmpp/chapter-18/#vi-summary","title":"18.6 T\u00f3m t\u1eaft","text":"<ul> <li>S\u1ef1 bi\u1ebfn \u0111\u1ed5i: Ch\u01b0\u01a1ng theo d\u00f5i h\u00e0nh tr\u00ecnh t\u1eeb m\u1ed9t kernel \"Scatter\" c\u01a1 b\u1ea3n sang m\u1ed9t kernel \"Gather\", sau \u0111\u00f3 th\u00eam \"Coarsening\" v\u00e0 \"Coalescing\".</li> <li>K\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng: Vi\u1ec7c tri\u1ec3n khai Cutoff Binning cho ph\u00e9p \u1ee9ng d\u1ee5ng x\u1eed l\u00fd c\u00e1c h\u1ec7 th\u1ed1ng ph\u00e2n t\u1eed kh\u1ed5ng l\u1ed3 m\u00e0 tr\u01b0\u1edbc \u0111\u00e2y kh\u00f4ng th\u1ec3 m\u00f4 ph\u1ecfng \u0111\u01b0\u1ee3c.</li> <li>B\u00e0i h\u1ecdc: Thay \u0111\u1ed5i thu\u1eadt to\u00e1n \u1edf c\u1ea5p \u0111\u1ed9 cao h\u01a1n (nh\u01b0 chuy\u1ec3n sang Bins v\u00e0 Cutoffs) th\u01b0\u1eddng mang l\u1ea1i hi\u1ec7u qu\u1ea3 t\u0103ng t\u1ed1c l\u1edbn h\u01a1n nhi\u1ec1u so v\u1edbi vi\u1ec7c \u0111i\u1ec1u ch\u1ec9nh m\u00e3 \u1edf c\u1ea5p \u0111\u1ed9 th\u1ea5p m\u1ed9t khi k\u00edch th\u01b0\u1edbc d\u1eef li\u1ec7u \u0111\u1ea1t \u0111\u1ebfn m\u1ed9t ng\u01b0\u1ee1ng nh\u1ea5t \u0111\u1ecbnh.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 18 d\u1ea1y b\u1ea1n c\u00e1ch qu\u1ea3n l\u00fd \u0110\u1ed9 ph\u1ee9c t\u1ea1p t\u00ednh to\u00e1n. N\u00f3 ch\u1ec9 ra r\u1eb1ng trong khi \u0111i\u1ec1u ch\u1ec9nh ph\u1ea7n c\u1ee9ng c\u1ea5p th\u1ea5p (coalescing/registers) l\u00e0 quan tr\u1ecdng, vi\u1ec7c m\u1edf r\u1ed9ng l\u00ean \"D\u1eef li\u1ec7u l\u1edbn\" \u0111\u00f2i h\u1ecfi c\u00e1c c\u1ea5u tr\u00fac d\u1eef li\u1ec7u th\u00f4ng minh nh\u01b0 Spatial Binning \u0111\u1ec3 tr\u00e1nh l\u00e0m nh\u1eefng c\u00f4ng vi\u1ec7c kh\u00f4ng c\u1ea7n thi\u1ebft.</p>"},{"location":"cuda/pmpp/chapter-19/","title":"Chapter 19: Programming Strategy and Goals","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter acts as a high-level recap of the book's philosophy. It moves away from specific code and focuses on the mental frameworks required to solve complex problems using massive parallelism.</p> <p>Ch\u01b0\u01a1ng n\u00e0y \u0111\u00f3ng vai tr\u00f2 l\u00e0 m\u1ed9t b\u1ea3n t\u00f3m t\u1eaft c\u1ea5p cao v\u1ec1 tri\u1ebft l\u00fd c\u1ee7a cu\u1ed1n s\u00e1ch. N\u00f3 kh\u00f4ng \u0111i s\u00e2u v\u00e0o m\u00e3 ngu\u1ed3n c\u1ee5 th\u1ec3 m\u00e0 t\u1eadp trung v\u00e0o c\u00e1c khung t\u01b0 duy c\u1ea7n thi\u1ebft \u0111\u1ec3 gi\u1ea3i quy\u1ebft c\u00e1c v\u1ea5n \u0111\u1ec1 ph\u1ee9c t\u1ea1p b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng t\u00ednh song song kh\u1ed5ng l\u1ed3.</p>"},{"location":"cuda/pmpp/chapter-19/#en-goals","title":"19.1 Goals of Parallel Computing","text":"<p>The authors identify three primary reasons to pursue parallel programming:</p> <ol> <li>Solve a problem in less time (Speed): Meeting strict real-time deadlines (e.g., finishing a financial risk analysis in 4 hours instead of 200).</li> <li>Solve bigger problems (Scale): Handling larger datasets (e.g., increasing the number of holdings in a portfolio) within the same time window.</li> <li>Achieve better solutions (Accuracy): Using more complex, accurate models that would be too slow on a serial processor.</li> </ol> <p>Amdahl's Law Revisited: Reminds the reader that even a 100x speedup of a major module only helps if the remaining sequential modules don't become the new bottleneck.</p>"},{"location":"cuda/pmpp/chapter-19/#en-selection","title":"19.2 Algorithm Selection","text":"<p>Choosing the right math is as important as writing the code.</p> <ul> <li>Trade-offs: Programmers must balance lower algorithmic complexity (work efficiency) with high degrees of parallel execution.</li> <li>Examples from the Book:<ul> <li>Scan (Ch 11): Kogge-Stone (more work but fewer steps) vs. Brent-Kung (less work but more steps).</li> <li>Sorting (Ch 13): Radix Sort (fast but limited to specific keys) vs. Merge Sort (general but higher complexity).</li> <li>Electrostatic Map (Ch 18): Direct Summation (\\(O(N^2)\\)) vs. Cutoff Binning (\\(O(N)\\)).</li> </ul> </li> <li>The Lesson: The \"best\" algorithm depends on the hardware's specific characteristics and the data size.</li> </ul>"},{"location":"cuda/pmpp/chapter-19/#en-decomposition","title":"19.3 Problem Decomposition","text":"<p>How you break a problem into sub-problems dictates your performance:</p> <ul> <li>Output-Centric (Gather): Threads are assigned to output elements. This is usually preferred for GPUs (as seen in MRI and Matrix Multiplication) because it avoids Atomic Operations.</li> <li>Input-Centric (Scatter): Threads are assigned to input elements. This is necessary for patterns like Histograms (Ch 9) where inputs are massive but output bins are few.</li> <li>Load Balance: Decompositions must ensure that work is distributed evenly to avoid idling SMs.</li> </ul>"},{"location":"cuda/pmpp/chapter-19/#en-thinking","title":"19.4 Computational Thinking","text":"<p>The authors define this as the art of formulating domain problems into computational steps. They categorize the approach to \"computation-hungry\" applications into three levels:</p> <ol> <li>The \"Good\" Approach: Accelerating legacy code using libraries (cuBLAS, cuFFT) or directives (OpenACC). High reward for low effort, but doesn't reach full potential.</li> <li>The \"Better\" Approach: Rewriting existing code for new architectures. Requires both domain knowledge and computer science skills.</li> <li>The \"Best\" Approach: A holistic attempt to rethink the numerical methods entirely (e.g., moving from Direct Summation to Cutoff Binning). This interdisciplinary approach leads to the biggest performance breakthroughs.</li> </ol>"},{"location":"cuda/pmpp/chapter-19/#en-summary","title":"19.5 Summary","text":"<ul> <li>High-performance programming is a thought process, not a \"black art.\"</li> <li>Successful programmers must understand Computer Architecture (memory/latency), Programming Interfaces (synchronization), and Domain Knowledge (the actual math of the problem).</li> </ul> <p>Key Takeaway: Chapter 19 teaches that the \"magic\" happens when you stop just \"porting\" code and start rethinking the problem to fit the throughput-oriented nature of the GPU. It emphasizes the \"best\" approach: challenging established numerical methods to unlock massive speedups.</p>"},{"location":"cuda/pmpp/chapter-19/#vi-goals","title":"19.1 M\u1ee5c ti\u00eau c\u1ee7a t\u00ednh to\u00e1n song song","text":"<p>C\u00e1c t\u00e1c gi\u1ea3 x\u00e1c \u0111\u1ecbnh ba l\u00fd do ch\u00ednh \u0111\u1ec3 theo \u0111u\u1ed5i l\u1eadp tr\u00ecnh song song:</p> <ol> <li>Gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 trong th\u1eddi gian ng\u1eafn h\u01a1n (T\u1ed1c \u0111\u1ed9): \u0110\u00e1p \u1ee9ng c\u00e1c th\u1eddi h\u1ea1n th\u1ef1c t\u1ebf nghi\u00eam ng\u1eb7t (v\u00ed d\u1ee5: ho\u00e0n th\u00e0nh ph\u00e2n t\u00edch r\u1ee7i ro t\u00e0i ch\u00ednh trong 4 gi\u1edd thay v\u00ec 200).</li> <li>Gi\u1ea3i quy\u1ebft c\u00e1c v\u1ea5n \u0111\u1ec1 l\u1edbn h\u01a1n (Quy m\u00f4): X\u1eed l\u00fd c\u00e1c t\u1eadp d\u1eef li\u1ec7u l\u1edbn h\u01a1n (v\u00ed d\u1ee5: t\u0103ng s\u1ed1 l\u01b0\u1ee3ng n\u1eafm gi\u1eef trong m\u1ed9t danh m\u1ee5c \u0111\u1ea7u t\u01b0) trong c\u00f9ng m\u1ed9t kho\u1ea3ng th\u1eddi gian.</li> <li>\u0110\u1ea1t \u0111\u01b0\u1ee3c c\u00e1c gi\u1ea3i ph\u00e1p t\u1ed1t h\u01a1n (\u0110\u1ed9 ch\u00ednh x\u00e1c): S\u1eed d\u1ee5ng c\u00e1c m\u00f4 h\u00ecnh ph\u1ee9c t\u1ea1p h\u01a1n, ch\u00ednh x\u00e1c h\u01a1n m\u00e0 n\u1ebfu ch\u1ea1y tr\u00ean b\u1ed9 x\u1eed l\u00fd tu\u1ea7n t\u1ef1 s\u1ebd qu\u00e1 ch\u1eadm.</li> </ol> <p>Xem l\u1ea1i \u0110\u1ecbnh lu\u1eadt Amdahl: Nh\u1eafc nh\u1edf ng\u01b0\u1eddi \u0111\u1ecdc r\u1eb1ng ngay c\u1ea3 khi t\u0103ng t\u1ed1c 100 l\u1ea7n cho m\u1ed9t m\u00f4-\u0111un ch\u00ednh c\u0169ng ch\u1ec9 c\u00f3 \u00edch n\u1ebfu c\u00e1c m\u00f4-\u0111un tu\u1ea7n t\u1ef1 c\u00f2n l\u1ea1i kh\u00f4ng tr\u1edf th\u00e0nh n\u00fat th\u1eaft c\u1ed5 chai m\u1edbi.</p>"},{"location":"cuda/pmpp/chapter-19/#vi-selection","title":"19.2 L\u1ef1a ch\u1ecdn thu\u1eadt to\u00e1n","text":"<p>L\u1ef1a ch\u1ecdn ph\u01b0\u01a1ng ph\u00e1p to\u00e1n h\u1ecdc \u0111\u00fang c\u0169ng quan tr\u1ecdng nh\u01b0 vi\u1ec7c vi\u1ebft m\u00e3.</p> <ul> <li>\u0110\u00e1nh \u0111\u1ed5i: L\u1eadp tr\u00ecnh vi\u00ean ph\u1ea3i c\u00e2n b\u1eb1ng gi\u1eefa \u0111\u1ed9 ph\u1ee9c t\u1ea1p thu\u1eadt to\u00e1n th\u1ea5p (hi\u1ec7u qu\u1ea3 c\u00f4ng vi\u1ec7c) v\u1edbi m\u1ee9c \u0111\u1ed9 th\u1ef1c thi song song cao.</li> <li>V\u00ed d\u1ee5 t\u1eeb cu\u1ed1n s\u00e1ch:<ul> <li>Scan (Ch\u01b0\u01a1ng 11): Kogge-Stone (nhi\u1ec1u vi\u1ec7c h\u01a1n nh\u01b0ng \u00edt b\u01b0\u1edbc h\u01a1n) so v\u1edbi Brent-Kung (\u00edt vi\u1ec7c h\u01a1n nh\u01b0ng nhi\u1ec1u b\u01b0\u1edbc h\u01a1n).</li> <li>S\u1eafp x\u1ebfp (Ch\u01b0\u01a1ng 13): Radix Sort (nhanh nh\u01b0ng gi\u1edbi h\u1ea1n \u1edf m\u1ed9t s\u1ed1 lo\u1ea1i kh\u00f3a c\u1ee5 th\u1ec3) so v\u1edbi Merge Sort (t\u1ed5ng qu\u00e1t nh\u01b0ng \u0111\u1ed9 ph\u1ee9c t\u1ea1p cao h\u01a1n).</li> <li>B\u1ea3n \u0111\u1ed3 t\u0129nh \u0111i\u1ec7n (Ch\u01b0\u01a1ng 18): Direct Summation (\\(O(N^2)\\)) so v\u1edbi Cutoff Binning (\\(O(N)\\)).</li> </ul> </li> <li>B\u00e0i h\u1ecdc: Thu\u1eadt to\u00e1n \"t\u1ed1t nh\u1ea5t\" ph\u1ee5 thu\u1ed9c v\u00e0o \u0111\u1eb7c \u0111i\u1ec3m c\u1ee5 th\u1ec3 c\u1ee7a ph\u1ea7n c\u1ee9ng v\u00e0 k\u00edch th\u01b0\u1edbc d\u1eef li\u1ec7u.</li> </ul>"},{"location":"cuda/pmpp/chapter-19/#vi-decomposition","title":"19.3 Ph\u00e2n r\u00e3 v\u1ea5n \u0111\u1ec1","text":"<p>C\u00e1ch b\u1ea1n chia nh\u1ecf m\u1ed9t v\u1ea5n \u0111\u1ec1 th\u00e0nh c\u00e1c v\u1ea5n \u0111\u1ec1 nh\u1ecf h\u01a1n s\u1ebd quy\u1ebft \u0111\u1ecbnh hi\u1ec7u su\u1ea5t c\u1ee7a b\u1ea1n:</p> <ul> <li>L\u1ea5y \u0111\u1ea7u ra l\u00e0m trung t\u00e2m (Gather): C\u00e1c lu\u1ed3ng \u0111\u01b0\u1ee3c g\u00e1n cho c\u00e1c ph\u1ea7n t\u1eed \u0111\u1ea7u ra. \u0110i\u1ec1u n\u00e0y th\u01b0\u1eddng \u0111\u01b0\u1ee3c \u01b0u ti\u00ean cho GPU (nh\u01b0 \u0111\u00e3 th\u1ea5y trong MRI v\u00e0 Nh\u00e2n ma tr\u1eadn) v\u00ec n\u00f3 tr\u00e1nh \u0111\u01b0\u1ee3c c\u00e1c Atomic Operations.</li> <li>L\u1ea5y \u0111\u1ea7u v\u00e0o l\u00e0m trung t\u00e2m (Scatter): C\u00e1c lu\u1ed3ng \u0111\u01b0\u1ee3c g\u00e1n cho c\u00e1c ph\u1ea7n t\u1eed \u0111\u1ea7u v\u00e0o. \u0110i\u1ec1u n\u00e0y c\u1ea7n thi\u1ebft cho c\u00e1c m\u1eabu nh\u01b0 Histogram (Ch\u01b0\u01a1ng 9) n\u01a1i \u0111\u1ea7u v\u00e0o kh\u1ed5ng l\u1ed3 nh\u01b0ng c\u00e1c th\u00f9ng (bins) \u0111\u1ea7u ra l\u1ea1i \u00edt.</li> <li>C\u00e2n b\u1eb1ng t\u1ea3i: Vi\u1ec7c ph\u00e2n r\u00e3 ph\u1ea3i \u0111\u1ea3m b\u1ea3o c\u00f4ng vi\u1ec7c \u0111\u01b0\u1ee3c ph\u00e2n ph\u1ed1i \u0111\u1ed3ng \u0111\u1ec1u \u0111\u1ec3 tr\u00e1nh c\u00e1c SM b\u1ecb nh\u00e0n r\u1ed7i.</li> </ul>"},{"location":"cuda/pmpp/chapter-19/#vi-thinking","title":"19.4 T\u01b0 duy t\u00ednh to\u00e1n (Computational Thinking)","text":"<p>C\u00e1c t\u00e1c gi\u1ea3 \u0111\u1ecbnh ngh\u0129a \u0111\u00e2y l\u00e0 ngh\u1ec7 thu\u1eadt x\u00e2y d\u1ef1ng c\u00e1c b\u00e0i to\u00e1n chuy\u00ean m\u00f4n th\u00e0nh c\u00e1c b\u01b0\u1edbc t\u00ednh to\u00e1n. H\u1ecd ph\u00e2n lo\u1ea1i c\u00e1ch ti\u1ebfp c\u1eadn c\u00e1c \u1ee9ng d\u1ee5ng \"\u0111\u00f3i t\u00ednh to\u00e1n\" th\u00e0nh ba c\u1ea5p \u0111\u1ed9:</p> <ol> <li>C\u00e1ch ti\u1ebfp c\u1eadn \"T\u1ed1t\": T\u0103ng t\u1ed1c m\u00e3 ngu\u1ed3n c\u0169 b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng c\u00e1c th\u01b0 vi\u1ec7n (cuBLAS, cuFFT) ho\u1eb7c c\u00e1c ch\u1ec9 th\u1ecb (OpenACC). Ph\u1ea7n th\u01b0\u1edfng cao cho n\u1ed7 l\u1ef1c th\u1ea5p, nh\u01b0ng kh\u00f4ng \u0111\u1ea1t \u0111\u01b0\u1ee3c h\u1ebft ti\u1ec1m n\u0103ng.</li> <li>C\u00e1ch ti\u1ebfp c\u1eadn \"T\u1ed1t h\u01a1n\": Vi\u1ebft l\u1ea1i m\u00e3 hi\u1ec7n c\u00f3 cho c\u00e1c ki\u1ebfn tr\u00fac m\u1edbi. \u0110\u00f2i h\u1ecfi c\u1ea3 ki\u1ebfn th\u1ee9c chuy\u00ean m\u00f4n v\u00e0 k\u1ef9 n\u0103ng khoa h\u1ecdc m\u00e1y t\u00ednh.</li> <li>C\u00e1ch ti\u1ebfp c\u1eadn \"T\u1ed1t nh\u1ea5t\": M\u1ed9t n\u1ed7 l\u1ef1c to\u00e0n di\u1ec7n \u0111\u1ec3 suy ngh\u0129 l\u1ea1i ho\u00e0n to\u00e0n v\u1ec1 c\u00e1c ph\u01b0\u01a1ng ph\u00e1p s\u1ed1 (v\u00ed d\u1ee5: chuy\u1ec3n t\u1eeb Direct Summation sang Cutoff Binning). C\u00e1ch ti\u1ebfp c\u1eadn li\u00ean ng\u00e0nh n\u00e0y mang l\u1ea1i nh\u1eefng \u0111\u1ed9t ph\u00e1 l\u1edbn nh\u1ea5t v\u1ec1 hi\u1ec7u su\u1ea5t.</li> </ol>"},{"location":"cuda/pmpp/chapter-19/#vi-summary","title":"19.5 T\u00f3m t\u1eaft","text":"<ul> <li>L\u1eadp tr\u00ecnh hi\u1ec7u su\u1ea5t cao l\u00e0 m\u1ed9t qu\u00e1 tr\u00ecnh t\u01b0 duy, kh\u00f4ng ph\u1ea3i l\u00e0 m\u1ed9t \"ma thu\u1eadt \u0111en\".</li> <li>L\u1eadp tr\u00ecnh vi\u00ean th\u00e0nh c\u00f4ng ph\u1ea3i hi\u1ec3u v\u1ec1 Ki\u1ebfn tr\u00fac m\u00e1y t\u00ednh (b\u1ed9 nh\u1edb/\u0111\u1ed9 tr\u1ec5), Giao di\u1ec7n l\u1eadp tr\u00ecnh (\u0111\u1ed3ng b\u1ed9 h\u00f3a) v\u00e0 Ki\u1ebfn th\u1ee9c chuy\u00ean m\u00f4n (to\u00e1n h\u1ecdc th\u1ef1c t\u1ebf c\u1ee7a v\u1ea5n \u0111\u1ec1).</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 19 d\u1ea1y r\u1eb1ng \"\u0111i\u1ec1u k\u1ef3 di\u1ec7u\" x\u1ea3y ra khi b\u1ea1n ng\u1eebng vi\u1ec7c ch\u1ec9 \"chuy\u1ec3n \u0111\u1ed5i\" m\u00e3 v\u00e0 b\u1eaft \u0111\u1ea7u suy ngh\u0129 l\u1ea1i v\u1ec1 v\u1ea5n \u0111\u1ec1 \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi b\u1ea3n ch\u1ea5t h\u01b0\u1edbng t\u1edbi th\u00f4ng l\u01b0\u1ee3ng c\u1ee7a GPU. N\u00f3 nh\u1ea5n m\u1ea1nh c\u00e1ch ti\u1ebfp c\u1eadn \"t\u1ed1t nh\u1ea5t\": th\u00e1ch th\u1ee9c c\u00e1c ph\u01b0\u01a1ng ph\u00e1p s\u1ed1 \u0111\u00e3 \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp \u0111\u1ec3 m\u1edf kh\u00f3a kh\u1ea3 n\u0103ng t\u0103ng t\u1ed1c kh\u1ed5ng l\u1ed3.</p>"},{"location":"cuda/pmpp/chapter-20/","title":"Chapter 20: Programming a Heterogeneous Cluster","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter marks the beginning of Part IV: Advanced Practices. It shifts from a single machine to High-Performance Computing (HPC) clusters, teaching how to combine CUDA with the Message Passing Interface (MPI) to scale applications across multiple nodes.</p> <p>Ch\u01b0\u01a1ng n\u00e0y \u0111\u00e1nh d\u1ea5u s\u1ef1 b\u1eaft \u0111\u1ea7u c\u1ee7a Ph\u1ea7n IV: Th\u1ef1c h\u00e0nh N\u00e2ng cao (Advanced Practices). N\u00f3 chuy\u1ec3n t\u1eeb m\u1ed9t m\u00e1y \u0111\u01a1n l\u1ebb sang c\u00e1c c\u1ee5m t\u00ednh to\u00e1n hi\u1ec7u n\u0103ng cao (HPC clusters), d\u1ea1y c\u00e1ch k\u1ebft h\u1ee3p CUDA v\u1edbi Giao di\u1ec7n Truy\u1ec1n Th\u00f4ng b\u00e1o (MPI) \u0111\u1ec3 m\u1edf r\u1ed9ng c\u00e1c \u1ee9ng d\u1ee5ng tr\u00ean nhi\u1ec1u n\u00fat (node).</p>"},{"location":"cuda/pmpp/chapter-20/#en-background","title":"20.1 Background","text":"<ul> <li>HPC Clusters: Modern supercomputers consist of thousands of \"nodes.\" Each node has its own CPUs (Host) and GPUs (Devices).</li> <li>The Challenge: Nodes do not share memory. To work together on a single problem, they must \"pass messages\" over a network.</li> <li>MPI: The industry standard for distributed memory programming.</li> </ul>"},{"location":"cuda/pmpp/chapter-20/#en-stencil","title":"20.2 A Running Example: 3D Stencil","text":"<ul> <li>Application: Modeling heat transfer in a 3D duct using a 25-point Jacobi iterative stencil.</li> <li>Domain Partitioning: The 3D grid is sliced along the \\(Z\\)-axis into several Domain Partitions (e.g., \\(D0, D1, D2, D3\\)). Each partition is assigned to a different MPI process (and therefore a different GPU).</li> <li>Dependency: Just like in Chapter 8, each slice needs data from its neighbors to calculate the next step. In a cluster, these neighbors live on different physical machines.</li> </ul>"},{"location":"cuda/pmpp/chapter-20/#en-mpi-basics","title":"20.3 Message Passing Interface (MPI) Basics","text":"<ul> <li>SPMD Model: Like CUDA, MPI uses a \"Single Program Multiple Data\" approach where every node runs the exact same code but acts differently based on its ID.</li> <li>MPI Rank: Each process is assigned a unique ID called a Rank (analogous to a <code>threadIdx</code> for a whole machine).</li> <li>Core Functions:<ul> <li><code>MPI_Init</code> / <code>MPI_Finalize</code>: Start and stop the MPI environment.</li> <li><code>MPI_Comm_rank</code>: Identify the current process Rank.</li> <li><code>MPI_Comm_size</code>: Find the total number of processes in the cluster.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/chapter-20/#en-communication","title":"20.4 Point-to-Point Communication","text":"<ul> <li>Send/Recv: Uses <code>MPI_Send</code> and <code>MPI_Recv</code> to move data between specific nodes.</li> <li>The Data Server: The authors illustrate a model where one process acts as a data server, distributing initial grid slices to \"Compute Nodes\" and gathering results at the end.</li> <li>Halo Exchange: The process of nodes trading their boundary slices so they have the \"ghost cells\" needed for the next stencil calculation.</li> </ul>"},{"location":"cuda/pmpp/chapter-20/#en-overlapping","title":"20.5 Overlapping Computation and Communication","text":"<ul> <li>The Latency Problem: Network communication is much slower than GPU math. If the GPU sits idle while the network moves data, performance is poor.</li> <li>CUDA Streams: A stream is a sequence of operations (kernels, memory copies) that execute in order. Different streams can execute simultaneously.</li> <li> <p>The Two-Stage Strategy:</p> <ol> <li>Stage 1 (Boundary): The GPU calculates only the edge slices of the grid and immediately starts a <code>cudaMemcpyAsync</code> to the host.</li> <li>Stage 2 (Internal): While the edges are being sent over the network, the GPU calculates the massive \"internal\" part of the grid in a separate stream.</li> </ol> </li> <li> <p>Pinned Memory (<code>cudaHostAlloc</code>): Necessary for \"Asynchronous\" transfers. It prevents the operating system from moving data in RAM, allowing the GPU to copy data to the host without stopping the CPU.</p> </li> </ul>"},{"location":"cuda/pmpp/chapter-20/#en-collective","title":"20.6 Collective Communication","text":"<ul> <li>Synchronization: Introduces <code>MPI_Barrier</code>, which forces every node in the cluster to wait until all have reached that point.</li> <li>Other Patterns: Mentions broadcast, reduce, and gather\u2014functions optimized by vendors to move data across all nodes efficiently.</li> </ul>"},{"location":"cuda/pmpp/chapter-20/#en-cuda-aware","title":"20.7 CUDA-Aware MPI","text":"<ul> <li>Modern Optimization: Explains that newer MPI libraries (like OpenMPI or MVAPICH2) can point directly to GPU memory addresses.</li> <li>Benefit: The programmer no longer has to manually copy data from GPU to CPU before sending it over the network. This simplifies the code and allows the hardware to optimize the transfer path.</li> </ul>"},{"location":"cuda/pmpp/chapter-20/#en-summary","title":"20.8 Summary","text":"<ul> <li>Scaling to a cluster requires a \"Symbiotic Relationship\" between MPI (inter-node) and CUDA (intra-node).</li> <li>The key to high performance in a cluster is using Streams and Asynchronous Transfers to hide the \"Network Wall\" behind the GPU's \"Compute Power.\"</li> </ul> <p>Key Takeaway: Chapter 20 teaches you how to break the \"single-node\" limit. The essential lesson is Communication-Hiding: using CUDA Streams to ensure the GPU is always doing internal math while the network is busy trading boundary data.</p>"},{"location":"cuda/pmpp/chapter-20/#vi-background","title":"20.1 B\u1ed1i c\u1ea3nh","text":"<ul> <li>C\u1ee5m HPC: C\u00e1c si\u00eau m\u00e1y t\u00ednh hi\u1ec7n \u0111\u1ea1i bao g\u1ed3m h\u00e0ng ngh\u00ecn \"n\u00fat\". M\u1ed7i n\u00fat c\u00f3 CPU (Host) v\u00e0 GPU (Device) ri\u00eang.</li> <li>Th\u00e1ch th\u1ee9c: C\u00e1c n\u00fat kh\u00f4ng chia s\u1ebb b\u1ed9 nh\u1edb. \u0110\u1ec3 l\u00e0m vi\u1ec7c c\u00f9ng nhau trong m\u1ed9t v\u1ea5n \u0111\u1ec1 duy nh\u1ea5t, ch\u00fang ph\u1ea3i \"truy\u1ec1n th\u00f4ng b\u00e1o\" qua m\u1ea1ng.</li> <li>MPI: Ti\u1ec3u chu\u1ea9n c\u00f4ng nghi\u1ec7p cho l\u1eadp tr\u00ecnh b\u1ed9 nh\u1edb ph\u00e2n t\u00e1n.</li> </ul>"},{"location":"cuda/pmpp/chapter-20/#vi-stencil","title":"20.2 V\u00ed d\u1ee5 th\u1ef1c t\u1ebf: 3D Stencil","text":"<ul> <li>\u1ee8ng d\u1ee5ng: M\u00f4 ph\u1ecfng s\u1ef1 truy\u1ec1n nhi\u1ec7t trong m\u1ed9t \u1ed1ng d\u1eabn 3D b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng stencil l\u1eb7p Jacobi 25 \u0111i\u1ec3m.</li> <li>Ph\u00e2n v\u00f9ng mi\u1ec1n (Domain Partitioning): L\u01b0\u1edbi 3D \u0111\u01b0\u1ee3c c\u1eaft d\u1ecdc theo tr\u1ee5c \\(Z\\) th\u00e0nh nhi\u1ec1u Ph\u00e2n v\u00f9ng mi\u1ec1n (v\u00ed d\u1ee5: \\(D0, D1, D2, D3\\)). M\u1ed7i ph\u00e2n v\u00f9ng \u0111\u01b0\u1ee3c g\u00e1n cho m\u1ed9t ti\u1ebfn tr\u00ecnh MPI kh\u00e1c nhau (v\u00e0 do \u0111\u00f3 l\u00e0 m\u1ed9t GPU kh\u00e1c nhau).</li> <li>S\u1ef1 ph\u1ee5 thu\u1ed9c: Gi\u1ed1ng nh\u01b0 trong Ch\u01b0\u01a1ng 8, m\u1ed7i l\u00e1t c\u1eaft c\u1ea7n d\u1eef li\u1ec7u t\u1eeb c\u00e1c n\u00fat l\u00e2n c\u1eadn \u0111\u1ec3 t\u00ednh to\u00e1n b\u01b0\u1edbc ti\u1ebfp theo. Trong m\u1ed9t c\u1ee5m m\u00e1y t\u00ednh, nh\u1eefng n\u00fat l\u00e2n c\u1eadn n\u00e0y n\u1eb1m tr\u00ean c\u00e1c m\u00e1y v\u1eadt l\u00fd kh\u00e1c nhau.</li> </ul>"},{"location":"cuda/pmpp/chapter-20/#vi-mpi-basics","title":"20.3 C\u01a1 b\u1ea3n v\u1ec1 Giao di\u1ec7n Truy\u1ec1n Th\u00f4ng b\u00e1o (MPI)","text":"<ul> <li>M\u00f4 h\u00ecnh SPMD: Gi\u1ed1ng nh\u01b0 CUDA, MPI s\u1eed d\u1ee5ng c\u00e1ch ti\u1ebfp c\u1eadn \"Single Program Multiple Data\" trong \u0111\u00f3 m\u1ecdi n\u00fat ch\u1ea1y c\u00f9ng m\u1ed9t m\u00e3 nh\u01b0ng ho\u1ea1t \u0111\u1ed9ng kh\u00e1c nhau d\u1ef1a tr\u00ean ID c\u1ee7a n\u00f3.</li> <li>Rank MPI: M\u1ed7i ti\u1ebfn tr\u00ecnh \u0111\u01b0\u1ee3c g\u00e1n m\u1ed9t ID duy nh\u1ea5t g\u1ecdi l\u00e0 Rank (t\u01b0\u01a1ng t\u1ef1 nh\u01b0 <code>threadIdx</code> nh\u01b0ng cho c\u1ea3 m\u1ed9t m\u00e1y).</li> <li>C\u00e1c h\u00e0m c\u1ed1t l\u00f5i:<ul> <li><code>MPI_Init</code> / <code>MPI_Finalize</code>: B\u1eaft \u0111\u1ea7u v\u00e0 k\u1ebft th\u00fac m\u00f4i tr\u01b0\u1eddng MPI.</li> <li><code>MPI_Comm_rank</code>: X\u00e1c \u0111\u1ecbnh Rank c\u1ee7a ti\u1ebfn tr\u00ecnh hi\u1ec7n t\u1ea1i.</li> <li><code>MPI_Comm_size</code>: T\u00ecm t\u1ed5ng s\u1ed1 ti\u1ebfn tr\u00ecnh trong c\u1ee5m.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/chapter-20/#vi-communication","title":"20.4 Truy\u1ec1n th\u00f4ng \u0110i\u1ec3m-\u0111\u1ebfn-\u0110i\u1ec3m (Point-to-Point)","text":"<ul> <li>Send/Recv: S\u1eed d\u1ee5ng <code>MPI_Send</code> v\u00e0 <code>MPI_Recv</code> \u0111\u1ec3 di chuy\u1ec3n d\u1eef li\u1ec7u gi\u1eefa c\u00e1c n\u00fat c\u1ee5 th\u1ec3.</li> <li>M\u00e1y ch\u1ee7 d\u1eef li\u1ec7u: C\u00e1c t\u00e1c gi\u1ea3 minh h\u1ecda m\u1ed9t m\u00f4 h\u00ecnh trong \u0111\u00f3 m\u1ed9t ti\u1ebfn tr\u00ecnh ho\u1ea1t \u0111\u1ed9ng nh\u01b0 m\u00e1y ch\u1ee7 d\u1eef li\u1ec7u, ph\u00e2n ph\u1ed1i c\u00e1c l\u00e1t l\u01b0\u1edbi ban \u0111\u1ea7u cho c\u00e1c \"N\u00fat t\u00ednh to\u00e1n (Compute Nodes)\" v\u00e0 thu th\u1eadp k\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng.</li> <li>Trao \u0111\u1ed5i Halo: Qu\u00e1 tr\u00ecnh c\u00e1c n\u00fat trao \u0111\u1ed5i c\u00e1c l\u00e1t ranh gi\u1edbi c\u1ee7a ch\u00fang \u0111\u1ec3 ch\u00fang c\u00f3 c\u00e1c \"\u00f4 ma (ghost cells)\" c\u1ea7n thi\u1ebft cho ph\u00e9p t\u00ednh stencil ti\u1ebfp theo.</li> </ul>"},{"location":"cuda/pmpp/chapter-20/#vi-overlapping","title":"20.5 Ch\u1ed3ng l\u1ea5p T\u00ednh to\u00e1n v\u00e0 Truy\u1ec1n th\u00f4ng","text":"<ul> <li>V\u1ea5n \u0111\u1ec1 \u0111\u1ed9 tr\u1ec5: Truy\u1ec1n th\u00f4ng qua m\u1ea1ng ch\u1eadm h\u01a1n nhi\u1ec1u so v\u1edbi t\u00ednh to\u00e1n tr\u00ean GPU. N\u1ebfu GPU nh\u00e0n r\u1ed7i trong khi m\u1ea1ng di chuy\u1ec3n d\u1eef li\u1ec7u, hi\u1ec7u su\u1ea5t s\u1ebd r\u1ea5t k\u00e9m.</li> <li>CUDA Streams: M\u1ed9t stream l\u00e0 m\u1ed9t chu\u1ed7i c\u00e1c thao t\u00e1c (kernel, sao ch\u00e9p b\u1ed9 nh\u1edb) th\u1ef1c thi theo th\u1ee9 t\u1ef1. C\u00e1c stream kh\u00e1c nhau c\u00f3 th\u1ec3 th\u1ef1c thi \u0111\u1ed3ng th\u1eddi.</li> <li> <p>Chi\u1ebfn l\u01b0\u1ee3c hai giai \u0111o\u1ea1n:</p> <ol> <li>Giai \u0111o\u1ea1n 1 (Ranh gi\u1edbi): GPU ch\u1ec9 t\u00ednh to\u00e1n c\u00e1c l\u00e1t c\u1ea1nh c\u1ee7a l\u01b0\u1edbi v\u00e0 b\u1eaft \u0111\u1ea7u ngay l\u1eadp t\u1ee9c m\u1ed9t l\u1ec7nh <code>cudaMemcpyAsync</code> sang host.</li> <li>Giai \u0111o\u1ea1n 2 (B\u00ean trong): Trong khi c\u00e1c c\u1ea1nh \u0111ang \u0111\u01b0\u1ee3c g\u1eedi qua m\u1ea1ng, GPU t\u00ednh to\u00e1n ph\u1ea7n l\u1edbn \"b\u00ean trong\" c\u1ee7a l\u01b0\u1edbi trong m\u1ed9t stream ri\u00eang bi\u1ec7t.</li> </ol> </li> <li> <p>Pinned Memory (<code>cudaHostAlloc</code>): C\u1ea7n thi\u1ebft cho c\u00e1c l\u1ea7n truy\u1ec1n \"B\u1ea5t \u0111\u1ed3ng b\u1ed9\". N\u00f3 ng\u0103n h\u1ec7 \u0111i\u1ec1u h\u00e0nh di chuy\u1ec3n d\u1eef li\u1ec7u trong RAM, cho ph\u00e9p GPU sao ch\u00e9p d\u1eef li\u1ec7u sang host m\u00e0 kh\u00f4ng l\u00e0m d\u1eebng CPU.</p> </li> </ul>"},{"location":"cuda/pmpp/chapter-20/#vi-collective","title":"20.6 Truy\u1ec1n th\u00f4ng t\u1eadp th\u1ec3 (Collective Communication)","text":"<ul> <li>\u0110\u1ed3ng b\u1ed9 h\u00f3a: Gi\u1edbi thi\u1ec7u <code>MPI_Barrier</code>, bu\u1ed9c m\u1ecdi n\u00fat trong c\u1ee5m ph\u1ea3i \u0111\u1ee3i cho \u0111\u1ebfn khi t\u1ea5t c\u1ea3 \u0111\u1ec1u \u0111\u1ea1t \u0111\u1ebfn \u0111i\u1ec3m \u0111\u00f3.</li> <li>C\u00e1c m\u1eabu kh\u00e1c: \u0110\u1ec1 c\u1eadp \u0111\u1ebfn broadcast, reduce v\u00e0 gather\u2014c\u00e1c h\u00e0m \u0111\u01b0\u1ee3c c\u00e1c nh\u00e0 cung c\u1ea5p t\u1ed1i \u01b0u h\u00f3a \u0111\u1ec3 di chuy\u1ec3n d\u1eef li\u1ec7u qua t\u1ea5t c\u1ea3 c\u00e1c n\u00fat m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3.</li> </ul>"},{"location":"cuda/pmpp/chapter-20/#vi-cuda-aware","title":"20.7 CUDA-Aware MPI","text":"<ul> <li>T\u1ed1i \u01b0u h\u00f3a hi\u1ec7n \u0111\u1ea1i: Gi\u1ea3i th\u00edch r\u1eb1ng c\u00e1c th\u01b0 vi\u1ec7n MPI m\u1edbi h\u01a1n (nh\u01b0 OpenMPI ho\u1eb7c MVAPICH2) c\u00f3 th\u1ec3 tr\u1ecf tr\u1ef1c ti\u1ebfp \u0111\u1ebfn \u0111\u1ecba ch\u1ec9 b\u1ed9 nh\u1edb GPU.</li> <li>L\u1ee3i \u00edch: L\u1eadp tr\u00ecnh vi\u00ean kh\u00f4ng c\u00f2n ph\u1ea3i sao ch\u00e9p d\u1eef li\u1ec7u t\u1eeb GPU sang CPU m\u1ed9t c\u00e1ch th\u1ee7 c\u00f4ng tr\u01b0\u1edbc khi g\u1eedi qua m\u1ea1ng. \u0110i\u1ec1u n\u00e0y \u0111\u01a1n gi\u1ea3n h\u00f3a m\u00e3 ngu\u1ed3n v\u00e0 cho ph\u00e9p ph\u1ea7n c\u1ee9ng t\u1ed1i \u01b0u h\u00f3a \u0111\u01b0\u1eddng truy\u1ec1n.</li> </ul>"},{"location":"cuda/pmpp/chapter-20/#vi-summary","title":"20.8 T\u00f3m t\u1eaft","text":"<ul> <li>M\u1edf r\u1ed9ng l\u00ean m\u1ed9t c\u1ee5m m\u00e1y t\u00ednh \u0111\u00f2i h\u1ecfi m\u1ed9t \"M\u1ed1i quan h\u1ec7 c\u1ed9ng sinh\" gi\u1eefa MPI (gi\u1eefa c\u00e1c n\u00fat) v\u00e0 CUDA (trong m\u1ed9t n\u00fat).</li> <li>Ch\u00eca kh\u00f3a \u0111\u1ec3 \u0111\u1ea1t hi\u1ec7u n\u0103ng cao trong m\u1ed9t c\u1ee5m l\u00e0 s\u1eed d\u1ee5ng Streams v\u00e0 Truy\u1ec1n b\u1ea5t \u0111\u1ed3ng b\u1ed9 \u0111\u1ec3 che gi\u1ea5u \"B\u1ee9c t\u01b0\u1eddng M\u1ea1ng\" \u0111\u1eb1ng sau \"S\u1ee9c m\u1ea1nh t\u00ednh to\u00e1n\" c\u1ee7a GPU.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 20 d\u1ea1y b\u1ea1n c\u00e1ch ph\u00e1 v\u1ee1 gi\u1edbi h\u1ea1n \"n\u00fat \u0111\u01a1n\". B\u00e0i h\u1ecdc thi\u1ebft y\u1ebfu l\u00e0 Che gi\u1ea5u truy\u1ec1n th\u00f4ng (Communication-Hiding): s\u1eed d\u1ee5ng CUDA Streams \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o GPU lu\u00f4n th\u1ef1c hi\u1ec7n t\u00ednh to\u00e1n b\u00ean trong trong khi m\u1ea1ng \u0111ang b\u1eadn r\u1ed9n trao \u0111\u1ed5i d\u1eef li\u1ec7u ranh gi\u1edbi.</p>"},{"location":"cuda/pmpp/chapter-21/","title":"Chapter 21: CUDA Dynamic Parallelism","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter introduces one of the most significant changes to the CUDA programming model since its inception: the ability for a GPU to launch its own kernels.</p> <p>Ch\u01b0\u01a1ng n\u00e0y gi\u1edbi thi\u1ec7u m\u1ed9t trong nh\u1eefng thay \u0111\u1ed5i quan tr\u1ecdng nh\u1ea5t \u0111\u1ed1i v\u1edbi m\u00f4 h\u00ecnh l\u1eadp tr\u00ecnh CUDA k\u1ec3 t\u1eeb khi ra \u0111\u1eddi: kh\u1ea3 n\u0103ng GPU t\u1ef1 kh\u1edfi ch\u1ea1y c\u00e1c kernel c\u1ee7a ch\u00ednh n\u00f3.</p>"},{"location":"cuda/pmpp/chapter-21/#en-background","title":"21.1 Background","text":"<ul> <li>The Traditional Limit: In early CUDA versions, only the Host (CPU) could launch kernels. If a kernel discovered it needed more detail, it had to exit, report back to the CPU, and wait for the CPU to launch a new \"refining\" kernel. This caused high overhead and latency.</li> <li>The Solution: Dynamic Parallelism allows the GPU to discover new work and launch \"child\" kernels to handle it without ever involving the CPU.</li> </ul>"},{"location":"cuda/pmpp/chapter-21/#en-overview","title":"21.2 Dynamic Parallelism Overview","text":"<ul> <li>Syntax: Launching a kernel from inside another kernel uses the same <code>&lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt;</code> syntax as a host launch.</li> <li>Hierarchy:<ul> <li>Parent Grid: The grid launched from the host.</li> <li>Child Grid: The grid launched from a thread inside the parent grid.</li> </ul> </li> <li>Asynchronous Nature: Child grids are asynchronous. A parent thread continues executing after a launch unless it explicitly calls <code>cudaDeviceSynchronize()</code>. However, a parent block is not considered finished until all its child grids have completed.</li> </ul>"},{"location":"cuda/pmpp/chapter-21/#en-bezier","title":"21.3 Example: Bezier Curves","text":"<ul> <li>Context: Used in computer graphics to draw smooth curves.</li> <li>Variable Workload: The \"curvature\" of a line determines how many points are needed to make it look smooth.</li> <li>The Optimization:<ul> <li>Without Dynamic Parallelism: One thread block handles one curve. If one curve is sharp and another is flat, threads in the same warp have different amounts of work, leading to Control Divergence.</li> <li>With Dynamic Parallelism: A \"parent\" thread analyzes the curve. If it's complex, it launches a \"child\" grid specifically sized for that curvature. This ensures every thread in the child grid has exactly one unit of work, eliminating divergence.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/chapter-21/#en-quadtree","title":"21.4 A Recursive Example: Quadtrees","text":"<ul> <li>Context: Spatial partitioning where a 2D space is subdivided into four quadrants.</li> <li> <p>Algorithm:</p> <ol> <li>A block is assigned a quadrant.</li> <li>It counts how many points are in that quadrant.</li> <li>If the number exceeds a threshold, the block launches four child blocks to subdivide further.</li> </ol> </li> <li> <p>Recursion: This process repeats until the quadrants are small enough or the maximum depth is reached. This demonstrates the GPU's ability to handle recursive tree structures that were previously very difficult to program.</p> </li> </ul>"},{"location":"cuda/pmpp/chapter-21/#en-considerations","title":"21.5 Important Considerations","text":"<ul> <li>Memory Visibility: Parent threads and child grids only share Global and Constant memory. A parent thread cannot pass a pointer to its Shared or Local memory to a child grid.</li> <li>Pending Launch Pool: There is a hardware limit on how many kernels can be \"waiting\" to execute (default is 2048). If exceeded, performance drops significantly. This can be increased using <code>cudaDeviceSetLimit()</code>.</li> <li>Streams: By default, child grids launched from the same block are serialized. To run child kernels in parallel, the programmer must use named streams within the device code.</li> <li>Nesting Depth: Current hardware supports a maximum of 24 levels of nested kernel launches.</li> </ul>"},{"location":"cuda/pmpp/chapter-21/#en-summary","title":"21.6 Summary","text":"<ul> <li>Dynamic parallelism removes the CPU-GPU communication bottleneck for irregular data.</li> <li>It supports Device-side <code>cudaMalloc</code>, allowing threads to allocate memory for their children.</li> <li>It simplifies the implementation of complex algorithms like adaptive mesh refinement, graph search, and recursive trees.</li> </ul> <p>Key Takeaway: Chapter 21 teaches you how to make the GPU self-scheduling. By allowing threads to launch kernels, you move from \"static\" parallelism (fixed data sizes) to \"dynamic\" parallelism, which is necessary for complex, real-world simulations where work is discovered on the fly.</p>"},{"location":"cuda/pmpp/chapter-21/#vi-background","title":"21.1 B\u1ed1i c\u1ea3nh","text":"<ul> <li>Gi\u1edbi h\u1ea1n truy\u1ec1n th\u1ed1ng: Trong c\u00e1c phi\u00ean b\u1ea3n CUDA \u0111\u1ea7u ti\u00ean, ch\u1ec9 c\u00f3 Host (CPU) m\u1edbi c\u00f3 th\u1ec3 kh\u1edfi ch\u1ea1y kernel. N\u1ebfu m\u1ed9t kernel ph\u00e1t hi\u1ec7n ra n\u00f3 c\u1ea7n x\u1eed l\u00fd chi ti\u1ebft h\u01a1n, n\u00f3 ph\u1ea3i tho\u00e1t ra, b\u00e1o c\u00e1o l\u1ea1i cho CPU v\u00e0 ch\u1edd CPU kh\u1edfi ch\u1ea1y m\u1ed9t kernel \"tinh ch\u1ec9nh\" m\u1edbi. \u0110i\u1ec1u n\u00e0y g\u00e2y ra chi ph\u00ed qu\u1ea3n l\u00fd (overhead) v\u00e0 \u0111\u1ed9 tr\u1ec5 cao.</li> <li>Gi\u1ea3i ph\u00e1p: Dynamic Parallelism cho ph\u00e9p GPU t\u1ef1 kh\u00e1m ph\u00e1 kh\u1ed1i l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c m\u1edbi v\u00e0 kh\u1edfi ch\u1ea1y c\u00e1c kernel \"con (child)\" \u0111\u1ec3 x\u1eed l\u00fd c\u00f4ng vi\u1ec7c \u0111\u00f3 m\u00e0 kh\u00f4ng c\u1ea7n s\u1ef1 tham gia c\u1ee7a CPU.</li> </ul>"},{"location":"cuda/pmpp/chapter-21/#vi-overview","title":"21.2 T\u1ed5ng quan v\u1ec1 Dynamic Parallelism","text":"<ul> <li>C\u00fa ph\u00e1p: Kh\u1edfi ch\u1ea1y m\u1ed9t kernel t\u1eeb b\u00ean trong m\u1ed9t kernel kh\u00e1c s\u1eed d\u1ee5ng c\u00f9ng c\u00fa ph\u00e1p <code>&lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt;</code> nh\u01b0 khi kh\u1edfi ch\u1ea1y t\u1eeb host.</li> <li>Ph\u00e2n c\u1ea5p:<ul> <li>Parent Grid: L\u01b0\u1edbi \u0111\u01b0\u1ee3c kh\u1edfi ch\u1ea1y t\u1eeb host.</li> <li>Child Grid: L\u01b0\u1edbi \u0111\u01b0\u1ee3c kh\u1edfi ch\u1ea1y t\u1eeb m\u1ed9t lu\u1ed3ng b\u00ean trong parent grid.</li> </ul> </li> <li>B\u1ea3n ch\u1ea5t b\u1ea5t \u0111\u1ed3ng b\u1ed9: C\u00e1c l\u01b0\u1edbi con (child grids) l\u00e0 b\u1ea5t \u0111\u1ed3ng b\u1ed9. M\u1ed9t lu\u1ed3ng cha ti\u1ebfp t\u1ee5c th\u1ef1c thi sau khi kh\u1edfi ch\u1ea1y tr\u1eeb khi n\u00f3 g\u1ecdi <code>cudaDeviceSynchronize()</code> m\u1ed9t c\u00e1ch r\u00f5 r\u00e0ng. Tuy nhi\u00ean, m\u1ed9t block cha kh\u00f4ng \u0111\u01b0\u1ee3c coi l\u00e0 k\u1ebft th\u00fac cho \u0111\u1ebfn khi t\u1ea5t c\u1ea3 c\u00e1c l\u01b0\u1edbi con c\u1ee7a n\u00f3 ho\u00e0n th\u00e0nh.</li> </ul>"},{"location":"cuda/pmpp/chapter-21/#vi-bezier","title":"21.3 V\u00ed d\u1ee5: \u0110\u01b0\u1eddng cong Bezier","text":"<ul> <li>Ng\u1eef c\u1ea3nh: \u0110\u01b0\u1ee3c s\u1eed d\u1ee5ng trong \u0111\u1ed3 h\u1ecda m\u00e1y t\u00ednh \u0111\u1ec3 v\u1ebd c\u00e1c \u0111\u01b0\u1eddng cong m\u01b0\u1ee3t m\u00e0.</li> <li>Kh\u1ed1i l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c thay \u0111\u1ed5i: \"\u0110\u1ed9 cong\" c\u1ee7a m\u1ed9t \u0111\u01b0\u1eddng x\u00e1c \u0111\u1ecbnh c\u1ea7n bao nhi\u00eau \u0111i\u1ec3m \u0111\u1ec3 l\u00e0m cho n\u00f3 tr\u00f4ng m\u01b0\u1ee3t m\u00e0.</li> <li>T\u1ed1i \u01b0u h\u00f3a:<ul> <li>Kh\u00f4ng c\u00f3 Dynamic Parallelism: M\u1ed9t kh\u1ed1i lu\u1ed3ng x\u1eed l\u00fd m\u1ed9t \u0111\u01b0\u1eddng cong. N\u1ebfu m\u1ed9t \u0111\u01b0\u1eddng cong s\u1eafc n\u00e9t v\u00e0 m\u1ed9t \u0111\u01b0\u1eddng kh\u00e1c ph\u1eb3ng, c\u00e1c lu\u1ed3ng trong c\u00f9ng m\u1ed9t warp c\u00f3 kh\u1ed1i l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c kh\u00e1c nhau, d\u1eabn \u0111\u1ebfn Ph\u00e2n k\u1ef3 \u0111i\u1ec1u khi\u1ec3n (Control Divergence).</li> <li>C\u00f3 Dynamic Parallelism: M\u1ed9t lu\u1ed3ng \"cha\" ph\u00e2n t\u00edch \u0111\u01b0\u1eddng cong. N\u1ebfu n\u00f3 ph\u1ee9c t\u1ea1p, n\u00f3 s\u1ebd kh\u1edfi ch\u1ea1y m\u1ed9t l\u01b0\u1edbi \"con\" c\u00f3 k\u00edch th\u01b0\u1edbc c\u1ee5 th\u1ec3 cho \u0111\u1ed9 cong \u0111\u00f3. \u0110i\u1ec1u n\u00e0y \u0111\u1ea3m b\u1ea3o m\u1ecdi lu\u1ed3ng trong l\u01b0\u1edbi con \u0111\u1ec1u c\u00f3 \u0111\u00fang m\u1ed9t \u0111\u01a1n v\u1ecb c\u00f4ng vi\u1ec7c, lo\u1ea1i b\u1ecf ph\u00e2n k\u1ef3.</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/chapter-21/#vi-quadtree","title":"21.4 V\u00ed d\u1ee5 \u0111\u1ec7 quy: Quadtrees","text":"<ul> <li>Ng\u1eef c\u1ea3nh: Ph\u00e2n v\u00f9ng kh\u00f4ng gian n\u01a1i m\u1ed9t kh\u00f4ng gian 2D \u0111\u01b0\u1ee3c chia nh\u1ecf th\u00e0nh b\u1ed1n g\u00f3c ph\u1ea7n t\u01b0.</li> <li> <p>Thu\u1eadt to\u00e1n:</p> <ol> <li>M\u1ed9t block \u0111\u01b0\u1ee3c g\u00e1n cho m\u1ed9t g\u00f3c ph\u1ea7n t\u01b0.</li> <li>N\u00f3 \u0111\u1ebfm xem c\u00f3 bao nhi\u00eau \u0111i\u1ec3m trong g\u00f3c ph\u1ea7n t\u01b0 \u0111\u00f3.</li> <li>N\u1ebfu s\u1ed1 l\u01b0\u1ee3ng v\u01b0\u1ee3t qu\u00e1 m\u1ed9t ng\u01b0\u1ee1ng, block s\u1ebd kh\u1edfi ch\u1ea1y b\u1ed1n block con \u0111\u1ec3 ph\u00e2n chia th\u00eam.</li> </ol> </li> <li> <p>\u0110\u1ec7 quy: Qu\u00e1 tr\u00ecnh n\u00e0y l\u1eb7p l\u1ea1i cho \u0111\u1ebfn khi c\u00e1c g\u00f3c ph\u1ea7n t\u01b0 \u0111\u1ee7 nh\u1ecf ho\u1eb7c \u0111\u1ea1t \u0111\u1ebfn \u0111\u1ed9 s\u00e2u t\u1ed1i \u0111a. \u0110i\u1ec1u n\u00e0y minh ch\u1ee9ng cho kh\u1ea3 n\u0103ng c\u1ee7a GPU trong vi\u1ec7c x\u1eed l\u00fd c\u00e1c c\u1ea5u tr\u00fac c\u00e2y \u0111\u1ec7 quy m\u00e0 tr\u01b0\u1edbc \u0111\u00e2y r\u1ea5t kh\u00f3 l\u1eadp tr\u00ecnh.</p> </li> </ul>"},{"location":"cuda/pmpp/chapter-21/#vi-considerations","title":"21.5 C\u00e1c l\u01b0u \u00fd quan tr\u1ecdng","text":"<ul> <li>Kh\u1ea3 n\u0103ng hi\u1ec3n th\u1ecb b\u1ed9 nh\u1edb: C\u00e1c lu\u1ed3ng cha v\u00e0 l\u01b0\u1edbi con ch\u1ec9 chia s\u1ebb b\u1ed9 nh\u1edb Global v\u00e0 Constant. M\u1ed9t lu\u1ed3ng cha kh\u00f4ng th\u1ec3 truy\u1ec1n m\u1ed9t con tr\u1ecf t\u1edbi b\u1ed9 nh\u1edb Shared ho\u1eb7c Local c\u1ee7a n\u00f3 cho m\u1ed9t l\u01b0\u1edbi con.</li> <li>B\u1ec3 ch\u1ee9a l\u1ec7nh kh\u1edfi ch\u1ea1y \u0111ang ch\u1edd (Pending Launch Pool): C\u00f3 m\u1ed9t gi\u1edbi h\u1ea1n ph\u1ea7n c\u1ee9ng v\u1ec1 s\u1ed1 l\u01b0\u1ee3ng kernel c\u00f3 th\u1ec3 \"\u0111ang ch\u1edd\" th\u1ef1c thi (m\u1eb7c \u0111\u1ecbnh l\u00e0 2048). N\u1ebfu v\u01b0\u1ee3t qu\u00e1, hi\u1ec7u su\u1ea5t s\u1ebd gi\u1ea3m \u0111\u00e1ng k\u1ec3. \u0110i\u1ec1u n\u00e0y c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c t\u0103ng l\u00ean b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng <code>cudaDeviceSetLimit()</code>.</li> <li>Streams: Theo m\u1eb7c \u0111\u1ecbnh, c\u00e1c l\u01b0\u1edbi con \u0111\u01b0\u1ee3c kh\u1edfi ch\u1ea1y t\u1eeb c\u00f9ng m\u1ed9t block s\u1ebd \u0111\u01b0\u1ee3c tu\u1ea7n t\u1ef1 h\u00f3a. \u0110\u1ec3 ch\u1ea1y c\u00e1c kernel con song song, l\u1eadp tr\u00ecnh vi\u00ean ph\u1ea3i s\u1eed d\u1ee5ng named streams b\u00ean trong m\u00e3 thi\u1ebft b\u1ecb.</li> <li>\u0110\u1ed9 s\u00e2u l\u1ed3ng nhau: Ph\u1ea7n c\u1ee9ng hi\u1ec7n t\u1ea1i h\u1ed7 tr\u1ee3 t\u1ed1i \u0111a 24 c\u1ea5p \u0111\u1ed9 kh\u1edfi ch\u1ea1y kernel l\u1ed3ng nhau.</li> </ul>"},{"location":"cuda/pmpp/chapter-21/#vi-summary","title":"21.6 T\u00f3m t\u1eaft","text":"<ul> <li>Dynamic parallelism lo\u1ea1i b\u1ecf n\u00fat th\u1eaft c\u1ed5 chai truy\u1ec1n th\u00f4ng CPU-GPU \u0111\u1ed1i v\u1edbi d\u1eef li\u1ec7u kh\u00f4ng \u0111\u1ec1u.</li> <li>N\u00f3 h\u1ed7 tr\u1ee3 <code>cudaMalloc</code> ph\u00eda thi\u1ebft b\u1ecb, cho ph\u00e9p c\u00e1c lu\u1ed3ng c\u1ea5p ph\u00e1t b\u1ed9 nh\u1edb cho c\u00e1c lu\u1ed3ng con c\u1ee7a ch\u00fang.</li> <li>N\u00f3 \u0111\u01a1n gi\u1ea3n h\u00f3a vi\u1ec7c tri\u1ec3n khai c\u00e1c thu\u1eadt to\u00e1n ph\u1ee9c t\u1ea1p nh\u01b0 l\u00e0m m\u1ecbn l\u01b0\u1edbi th\u00edch \u1ee9ng, t\u00ecm ki\u1ebfm \u0111\u1ed3 th\u1ecb v\u00e0 c\u00e2y \u0111\u1ec7 quy.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 21 d\u1ea1y b\u1ea1n c\u00e1ch l\u00e0m cho GPU t\u1ef1 l\u1eadp l\u1ecbch. B\u1eb1ng c\u00e1ch cho ph\u00e9p c\u00e1c lu\u1ed3ng kh\u1edfi ch\u1ea1y kernel, b\u1ea1n chuy\u1ec3n t\u1eeb t\u00ednh song song \"t\u0129nh\" (k\u00edch th\u01b0\u1edbc d\u1eef li\u1ec7u c\u1ed1 \u0111\u1ecbnh) sang t\u00ednh song song \"\u0111\u1ed9ng\", \u0111i\u1ec1u c\u1ea7n thi\u1ebft cho c\u00e1c m\u00f4 ph\u1ecfng th\u1ef1c t\u1ebf ph\u1ee9c t\u1ea1p n\u01a1i kh\u1ed1i l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c \u0111\u01b0\u1ee3c ph\u00e1t hi\u1ec7n ngay l\u1eadp t\u1ee9c.</p>"},{"location":"cuda/pmpp/chapter-22/","title":"Chapter 22: Advanced Practices and Future Evolution","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>This chapter provides a high-level overview of how the CUDA programming model and GPU hardware have evolved over several generations (from Fermi and Kepler to Pascal and Ampere). It focuses on features that improve developer productivity and system-level performance.</p> <p>Ch\u01b0\u01a1ng n\u00e0y cung c\u1ea5p c\u00e1i nh\u00ecn t\u1ed5ng quan c\u1ea5p cao v\u1ec1 c\u00e1ch m\u00f4 h\u00ecnh l\u1eadp tr\u00ecnh CUDA v\u00e0 ph\u1ea7n c\u1ee9ng GPU \u0111\u00e3 ph\u00e1t tri\u1ec3n qua nhi\u1ec1u th\u1ebf h\u1ec7 (t\u1eeb Fermi v\u00e0 Kepler \u0111\u1ebfn Pascal v\u00e0 Ampere). N\u00f3 t\u1eadp trung v\u00e0o c\u00e1c t\u00ednh n\u0103ng c\u1ea3i thi\u1ec7n n\u0103ng su\u1ea5t c\u1ee7a nh\u00e0 ph\u00e1t tri\u1ec3n v\u00e0 hi\u1ec7u su\u1ea5t c\u1ea5p h\u1ec7 th\u1ed1ng.</p>"},{"location":"cuda/pmpp/chapter-22/#en-interaction","title":"22.1 Model of Host/Device Interaction","text":"<ul> <li>Historical Context: Early GPUs had strictly separate memory spaces, requiring manual <code>cudaMemcpy</code> for every data move.</li> <li>Zero-Copy Memory: Introduced in CUDA 2.2. It allows a kernel to access pinned host memory directly over the PCIe bus. It is useful for data that is accessed only once or twice, as it avoids the overhead of a full copy, but it is limited by PCIe bandwidth.</li> <li>Unified Virtual Addressing (UVA): Introduced in CUDA 4. It gives the host and device a single virtual address space. The system can automatically determine if a pointer resides on the CPU or GPU, removing the need to specify the direction in memory copies.</li> <li>Unified Memory (UM): Introduced in CUDA 6. It creates a pool of managed memory shared between the CPU and GPU.<ul> <li>Pascal Evolution: Modern GPUs (Pascal and later) support Hardware Page Faulting. If a GPU tries to access data currently on the CPU, the hardware triggers a fault and migrates the data automatically. This allows for oversubscribing GPU memory (processing datasets larger than physical VRAM).</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/chapter-22/#en-control","title":"22.2 Kernel Execution Control","text":"<ul> <li>Function Calls within Kernels: Early GPUs required the compiler to \"inline\" all functions. Kepler introduced a hardware-managed stack, allowing true function calls and recursion.</li> <li>Lambdas and Composability: Support for C++11 lambdas allows for more reusable and modern code structures.</li> <li>Simultaneous Grid Execution: Starting with the Fermi architecture, GPUs can execute multiple different kernels from the same application at the same time, improving utilization for small kernels.</li> <li>Interruptible Grids: Allows the user to \"cancel\" a long-running kernel without rebooting the system.</li> <li>Cooperative Kernels: Introduced in CUDA 11. This allows thread blocks to synchronize with each other across the entire GPU (global synchronization), which was previously impossible without terminating the kernel.</li> </ul>"},{"location":"cuda/pmpp/chapter-22/#en-throughput","title":"22.3 Memory Bandwidth and Compute Throughput","text":"<ul> <li>Double-Precision (FP64): Early GPUs were very slow at FP64 math. Fermi and later architectures significantly strengthened FP64 units, making GPUs viable for high-end scientific simulations.</li> <li>Half-Precision (FP16): The Pascal architecture added support for 16-bit math, which is 2x faster than 32-bit.<ul> <li>Ampere/Tensor Cores: Mentions the massive jump in throughput for AI workloads using specialized Tensor Core hardware.</li> </ul> </li> <li>Interconnects (NVLink): To bypass the slow PCIe bus, NVIDIA introduced NVLink, a high-speed \"GPU-to-GPU\" and \"GPU-to-CPU\" interconnect that drastically improves scalability in multi-GPU systems.</li> <li>HBM2: Explains the shift to High-Bandwidth Memory (stacked DRAM) to provide the massive data rates required by modern AI and HPC.</li> </ul>"},{"location":"cuda/pmpp/chapter-22/#en-profiling","title":"22.4 Programming Environment and Profiling","text":"<ul> <li>Unified Device Memory Space: Simplifies the creation of libraries. A single function can now accept a pointer regardless of whether it points to global, local, or shared memory.</li> <li>Profiling with Critical Path Analysis: Introduces a sophisticated way to analyze performance. Instead of just looking for the \"slowest\" kernel, the tool identifies the Critical Path\u2014the sequence of operations that actually makes the CPU wait. Optimizing a kernel not on the critical path provides zero total speedup.</li> </ul>"},{"location":"cuda/pmpp/chapter-22/#en-future","title":"22.5 Future Outlook","text":"<ul> <li>The authors predict an \"insatiable demand\" for faster computing systems.</li> <li>Future improvements will likely focus on Storage Parallelism (getting data from SSDs to GPUs faster) and higher-level tools like Thrust that generate CUDA code automatically.</li> </ul> <p>Key Takeaway: Chapter 22 transitions from \"how to write a kernel\" to \"how to build a system.\" It emphasizes that modern GPU programming is moving away from manual memory management toward Unified Memory and Task-Level Concurrency, allowing developers to focus on high-level logic while the hardware handles the data migration.</p>"},{"location":"cuda/pmpp/chapter-22/#vi-interaction","title":"22.1 M\u00f4 h\u00ecnh t\u01b0\u01a1ng t\u00e1c Host/Device","text":"<ul> <li>B\u1ed1i c\u1ea3nh l\u1ecbch s\u1eed: C\u00e1c GPU \u0111\u1eddi \u0111\u1ea7u c\u00f3 kh\u00f4ng gian b\u1ed9 nh\u1edb ho\u00e0n to\u00e0n t\u00e1ch bi\u1ec7t, y\u00eau c\u1ea7u l\u1ec7nh <code>cudaMemcpy</code> th\u1ee7 c\u00f4ng cho m\u1ecdi l\u1ea7n di chuy\u1ec3n d\u1eef li\u1ec7u.</li> <li>Zero-Copy Memory: \u0110\u01b0\u1ee3c gi\u1edbi thi\u1ec7u trong CUDA 2.2. N\u00f3 cho ph\u00e9p m\u1ed9t kernel truy c\u1eadp tr\u1ef1c ti\u1ebfp v\u00e0o b\u1ed9 nh\u1edb host \u0111\u01b0\u1ee3c ghim (pinned) th\u00f4ng qua bus PCIe. N\u00f3 h\u1eefu \u00edch cho d\u1eef li\u1ec7u ch\u1ec9 \u0111\u01b0\u1ee3c truy c\u1eadp m\u1ed9t ho\u1eb7c hai l\u1ea7n, v\u00ec n\u00f3 tr\u00e1nh \u0111\u01b0\u1ee3c chi ph\u00ed sao ch\u00e9p to\u00e0n b\u1ed9, nh\u01b0ng b\u1ecb gi\u1edbi h\u1ea1n b\u1edfi b\u0103ng th\u00f4ng PCIe.</li> <li>Unified Virtual Addressing (UVA): \u0110\u01b0\u1ee3c gi\u1edbi thi\u1ec7u trong CUDA 4. N\u00f3 cung c\u1ea5p cho host v\u00e0 device m\u1ed9t kh\u00f4ng gian \u0111\u1ecba ch\u1ec9 \u1ea3o duy nh\u1ea5t. H\u1ec7 th\u1ed1ng c\u00f3 th\u1ec3 t\u1ef1 \u0111\u1ed9ng x\u00e1c \u0111\u1ecbnh xem m\u1ed9t con tr\u1ecf n\u1eb1m tr\u00ean CPU hay GPU, lo\u1ea1i b\u1ecf nhu c\u1ea7u ch\u1ec9 \u0111\u1ecbnh h\u01b0\u1edbng trong c\u00e1c b\u1ea3n sao b\u1ed9 nh\u1edb.</li> <li>Unified Memory (UM): \u0110\u01b0\u1ee3c gi\u1edbi thi\u1ec7u trong CUDA 6. N\u00f3 t\u1ea1o ra m\u1ed9t b\u1ec3 b\u1ed9 nh\u1edb (managed memory pool) \u0111\u01b0\u1ee3c chia s\u1ebb gi\u1eefa CPU v\u00e0 GPU.<ul> <li>S\u1ef1 ti\u1ebfn h\u00f3a c\u1ee7a Pascal: C\u00e1c GPU hi\u1ec7n \u0111\u1ea1i (Pascal tr\u1edf v\u1ec1 sau) h\u1ed7 tr\u1ee3 L\u1ed7i trang ph\u1ea7n c\u1ee9ng (Hardware Page Faulting). N\u1ebfu GPU c\u1ed1 g\u1eafng truy c\u1eadp d\u1eef li\u1ec7u hi\u1ec7n \u0111ang \u1edf tr\u00ean CPU, ph\u1ea7n c\u1ee9ng s\u1ebd k\u00edch ho\u1ea1t l\u1ed7i trang v\u00e0 t\u1ef1 \u0111\u1ed9ng di chuy\u1ec3n d\u1eef li\u1ec7u. \u0110i\u1ec1u n\u00e0y cho ph\u00e9p \"oversubscribing\" b\u1ed9 nh\u1edb GPU (x\u1eed l\u00fd c\u00e1c t\u1eadp d\u1eef li\u1ec7u l\u1edbn h\u01a1n dung l\u01b0\u1ee3ng VRAM v\u1eadt l\u00fd).</li> </ul> </li> </ul>"},{"location":"cuda/pmpp/chapter-22/#vi-control","title":"22.2 Ki\u1ec3m so\u00e1t th\u1ef1c thi Kernel","text":"<ul> <li>G\u1ecdi h\u00e0m b\u00ean trong Kernel: C\u00e1c GPU \u0111\u1eddi \u0111\u1ea7u y\u00eau c\u1ea7u tr\u00ecnh bi\u00ean d\u1ecbch ph\u1ea3i \"inline\" t\u1ea5t c\u1ea3 c\u00e1c h\u00e0m. Kepler \u0111\u00e3 gi\u1edbi thi\u1ec7u ng\u0103n x\u1ebfp (stack) do ph\u1ea7n c\u1ee9ng qu\u1ea3n l\u00fd, cho ph\u00e9p g\u1ecdi h\u00e0m th\u1ef1c s\u1ef1 v\u00e0 \u0111\u1ec7 quy.</li> <li>Lambdas v\u00e0 T\u00ednh k\u1ebft h\u1ee3p (Composability): H\u1ed7 tr\u1ee3 lambda C++11 cho ph\u00e9p c\u00e1c c\u1ea5u tr\u00fac m\u00e3 hi\u1ec7n \u0111\u1ea1i v\u00e0 c\u00f3 th\u1ec3 t\u00e1i s\u1eed d\u1ee5ng t\u1ed1t h\u01a1n.</li> <li>Th\u1ef1c thi l\u01b0\u1edbi (Grid) \u0111\u1ed3ng th\u1eddi: B\u1eaft \u0111\u1ea7u t\u1eeb ki\u1ebfn tr\u00fac Fermi, GPU c\u00f3 th\u1ec3 th\u1ef1c thi nhi\u1ec1u kernel kh\u00e1c nhau t\u1eeb c\u00f9ng m\u1ed9t \u1ee9ng d\u1ee5ng t\u1ea1i c\u00f9ng m\u1ed9t th\u1eddi \u0111i\u1ec3m, c\u1ea3i thi\u1ec7n hi\u1ec7u su\u1ea5t s\u1eed d\u1ee5ng cho c\u00e1c kernel nh\u1ecf.</li> <li>L\u01b0\u1edbi c\u00f3 th\u1ec3 ng\u1eaft (Interruptible Grids): Cho ph\u00e9p ng\u01b0\u1eddi d\u00f9ng \"h\u1ee7y\" m\u1ed9t kernel \u0111ang ch\u1ea1y l\u00e2u m\u00e0 kh\u00f4ng c\u1ea7n kh\u1edfi \u0111\u1ed9ng l\u1ea1i h\u1ec7 th\u1ed1ng.</li> <li>Kernel c\u1ed9ng t\u00e1c (Cooperative Kernels): \u0110\u01b0\u1ee3c gi\u1edbi thi\u1ec7u trong CUDA 11. T\u00ednh n\u0103ng n\u00e0y cho ph\u00e9p c\u00e1c kh\u1ed1i lu\u1ed3ng \u0111\u1ed3ng b\u1ed9 h\u00f3a v\u1edbi nhau tr\u00ean to\u00e0n b\u1ed9 GPU (\u0111\u1ed3ng b\u1ed9 h\u00f3a to\u00e0n c\u1ee5c), \u0111i\u1ec1u m\u00e0 tr\u01b0\u1edbc \u0111\u00e2y kh\u00f4ng th\u1ec3 th\u1ef1c hi\u1ec7n \u0111\u01b0\u1ee3c n\u1ebfu kh\u00f4ng k\u1ebft th\u00fac kernel.</li> </ul>"},{"location":"cuda/pmpp/chapter-22/#vi-throughput","title":"22.3 B\u0103ng th\u00f4ng b\u1ed9 nh\u1edb v\u00e0 Th\u00f4ng l\u01b0\u1ee3ng t\u00ednh to\u00e1n","text":"<ul> <li>\u0110\u1ed9 ch\u00ednh x\u00e1c k\u00e9p (FP64): C\u00e1c GPU \u0111\u1eddi \u0111\u1ea7u r\u1ea5t ch\u1eadm trong t\u00ednh to\u00e1n FP64. Fermi v\u00e0 c\u00e1c ki\u1ebfn tr\u00fac sau \u0111\u00f3 \u0111\u00e3 t\u0103ng c\u01b0\u1eddng \u0111\u00e1ng k\u1ec3 c\u00e1c \u0111\u01a1n v\u1ecb FP64, gi\u00fap GPU kh\u1ea3 thi cho c\u00e1c m\u00f4 ph\u1ecfng khoa h\u1ecdc cao c\u1ea5p.</li> <li>\u0110\u1ed9 ch\u00ednh x\u00e1c m\u1ed9t n\u1eeda (FP16): Ki\u1ebfn tr\u00fac Pascal \u0111\u00e3 th\u00eam h\u1ed7 tr\u1ee3 cho t\u00ednh to\u00e1n 16-bit, nhanh g\u1ea5p \u0111\u00f4i so v\u1edbi 32-bit.<ul> <li>Ampere/Tensor Cores: \u0110\u1ec1 c\u1eadp \u0111\u1ebfn s\u1ef1 nh\u1ea3y v\u1ecdt kh\u1ed5ng l\u1ed3 v\u1ec1 th\u00f4ng l\u01b0\u1ee3ng cho kh\u1ed1i l\u01b0\u1ee3ng c\u00f4ng vi\u1ec7c AI b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng ph\u1ea7n c\u1ee9ng Tensor Core chuy\u00ean d\u1ee5ng.</li> </ul> </li> <li>K\u1ebft n\u1ed1i (NVLink): \u0110\u1ec3 v\u01b0\u1ee3t qua bus PCIe ch\u1eadm, NVIDIA \u0111\u00e3 gi\u1edbi thi\u1ec7u NVLink, m\u1ed9t k\u1ebft n\u1ed1i t\u1ed1c \u0111\u1ed9 cao \"GPU-to-GPU\" v\u00e0 \"GPU-to-CPU\" gi\u00fap c\u1ea3i thi\u1ec7n \u0111\u00e1ng k\u1ec3 kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng trong c\u00e1c h\u1ec7 th\u1ed1ng \u0111a GPU.</li> <li>HBM2: Gi\u1ea3i th\u00edch s\u1ef1 chuy\u1ec3n d\u1ecbch sang B\u1ed9 nh\u1edb b\u0103ng th\u00f4ng cao (DRAM x\u1ebfp ch\u1ed3ng) \u0111\u1ec3 cung c\u1ea5p t\u1ed1c \u0111\u1ed9 d\u1eef li\u1ec7u kh\u1ed5ng l\u1ed3 theo y\u00eau c\u1ea7u c\u1ee7a AI v\u00e0 HPC hi\u1ec7n \u0111\u1ea1i.</li> </ul>"},{"location":"cuda/pmpp/chapter-22/#vi-profiling","title":"22.4 M\u00f4i tr\u01b0\u1eddng l\u1eadp tr\u00ecnh v\u00e0 Profiling","text":"<ul> <li>Kh\u00f4ng gian b\u1ed9 nh\u1edb thi\u1ebft b\u1ecb th\u1ed1ng nh\u1ea5t: \u0110\u01a1n gi\u1ea3n h\u00f3a vi\u1ec7c t\u1ea1o th\u01b0 vi\u1ec7n. M\u1ed9t h\u00e0m duy nh\u1ea5t hi\u1ec7n c\u00f3 th\u1ec3 ch\u1ea5p nh\u1eadn m\u1ed9t con tr\u1ecf b\u1ea5t k\u1ec3 n\u00f3 tr\u1ecf \u0111\u1ebfn b\u1ed9 nh\u1edb global, local hay shared.</li> <li>Profiling v\u1edbi Ph\u00e2n t\u00edch \u0111\u01b0\u1eddng d\u1eabn t\u1edbi h\u1ea1n (Critical Path Analysis): Gi\u1edbi thi\u1ec7u m\u1ed9t c\u00e1ch tinh vi \u0111\u1ec3 ph\u00e2n t\u00edch hi\u1ec7u su\u1ea5t. Thay v\u00ec ch\u1ec9 t\u00ecm ki\u1ebfm kernel \"ch\u1eadm nh\u1ea5t\", c\u00f4ng c\u1ee5 x\u00e1c \u0111\u1ecbnh \u0110\u01b0\u1eddng d\u1eabn t\u1edbi h\u1ea1n\u2014chu\u1ed7i c\u00e1c thao t\u00e1c th\u1ef1c s\u1ef1 khi\u1ebfn CPU ph\u1ea3i ch\u1edd \u0111\u1ee3i. T\u1ed1i \u01b0u h\u00f3a m\u1ed9t kernel kh\u00f4ng n\u1eb1m tr\u00ean \u0111\u01b0\u1eddng d\u1eabn t\u1edbi h\u1ea1n s\u1ebd kh\u00f4ng mang l\u1ea1i s\u1ef1 t\u0103ng t\u1ed1c t\u1ed5ng th\u1ec3.</li> </ul>"},{"location":"cuda/pmpp/chapter-22/#vi-future","title":"22.5 Tri\u1ec3n v\u1ecdng t\u01b0\u01a1ng lai","text":"<ul> <li>C\u00e1c t\u00e1c gi\u1ea3 d\u1ef1 \u0111o\u00e1n m\u1ed9t \"nhu c\u1ea7u v\u00f4 \u0111\u1ed9\" \u0111\u1ed1i v\u1edbi c\u00e1c h\u1ec7 th\u1ed1ng t\u00ednh to\u00e1n nhanh h\u01a1n.</li> <li>Nh\u1eefng c\u1ea3i ti\u1ebfn trong t\u01b0\u01a1ng lai c\u00f3 th\u1ec3 s\u1ebd t\u1eadp trung v\u00e0o T\u00ednh song song trong l\u01b0u tr\u1eef (Storage Parallelism) (l\u1ea5y d\u1eef li\u1ec7u t\u1eeb SSD sang GPU nhanh h\u01a1n) v\u00e0 c\u00e1c c\u00f4ng c\u1ee5 c\u1ea5p cao h\u01a1n nh\u01b0 Thrust t\u1ef1 \u0111\u1ed9ng t\u1ea1o m\u00e3 CUDA.</li> </ul> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 22 chuy\u1ec3n \u0111\u1ed5i t\u1eeb \"c\u00e1ch vi\u1ebft m\u1ed9t kernel\" sang \"c\u00e1ch x\u00e2y d\u1ef1ng m\u1ed9t h\u1ec7 th\u1ed1ng\". N\u00f3 nh\u1ea5n m\u1ea1nh r\u1eb1ng l\u1eadp tr\u00ecnh GPU hi\u1ec7n \u0111\u1ea1i \u0111ang chuy\u1ec3n d\u1ea7n t\u1eeb qu\u1ea3n l\u00fd b\u1ed9 nh\u1edb th\u1ee7 c\u00f4ng sang B\u1ed9 nh\u1edb th\u1ed1ng nh\u1ea5t (Unified Memory) v\u00e0 T\u00ednh \u0111\u1ed3ng th\u1eddi c\u1ea5p t\u00e1c v\u1ee5 (Task-Level Concurrency), cho ph\u00e9p c\u00e1c nh\u00e0 ph\u00e1t tri\u1ec3n t\u1eadp trung v\u00e0o logic c\u1ea5p cao trong khi ph\u1ea7n c\u1ee9ng x\u1eed l\u00fd vi\u1ec7c di chuy\u1ec3n d\u1eef li\u1ec7u.</p>"},{"location":"cuda/pmpp/chapter-23/","title":"Chapter 23: Conclusion and Outlook","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>In this final chapter, the authors revisit the journey of the book, comparing the evolution of GPUs from the G80 architecture (2006) to modern powerhouses like the Ampere and Hopper architectures. It serves as both a look back and a roadmap for the future of throughput-oriented computing.</p> <p>Trong ch\u01b0\u01a1ng cu\u1ed1i c\u00f9ng n\u00e0y, c\u00e1c t\u00e1c gi\u1ea3 xem x\u00e9t l\u1ea1i h\u00e0nh tr\u00ecnh c\u1ee7a cu\u1ed1n s\u00e1ch, so s\u00e1nh s\u1ef1 ph\u00e1t tri\u1ec3n c\u1ee7a GPU t\u1eeb ki\u1ebfn tr\u00fac G80 (2006) \u0111\u1ebfn nh\u1eefng c\u1ed7 m\u00e1y m\u1ea1nh m\u1ebd hi\u1ec7n \u0111\u1ea1i nh\u01b0 ki\u1ebfn tr\u00fac Ampere v\u00e0 Hopper. N\u00f3 \u0111\u00f3ng vai tr\u00f2 v\u1eeba l\u00e0 m\u1ed9t c\u00e1i nh\u00ecn l\u1ea1i, v\u1eeba l\u00e0 m\u1ed9t b\u1ea3n l\u1ed9 tr\u00ecnh cho t\u01b0\u01a1ng lai c\u1ee7a t\u00ednh to\u00e1n h\u01b0\u1edbng t\u1edbi th\u00f4ng l\u01b0\u1ee3ng.</p>"},{"location":"cuda/pmpp/chapter-23/#en-legacy","title":"23.1 A Legacy of Growth","text":"<ul> <li>Evolution of Performance: Since the first edition, GPU peak performance has increased by hundreds of times, and memory bandwidth has grown by dozens.</li> <li>Standardization: CUDA has evolved from a niche research project into the industry standard for high-performance computing, deep learning, and scientific visualization.</li> <li>Beyond Graphics: The GPU is no longer just a \"graphics\" processor. It is a general-purpose throughput engine that powers everything from desktop high-end gaming to the world's fastest supercomputers.</li> </ul>"},{"location":"cuda/pmpp/chapter-23/#en-message","title":"23.2 The Core Message: Parallel Thinking","text":"<ul> <li>Patterns over Syntax: The most important skill learned in this book is not CUDA syntax, but the ability to identify parallel patterns (Tiling, Scan, Reduction, Stencil) and map them to hardware.</li> <li>Hardware-Aware Design: High performance is only possible when software developers understand the reality of the hardware\u2014memory hierarchy, warp execution, and latency hiding.</li> <li>The Power of Abstraction: While low-level tuning is sometimes necessary, modern tools like Unified Memory and optimized libraries are making high-performance computing more accessible to everyone.</li> </ul>"},{"location":"cuda/pmpp/chapter-23/#en-future","title":"23.3 The Future: AI and Beyond","text":"<ul> <li>AI Revolution: The rise of Large Language Models (LLMs) and Generative AI has made GPU programming more critical than ever.</li> <li>New Hardware Frontiers: Future architectures will likely integrate even more specialized \"acceleration units\" (like Tensor Cores) for specific mathematical operations.</li> <li>Universal Parallelism: As datasets continue to grow, the ability to think and program in parallel will transition from a \"specialized skill\" to a \"fundamental requirement\" for all software engineers.</li> </ul>"},{"location":"cuda/pmpp/chapter-23/#en-final","title":"23.4 Final Words","text":"<p>The journey doesn't end here. The principles of data locality and throughput-oriented design are universal. Whether you are building the next world-changing AI model or simulating the collision of galaxies, the ability to harness massive parallelism is the \"superpower\" of the modern programmer.</p> <p>Key Takeaway: Chapter 23 reminds us that while hardware changes rapidly, the principles of parallel computing remain constant. Mastering these principles opens the door to solving the most challenging problems of the 21<sup>st</sup> century.</p>"},{"location":"cuda/pmpp/chapter-23/#vi-legacy","title":"23.1 Di s\u1ea3n c\u1ee7a s\u1ef1 t\u0103ng tr\u01b0\u1edfng","text":"<ul> <li>S\u1ef1 ti\u1ebfn h\u00f3a c\u1ee7a hi\u1ec7u su\u1ea5t: K\u1ec3 t\u1eeb \u1ea5n b\u1ea3n \u0111\u1ea7u ti\u00ean, hi\u1ec7u su\u1ea5t \u0111\u1ec9nh c\u1ee7a GPU \u0111\u00e3 t\u0103ng h\u00e0ng tr\u0103m l\u1ea7n v\u00e0 b\u0103ng th\u00f4ng b\u1ed9 nh\u1edb \u0111\u00e3 t\u0103ng h\u00e0ng ch\u1ee5c l\u1ea7n.</li> <li>Ti\u00eau chu\u1ea9n h\u00f3a: CUDA \u0111\u00e3 ph\u00e1t tri\u1ec3n t\u1eeb m\u1ed9t d\u1ef1 \u00e1n nghi\u00ean c\u1ee9u ng\u00e1ch th\u00e0nh ti\u00eau chu\u1ea9n c\u00f4ng nghi\u1ec7p cho t\u00ednh to\u00e1n hi\u1ec7u n\u0103ng cao, h\u1ecdc s\u00e2u v\u00e0 h\u00ecnh \u1ea3nh h\u00f3a khoa h\u1ecdc.</li> <li>V\u01b0\u1ee3t xa \u0111\u1ed3 h\u1ecda: GPU kh\u00f4ng c\u00f2n ch\u1ec9 l\u00e0 m\u1ed9t b\u1ed9 x\u1eed l\u00fd \"\u0111\u1ed3 h\u1ecda\". N\u00f3 l\u00e0 m\u1ed9t \u0111\u1ed9ng c\u01a1 th\u00f4ng l\u01b0\u1ee3ng \u0111a n\u0103ng cung c\u1ea5p s\u1ee9c m\u1ea1nh cho m\u1ecdi th\u1ee9, t\u1eeb ch\u01a1i game cao c\u1ea5p tr\u00ean m\u00e1y t\u00ednh \u0111\u1ec3 b\u00e0n \u0111\u1ebfn nh\u1eefng si\u00eau m\u00e1y t\u00ednh nhanh nh\u1ea5t th\u1ebf gi\u1edbi.</li> </ul>"},{"location":"cuda/pmpp/chapter-23/#vi-message","title":"23.2 Th\u00f4ng \u0111i\u1ec7p c\u1ed1t l\u00f5i: T\u01b0 duy song song","text":"<ul> <li>M\u1eabu quan tr\u1ecdng h\u01a1n c\u00fa ph\u00e1p: K\u1ef9 n\u0103ng quan tr\u1ecdng nh\u1ea5t c\u00f3 \u0111\u01b0\u1ee3c t\u1eeb cu\u1ed1n s\u00e1ch n\u00e0y kh\u00f4ng ph\u1ea3i l\u00e0 c\u00fa ph\u00e1p CUDA, m\u00e0 l\u00e0 kh\u1ea3 n\u0103ng x\u00e1c \u0111\u1ecbnh c\u00e1c m\u1eabu song song (Tiling, Scan, Reduction, Stencil) v\u00e0 \u00e1nh x\u1ea1 ch\u00fang v\u00e0o ph\u1ea7n c\u1ee9ng.</li> <li>Thi\u1ebft k\u1ebf nh\u1eadn th\u1ee9c ph\u1ea7n c\u1ee9ng: Hi\u1ec7u su\u1ea5t cao ch\u1ec9 c\u00f3 th\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c khi c\u00e1c nh\u00e0 ph\u00e1t tri\u1ec3n ph\u1ea7n m\u1ec1m hi\u1ec3u \u0111\u01b0\u1ee3c th\u1ef1c t\u1ebf c\u1ee7a ph\u1ea7n c\u1ee9ng\u2014ph\u00e2n c\u1ea5p b\u1ed9 nh\u1edb, th\u1ef1c thi warp v\u00e0 che gi\u1ea5u \u0111\u1ed9 tr\u1ec5.</li> <li>S\u1ee9c m\u1ea1nh c\u1ee7a tr\u1eebu t\u01b0\u1ee3ng h\u00f3a: M\u1eb7c d\u00f9 vi\u1ec7c \u0111i\u1ec1u ch\u1ec9nh c\u1ea5p th\u1ea5p \u0111\u00f4i khi l\u00e0 c\u1ea7n thi\u1ebft, nh\u01b0ng c\u00e1c c\u00f4ng c\u1ee5 hi\u1ec7n \u0111\u1ea1i nh\u01b0 B\u1ed9 nh\u1edb th\u1ed1ng nh\u1ea5t (Unified Memory) v\u00e0 c\u00e1c th\u01b0 vi\u1ec7n t\u1ed1i \u01b0u h\u00f3a \u0111ang gi\u00fap t\u00ednh to\u00e1n hi\u1ec7u n\u0103ng cao tr\u1edf n\u00ean d\u1ec5 ti\u1ebfp c\u1eadn h\u01a1n v\u1edbi m\u1ecdi ng\u01b0\u1eddi.</li> </ul>"},{"location":"cuda/pmpp/chapter-23/#vi-future","title":"23.3 T\u01b0\u01a1ng lai: AI v\u00e0 xa h\u01a1n n\u1eefa","text":"<ul> <li>Cu\u1ed9c c\u00e1ch m\u1ea1ng AI: S\u1ef1 tr\u1ed7i d\u1eady c\u1ee7a c\u00e1c M\u00f4 h\u00ecnh ng\u00f4n ng\u1eef l\u1edbn (LLM) v\u00e0 AI t\u1ea1o h\u00ecnh (Generative AI) \u0111\u00e3 khi\u1ebfn l\u1eadp tr\u00ecnh GPU tr\u1edf n\u00ean quan tr\u1ecdng h\u01a1n bao gi\u1edd h\u1ebft.</li> <li>Nh\u1eefng ranh gi\u1edbi ph\u1ea7n c\u1ee9ng m\u1edbi: C\u00e1c ki\u1ebfn tr\u00fac trong t\u01b0\u01a1ng lai c\u00f3 th\u1ec3 s\u1ebd t\u00edch h\u1ee3p nhi\u1ec1u \"\u0111\u01a1n v\u1ecb t\u0103ng t\u1ed1c\" chuy\u00ean d\u1ee5ng h\u01a1n n\u1eefa (nh\u01b0 Tensor Cores) cho c\u00e1c ph\u00e9p to\u00e1n c\u1ee5 th\u1ec3.</li> <li>T\u00ednh song song ph\u1ed5 qu\u00e1t: Khi c\u00e1c t\u1eadp d\u1eef li\u1ec7u ti\u1ebfp t\u1ee5c t\u0103ng tr\u01b0\u1edfng, kh\u1ea3 n\u0103ng t\u01b0 duy v\u00e0 l\u1eadp tr\u00ecnh song song s\u1ebd chuy\u1ec3n \u0111\u1ed5i t\u1eeb m\u1ed9t \"k\u1ef9 n\u0103ng chuy\u00ean m\u00f4n\" th\u00e0nh m\u1ed9t \"y\u00eau c\u1ea7u c\u01a1 b\u1ea3n\" \u0111\u1ed1i v\u1edbi t\u1ea5t c\u1ea3 c\u00e1c k\u1ef9 s\u01b0 ph\u1ea7n m\u1ec1m.</li> </ul>"},{"location":"cuda/pmpp/chapter-23/#vi-final","title":"23.4 L\u1eddi k\u1ebft","text":"<p>H\u00e0nh tr\u00ecnh kh\u00f4ng k\u1ebft th\u00fac \u1edf \u0111\u00e2y. C\u00e1c nguy\u00ean t\u1eafc v\u1ec1 t\u00ednh c\u1ee5c b\u1ed9 d\u1eef li\u1ec7u v\u00e0 thi\u1ebft k\u1ebf h\u01b0\u1edbng t\u1edbi th\u00f4ng l\u01b0\u1ee3ng l\u00e0 ph\u1ed5 qu\u00e1t. Cho d\u00f9 b\u1ea1n \u0111ang x\u00e2y d\u1ef1ng m\u00f4 h\u00ecnh AI thay \u0111\u1ed5i th\u1ebf gi\u1edbi ti\u1ebfp theo hay m\u00f4 ph\u1ecfng s\u1ef1 va ch\u1ea1m c\u1ee7a c\u00e1c thi\u00ean h\u00e0, kh\u1ea3 n\u0103ng khai th\u00e1c t\u00ednh song song kh\u1ed5ng l\u1ed3 ch\u00ednh l\u00e0 \"si\u00eau n\u0103ng l\u1ef1c\" c\u1ee7a l\u1eadp tr\u00ecnh vi\u00ean hi\u1ec7n \u0111\u1ea1i.</p> <p>\u0110i\u1ec3m ch\u00ednh: Ch\u01b0\u01a1ng 23 nh\u1eafc nh\u1edf ch\u00fang ta r\u1eb1ng m\u1eb7c d\u00f9 ph\u1ea7n c\u1ee9ng thay \u0111\u1ed5i nhanh ch\u00f3ng, c\u00e1c nguy\u00ean t\u1eafc c\u1ee7a t\u00ednh to\u00e1n song song v\u1eabn kh\u00f4ng \u0111\u1ed5i. L\u00e0m ch\u1ee7 c\u00e1c nguy\u00ean t\u1eafc n\u00e0y s\u1ebd m\u1edf ra c\u00e1nh c\u1eeda \u0111\u1ec3 gi\u1ea3i quy\u1ebft nh\u1eefng v\u1ea5n \u0111\u1ec1 th\u00e1ch th\u1ee9c nh\u1ea5t c\u1ee7a th\u1ebf k\u1ef7 21.</p>"},{"location":"cuda/pmpp/engineer/","title":"The Road to becoming a GPU Engineer","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>To get the most benefit from this book and turn its concepts into a high-paying career at companies like NVIDIA, AMD, Apple, Google, or Meta, you must transition from a \"reader\" to an \"experimentalist.\"</p> <p>Here is a roadmap for getting the most out of this material and securing a role as a GPU/Parallel Systems Engineer.</p> <p>\u0110\u1ec3 nh\u1eadn \u0111\u01b0\u1ee3c nhi\u1ec1u l\u1ee3i \u00edch nh\u1ea5t t\u1eeb cu\u1ed1n s\u00e1ch n\u00e0y v\u00e0 bi\u1ebfn nh\u1eefng kh\u00e1i ni\u1ec7m c\u1ee7a n\u00f3 th\u00e0nh m\u1ed9t s\u1ef1 nghi\u1ec7p thu nh\u1eadp cao t\u1ea1i c\u00e1c c\u00f4ng ty nh\u01b0 NVIDIA, AMD, Apple, Google, hay Meta, b\u1ea1n ph\u1ea3i chuy\u1ec3n \u0111\u1ed5i t\u1eeb m\u1ed9t \"ng\u01b0\u1eddi \u0111\u1ecdc\" th\u00e0nh m\u1ed9t \"ng\u01b0\u1eddi th\u1ef1c nghi\u1ec7m\".</p> <p>D\u01b0\u1edbi \u0111\u00e2y l\u00e0 l\u1ed9 tr\u00ecnh \u0111\u1ec3 t\u1eadn d\u1ee5ng t\u1ed1i \u0111a t\u00e0i li\u1ec7u n\u00e0y v\u00e0 \u0111\u1ea3m b\u1ea3o m\u1ed9t v\u1ecb tr\u00ed K\u1ef9 s\u01b0 GPU/H\u1ec7 th\u1ed1ng Song song.</p>"},{"location":"cuda/pmpp/engineer/#en-benefit","title":"1. How to get the most benefit from this book","text":"<p>The book is subtitled \"A Hands-on Approach.\" If you don't write the code, you only learn 10% of the value.</p> <ul> <li>The \"Clean Room\" Implementation: After reading a chapter on a pattern (like Scan or Merge), close the book and try to implement it from scratch using only the mathematical description. You will fail at first\u2014and those failures (bank conflicts, deadlocks, uncoalesced memory) are where the real learning happens.</li> <li>Profile Everything: Never assume your code is fast. Use NVIDIA Nsight Compute and Nsight Systems. Every time you apply an optimization from Chapter 6, look at the \"Speed of Light\" (SOL) markers in the profiler to see why it got faster.</li> <li>The Roofline Model: Master the chart in Chapter 5. For every kernel you write, identify if you are Memory-Bound or Compute-Bound. If you don't know which one you are, you aren't engineering; you're guessing.</li> </ul>"},{"location":"cuda/pmpp/engineer/#en-jobs","title":"2. How to secure a job at a Top Tech Company","text":"<p>Top companies don't just hire people who know CUDA; they hire people who understand Hardware-Software Co-design.</p> <ul> <li>Build a Portfolio of Kernels: Don't just do the exercises. Implement a modern operation used in AI, like FlashAttention or a custom LayerNorm. Post the code on GitHub with a detailed README explaining your optimization choices and showing benchmark graphs comparing your speed to a baseline.</li> <li>Master C++ first, then CUDA: GPU engineering is 90% high-performance C++. You need to be expert-level in memory management, pointers, and templates.</li> <li>The \"Whiteboard\" Challenge: In interviews at NVIDIA or Google, they will ask you to \"Parallelize this sequential algorithm on the fly.\" You must be able to instantly spot Data Dependencies and decide between a Gather or Scatter approach (Chapter 17/18).</li> <li>Target the \"Ops\" Teams: Look for teams labeled \"Kernels,\" \"AI Infrastructure,\" \"HPC,\" or \"Deep Learning Compiler.\" These are the groups that specifically require the knowledge in this book.</li> </ul>"},{"location":"cuda/pmpp/engineer/#en-continue","title":"3. How to continue your study from here","text":"<ul> <li>OpenAI Triton: After learning CUDA, look at Triton. It is a language used to write fast AI kernels (like those in ChatGPT) more easily than CUDA. Understanding the \"tiling\" and \"coalescing\" from this book is mandatory to use Triton effectively.</li> <li>Study CUTLASS and CUB: Look at NVIDIA's open-source libraries CUTLASS (for matrix multiplication) and CUB (for primitives). Reading their source code will show you how \"World Class\" engineers implement the patterns from this book.</li> <li>Explore Cross-Platform: Learn SYCL (for Intel/AMD/NVIDIA) or Apple Metal. This ensures you aren't just a \"CUDA dev\" but a \"Parallel Programmer\" who can work on any chip.</li> <li>Deep Learning Compilers: Read about TVM or MLIR. The future of this field is \"Compilers writing Kernels.\" Understanding how they automate the optimizations in Chapter 6 is the next frontier.</li> </ul>"},{"location":"cuda/pmpp/engineer/#en-skills","title":"4. Essential \"Peripheral\" Skills to prepare","text":"<ul> <li>Numerical Analysis: Go deeper than Appendix A. Understand how Mixed Precision (FP8, FP16, BF16) affects both speed and accuracy. This is the secret to modern AI training.</li> <li>Computer Architecture: Read Computer Architecture: A Quantitative Approach by Hennessy and Patterson. You need to understand the \"Memory Wall\" and \"Instruction Level Parallelism\" (ILP) at a deep hardware level.</li> <li>Distributed Systems: As seen in Chapter 20, the future is \"Multi-GPU.\" Learn about NCCL (NVIDIA Collective Communications Library) and how data moves across NVLink and InfiniBand.</li> </ul>"},{"location":"cuda/pmpp/engineer/#one-final-thought","title":"One Final Thought","text":"<p>The authors use the Peach Analogy in Chapter 1: The \"pit\" is the hard, sequential part, and the \"flesh\" is the large, parallel part.</p> <p>Your value as an engineer is your ability to shrink the pit. Top companies are currently in a \"war for compute.\" If you can take a process that takes 1,000 GPUs and optimize the kernels so it only takes 500 GPUs, you have just saved that company millions of dollars. Performance is the product.</p> <p>Treat every cycle and every byte of bandwidth as a precious resource, and you will find yourself among the most sought-after engineers in the industry.</p>"},{"location":"cuda/pmpp/engineer/#vi-benefit","title":"1. C\u00e1ch t\u1eadn d\u1ee5ng t\u1ed1i \u0111a cu\u1ed1n s\u00e1ch n\u00e0y","text":"<p>Cu\u1ed1n s\u00e1ch c\u00f3 ph\u1ee5 \u0111\u1ec1 l\u00e0 \"M\u1ed9t c\u00e1ch ti\u1ebfp c\u1eadn th\u1ef1c h\u00e0nh (A Hands-on Approach)\". N\u1ebfu b\u1ea1n kh\u00f4ng vi\u1ebft m\u00e3, b\u1ea1n ch\u1ec9 h\u1ecdc \u0111\u01b0\u1ee3c 10% gi\u00e1 tr\u1ecb.</p> <ul> <li>Tri\u1ec3n khai \"Ph\u00f2ng s\u1ea1ch\" (Clean Room Implementation): Sau khi \u0111\u1ecdc m\u1ed9t ch\u01b0\u01a1ng v\u1ec1 m\u1ed9t m\u1eabu (nh\u01b0 Scan ho\u1eb7c Merge), h\u00e3y \u0111\u00f3ng s\u00e1ch l\u1ea1i v\u00e0 c\u1ed1 g\u1eafng t\u1ef1 m\u00ecnh tri\u1ec3n khai n\u00f3 t\u1eeb \u0111\u1ea7u ch\u1ec9 b\u1eb1ng m\u00f4 t\u1ea3 to\u00e1n h\u1ecdc. B\u1ea1n s\u1ebd th\u1ea5t b\u1ea1i l\u00fac \u0111\u1ea7u\u2014v\u00e0 ch\u00ednh nh\u1eefng th\u1ea5t b\u1ea1i \u0111\u00f3 (bank conflicts, deadlocks, uncoalesced memory) m\u1edbi l\u00e0 n\u01a1i vi\u1ec7c h\u1ecdc th\u1ef1c s\u1ef1 di\u1ec5n ra.</li> <li>Profile m\u1ecdi th\u1ee9: \u0110\u1eebng bao gi\u1edd gi\u1ea3 \u0111\u1ecbnh r\u1eb1ng m\u00e3 c\u1ee7a b\u1ea1n nhanh. H\u00e3y s\u1eed d\u1ee5ng NVIDIA Nsight Compute v\u00e0 Nsight Systems. M\u1ed7i khi b\u1ea1n \u00e1p d\u1ee5ng m\u1ed9t t\u1ed1i \u01b0u h\u00f3a t\u1eeb Ch\u01b0\u01a1ng 6, h\u00e3y nh\u00ecn v\u00e0o c\u00e1c ch\u1ec9 s\u1ed1 \"Speed of Light\" (SOL) trong tr\u00ecnh profile \u0111\u1ec3 xem t\u1ea1i sao n\u00f3 l\u1ea1i nhanh h\u01a1n.</li> <li>M\u00f4 h\u00ecnh Roofline: L\u00e0m ch\u1ee7 bi\u1ec3u \u0111\u1ed3 trong Ch\u01b0\u01a1ng 5. V\u1edbi m\u1ed7i kernel b\u1ea1n vi\u1ebft, h\u00e3y x\u00e1c \u0111\u1ecbnh xem b\u1ea1n \u0111ang b\u1ecb Gi\u1edbi h\u1ea1n b\u1edfi b\u1ed9 nh\u1edb (Memory-Bound) hay Gi\u1edbi h\u1ea1n b\u1edfi t\u00ednh to\u00e1n (Compute-Bound). N\u1ebfu b\u1ea1n kh\u00f4ng bi\u1ebft m\u00ecnh thu\u1ed9c lo\u1ea1i n\u00e0o, b\u1ea1n kh\u00f4ng ph\u1ea3i \u0111ang l\u00e0m k\u1ef9 thu\u1eadt; b\u1ea1n \u0111ang \u0111o\u00e1n m\u00f2.</li> </ul>"},{"location":"cuda/pmpp/engineer/#vi-jobs","title":"2. C\u00e1ch \u0111\u1ea3m b\u1ea3o m\u1ed9t c\u00f4ng vi\u1ec7c t\u1ea1i c\u00e1c c\u00f4ng ty c\u00f4ng ngh\u1ec7 h\u00e0ng \u0111\u1ea7u","text":"<p>C\u00e1c c\u00f4ng ty h\u00e0ng \u0111\u1ea7u kh\u00f4ng ch\u1ec9 thu\u00ea nh\u1eefng ng\u01b0\u1eddi bi\u1ebft CUDA; h\u1ecd thu\u00ea nh\u1eefng ng\u01b0\u1eddi hi\u1ec3u v\u1ec1 Thi\u1ebft k\u1ebf \u0111\u1ed3ng b\u1ed9 Ph\u1ea7n c\u1ee9ng-Ph\u1ea7n m\u1ec1m (Hardware-Software Co-design).</p> <ul> <li>X\u00e2y d\u1ef1ng danh m\u1ee5c c\u00e1c Kernel: \u0110\u1eebng ch\u1ec9 l\u00e0m c\u00e1c b\u00e0i t\u1eadp. H\u00e3y tri\u1ec3n khai m\u1ed9t ph\u00e9p to\u00e1n hi\u1ec7n \u0111\u1ea1i \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong AI, nh\u01b0 FlashAttention ho\u1eb7c m\u1ed9t LayerNorm t\u00f9y ch\u1ec9nh. \u0110\u0103ng m\u00e3 ngu\u1ed3n l\u00ean GitHub v\u1edbi m\u1ed9t t\u1ec7p README chi ti\u1ebft gi\u1ea3i th\u00edch c\u00e1c l\u1ef1a ch\u1ecdn t\u1ed1i \u01b0u h\u00f3a c\u1ee7a b\u1ea1n v\u00e0 hi\u1ec3n th\u1ecb c\u00e1c bi\u1ec3u \u0111\u1ed3 benchmark so s\u00e1nh t\u1ed1c \u0111\u1ed9 c\u1ee7a b\u1ea1n v\u1edbi m\u1ed9t \u0111\u01b0\u1eddng c\u01a1 s\u1edf (baseline).</li> <li>L\u00e0m ch\u1ee7 C++ tr\u01b0\u1edbc, sau \u0111\u00f3 m\u1edbi \u0111\u1ebfn CUDA: K\u1ef9 thu\u1eadt GPU chi\u1ebfm 90% l\u00e0 C++ hi\u1ec7u n\u0103ng cao. B\u1ea1n c\u1ea7n \u1edf tr\u00ecnh \u0111\u1ed9 chuy\u00ean gia v\u1ec1 qu\u1ea3n l\u00fd b\u1ed9 nh\u1edb, con tr\u1ecf v\u00e0 templates.</li> <li>Th\u00e1ch th\u1ee9c \"B\u1ea3ng tr\u1eafng\": Trong c\u00e1c bu\u1ed5i ph\u1ecfng v\u1ea5n t\u1ea1i NVIDIA ho\u1eb7c Google, h\u1ecd s\u1ebd y\u00eau c\u1ea7u b\u1ea1n \"Song song h\u00f3a thu\u1eadt to\u00e1n tu\u1ea7n t\u1ef1 n\u00e0y ngay l\u1eadp t\u1ee9c\". B\u1ea1n ph\u1ea3i c\u00f3 kh\u1ea3 n\u0103ng nh\u1eadn ra ngay c\u00e1c S\u1ef1 ph\u1ee5 thu\u1ed9c d\u1eef li\u1ec7u (Data Dependencies) v\u00e0 quy\u1ebft \u0111\u1ecbnh gi\u1eefa c\u00e1ch ti\u1ebfp c\u1eadn Gather hay Scatter (Ch\u01b0\u01a1ng 17/18).</li> <li>Nh\u1eafm v\u00e0o c\u00e1c nh\u00f3m \"Ops\": H\u00e3y t\u00ecm ki\u1ebfm c\u00e1c nh\u00f3m c\u00f3 t\u00ean \"Kernels\", \"AI Infrastructure\", \"HPC\", ho\u1eb7c \"Deep Learning Compiler\". \u0110\u00e2y l\u00e0 nh\u1eefng nh\u00f3m y\u00eau c\u1ea7u c\u1ee5 th\u1ec3 ki\u1ebfn th\u1ee9c trong cu\u1ed1n s\u00e1ch n\u00e0y.</li> </ul>"},{"location":"cuda/pmpp/engineer/#vi-continue","title":"3. C\u00e1ch ti\u1ebfp t\u1ee5c h\u1ecdc t\u1eadp t\u1eeb \u0111\u00e2y","text":"<ul> <li>OpenAI Triton: Sau khi h\u1ecdc CUDA, h\u00e3y t\u00ecm hi\u1ec3u v\u1ec1 Triton. \u0110\u00e2y l\u00e0 m\u1ed9t ng\u00f4n ng\u1eef \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 vi\u1ebft c\u00e1c kernel AI nhanh (nh\u01b0 nh\u1eefng kernel trong ChatGPT) d\u1ec5 d\u00e0ng h\u01a1n CUDA. Vi\u1ec7c hi\u1ec3u v\u1ec1 \"tiling\" v\u00e0 \"coalescing\" t\u1eeb cu\u1ed1n s\u00e1ch n\u00e0y l\u00e0 b\u1eaft bu\u1ed9c \u0111\u1ec3 s\u1eed d\u1ee5ng Triton hi\u1ec7u qu\u1ea3.</li> <li>Nghi\u00ean c\u1ee9u CUTLASS v\u00e0 CUB: H\u00e3y xem c\u00e1c th\u01b0 vi\u1ec7n m\u00e3 ngu\u1ed3n m\u1edf c\u1ee7a NVIDIA l\u00e0 CUTLASS (cho nh\u00e2n ma tr\u1eadn) v\u00e0 CUB (cho c\u00e1c nguy\u00ean ng\u1eef). \u0110\u1ecdc m\u00e3 ngu\u1ed3n c\u1ee7a ch\u00fang s\u1ebd cho b\u1ea1n th\u1ea5y c\u00e1c k\u1ef9 s\u01b0 \"\u0110\u1eb3ng c\u1ea5p th\u1ebf gi\u1edbi\" tri\u1ec3n khai c\u00e1c m\u1eabu t\u1eeb cu\u1ed1n s\u00e1ch n\u00e0y nh\u01b0 th\u1ebf n\u00e0o.</li> <li>Kh\u00e1m ph\u00e1 \u0111a n\u1ec1n t\u1ea3ng: H\u1ecdc SYCL (cho Intel/AMD/NVIDIA) ho\u1eb7c Apple Metal. \u0110i\u1ec1u n\u00e0y \u0111\u1ea3m b\u1ea3o b\u1ea1n kh\u00f4ng ch\u1ec9 l\u00e0 m\u1ed9t \"l\u1eadp tr\u00ecnh vi\u00ean CUDA\" m\u00e0 l\u00e0 m\u1ed9t \"L\u1eadp tr\u00ecnh vi\u00ean song song\" c\u00f3 th\u1ec3 l\u00e0m vi\u1ec7c tr\u00ean b\u1ea5t k\u1ef3 lo\u1ea1i chip n\u00e0o.</li> <li>Tr\u00ecnh bi\u00ean d\u1ecbch H\u1ecdc s\u00e2u (Deep Learning Compilers): T\u00ecm hi\u1ec3u v\u1ec1 TVM ho\u1eb7c MLIR. T\u01b0\u01a1ng lai c\u1ee7a l\u0129nh v\u1ef1c n\u00e0y l\u00e0 \"Tr\u00ecnh bi\u00ean d\u1ecbch vi\u1ebft Kernel\". Hi\u1ec3u c\u00e1ch ch\u00fang t\u1ef1 \u0111\u1ed9ng h\u00f3a c\u00e1c t\u1ed1i \u01b0u h\u00f3a trong Ch\u01b0\u01a1ng 6 l\u00e0 bi\u00ean gi\u1edbi ti\u1ebfp theo.</li> </ul>"},{"location":"cuda/pmpp/engineer/#vi-skills","title":"4. C\u00e1c k\u1ef9 n\u0103ng \"ngo\u1ea1i vi\" thi\u1ebft y\u1ebfu c\u1ea7n chu\u1ea9n b\u1ecb","text":"<ul> <li>Ph\u00e2n t\u00edch s\u1ed1 h\u1ecdc: \u0110i s\u00e2u h\u01a1n Ph\u1ee5 l\u1ee5c A. Hi\u1ec3u c\u00e1ch Mixed Precision (FP8, FP16, BF16) \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn c\u1ea3 t\u1ed1c \u0111\u1ed9 v\u00e0 \u0111\u1ed9 ch\u00ednh x\u00e1c. \u0110\u00e2y l\u00e0 b\u00ed m\u1eadt c\u1ee7a vi\u1ec7c hu\u1ea5n luy\u1ec7n AI hi\u1ec7n \u0111\u1ea1i.</li> <li>Ki\u1ebfn tr\u00fac m\u00e1y t\u00ednh: \u0110\u1ecdc cu\u1ed1n Computer Architecture: A Quantitative Approach c\u1ee7a Hennessy v\u00e0 Patterson. B\u1ea1n c\u1ea7n hi\u1ec3u v\u1ec1 \"B\u1ee9c t\u01b0\u1eddng B\u1ed9 nh\u1edb\" v\u00e0 \"T\u00ednh song song c\u1ea5p l\u1ec7nh\" (ILP) \u1edf c\u1ea5p \u0111\u1ed9 ph\u1ea7n c\u1ee9ng s\u00e2u s\u1eafc.</li> <li>H\u1ec7 th\u1ed1ng ph\u00e2n t\u00e1n: Nh\u01b0 \u0111\u00e3 th\u1ea5y trong Ch\u01b0\u01a1ng 20, t\u01b0\u01a1ng lai l\u00e0 \"\u0110a GPU\". H\u00e3y t\u00ecm hi\u1ec3u v\u1ec1 NCCL (NVIDIA Collective Communications Library) v\u00e0 c\u00e1ch d\u1eef li\u1ec7u di chuy\u1ec3n qua NVLink v\u00e0 InfiniBand.</li> </ul>"},{"location":"cuda/pmpp/engineer/#mot-suy-nghi-cuoi-cung","title":"M\u1ed9t suy ngh\u0129 cu\u1ed1i c\u00f9ng","text":"<p>C\u00e1c t\u00e1c gi\u1ea3 s\u1eed d\u1ee5ng Ph\u00e9p \u1ea9n d\u1ee5 qu\u1ea3 \u0111\u00e0o trong Ch\u01b0\u01a1ng 1: Ph\u1ea7n \"h\u1ea1t\" l\u00e0 ph\u1ea7n tu\u1ea7n t\u1ef1 c\u1ee9ng nh\u1eafc, v\u00e0 ph\u1ea7n \"th\u1ecbt\" l\u00e0 ph\u1ea7n song song to l\u1edbn.</p> <p>Gi\u00e1 tr\u1ecb c\u1ee7a b\u1ea1n v\u1edbi t\u01b0 c\u00e1ch l\u00e0 m\u1ed9t k\u1ef9 s\u01b0 l\u00e0 kh\u1ea3 n\u0103ng thu nh\u1ecf ph\u1ea7n h\u1ea1t. C\u00e1c c\u00f4ng ty h\u00e0ng \u0111\u1ea7u hi\u1ec7n \u0111ang trong m\u1ed9t \"cu\u1ed9c chi\u1ebfn v\u1ec1 t\u00ednh to\u00e1n\". N\u1ebfu b\u1ea1n c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n m\u1ed9t quy tr\u00ecnh v\u1ed1n m\u1ea5t 1.000 GPU v\u00e0 t\u1ed1i \u01b0u h\u00f3a c\u00e1c kernel \u0111\u1ec3 n\u00f3 ch\u1ec9 m\u1ea5t 500 GPU, b\u1ea1n v\u1eeba ti\u1ebft ki\u1ec7m cho c\u00f4ng ty \u0111\u00f3 h\u00e0ng tri\u1ec7u \u0111\u00f4 la. Hi\u1ec7u su\u1ea5t ch\u00ednh l\u00e0 s\u1ea3n ph\u1ea9m.</p> <p>H\u00e3y coi m\u1ecdi chu k\u1ef3 (cycle) v\u00e0 m\u1ecdi byte b\u0103ng th\u00f4ng l\u00e0 m\u1ed9t t\u00e0i nguy\u00ean qu\u00fd gi\u00e1, v\u00e0 b\u1ea1n s\u1ebd th\u1ea5y m\u00ecnh n\u1eb1m trong s\u1ed1 nh\u1eefng k\u1ef9 s\u01b0 \u0111\u01b0\u1ee3c s\u0103n \u0111\u00f3n nh\u1ea5t trong ng\u00e0nh.</p>"},{"location":"efficient-ai/","title":"Efficient AI","text":"<p>Techniques to train and serve massive models on constrained resources.</p>"},{"location":"efficient-ai/#sota-roadmap","title":"SOTA Roadmap","text":""},{"location":"efficient-ai/#1-quantization-compression","title":"1. Quantization &amp; Compression","text":"<ul> <li>Weight-Only: GPTQ, AWQ (Activation-aware Weight Quantization), ExLlamaV2.</li> <li>LoRA &amp; Derivatives: QLoRA (4-bit), DoRA (Weight-Decomposed), LongLoRA.</li> <li>Extreme Quantization: 1.58-bit LLMs (BitNet b1.58), QuIP#.</li> </ul>"},{"location":"efficient-ai/#2-efficient-architectures-beyond-transformer","title":"2. Efficient Architectures (Beyond Transformer)","text":"<ul> <li>State Space Models (SSM): Mamba, S4, H3.</li> <li>Linear Attention: RWKV, RetNet (Retentive Networks).</li> <li>Hybrid Models: Jamba (Mamba + Transformer + MoE).</li> </ul>"},{"location":"efficient-ai/#3-inference-optimization","title":"3. Inference Optimization","text":"<ul> <li>Memory Management: PagedAttention (vLLM), RadixAttention (SGLang).</li> <li>Decoding Strategies: Speculative Decoding (Medusa, Lookahead), KV Cache Compression.</li> <li>Frameworks: TensorRT-LLM, MLX (Apple Silicon), TGI (HuggingFace).</li> </ul>"},{"location":"efficient-ai/#4-sparsity-pruning","title":"4. Sparsity &amp; Pruning","text":"<ul> <li>Structured Sparsity: 2:4 Sparsity (NVIDIA Ampere).</li> <li>One-Shot Pruning: SparseGPT, Wanda (Pruning by Weight and Activation).</li> </ul>"},{"location":"efficient-ai/#key-resources","title":"Key Resources","text":"<ul> <li>Blog: Tim Dettmers' Blog (The gold standard for LLM quantization).</li> <li>Library: vLLM Blog (PagedAttention internals).</li> <li>Paper: QLoRA: Efficient Finetuning of Quantized LLMs.</li> </ul>"},{"location":"genai/","title":"Generative AI","text":"<p>Explorations into the frontier of Artificial Intelligence.</p>"},{"location":"genai/#core-concepts","title":"Core Concepts","text":"<ul> <li>Transformer &amp; Attention Foundations: The architecture that started it all. A mathematical and code-level deep dive into Self-Attention, Multi-Head Attention, and Positional Encodings.</li> </ul>"},{"location":"genai/#sota-roadmap","title":"SOTA Roadmap","text":"<p>We will cover the following cutting-edge topics:</p>"},{"location":"genai/#1-large-language-models-llms","title":"1. Large Language Models (LLMs)","text":"<ul> <li>Architectures: Mixture of Experts (MoE/Mixtral), Grouped Query Attention (GQA), Rotary Embeddings (RoPE).</li> <li>Optimization: FlashAttention-2, Memory-efficient Transformers.</li> <li>State-of-the-Art Models: Analysis of Llama 3, Gemini 1.5, Claude 3.5 Sonnet.</li> </ul>"},{"location":"genai/#2-alignment-instruct-tuning","title":"2. Alignment &amp; Instruct Tuning","text":"<ul> <li>RLHF Alternatives: Direct Preference Optimization (DPO), Identity Preference Optimization (IPO).</li> <li>Synthetic Data: Self-Instruct, Evol-Instruct, Constitutional AI.</li> </ul>"},{"location":"genai/#3-image-video-generation","title":"3. Image &amp; Video Generation","text":"<ul> <li>Diffusion Evolution: Latent Diffusion (SDXL), Rectified Flow (Flux.1), Consistency Models.</li> <li>Video: Spacetime Patches (Sora), Masked Generative Transformers.</li> </ul>"},{"location":"genai/#4-reasoning-agents","title":"4. Reasoning &amp; Agents","text":"<ul> <li>Prompt Engineering: Chain of Thought (CoT), Tree of Thoughts (ToT), Reflection.</li> <li>Tool Use: ReAct, Toolformer, Function Calling patterns.</li> </ul>"},{"location":"genai/#key-resources","title":"Key Resources","text":"<ul> <li>Blog: Lilian Weng's Blog (Highly recommended for deep technical summaries).</li> <li>Visuals: The Illustrated Transformer (Jay Alammar).</li> <li>Video: Andrej Karpathy's Neural Networks: Zero to Hero.</li> </ul>"},{"location":"genai/transformer-attention/","title":"Transformer &amp; Attention Foundations","text":"EnglishTi\u1ebfng Vi\u1ec7t <p>The Transformer architecture, introduced in the seminal paper Attention Is All You Need (Vaswani et al., 2017), revolutionized natural language processing by dispensing with recurrence and convolutions entirely.</p> <p>This deep dive covers the mathematical and implementation foundations of the Transformer, focusing on the mechanism that powers it all: Self-Attention.</p> <p>Ki\u1ebfn tr\u00fac Transformer, \u0111\u01b0\u1ee3c gi\u1edbi thi\u1ec7u trong b\u00e0i b\u00e1o mang t\u00ednh n\u1ec1n t\u1ea3ng Attention Is All You Need (Vaswani et al., 2017), \u0111\u00e3 t\u1ea1o ra m\u1ed9t b\u01b0\u1edbc ngo\u1eb7t quan tr\u1ecdng trong l\u0129nh v\u1ef1c x\u1eed l\u00fd ng\u00f4n ng\u1eef t\u1ef1 nhi\u00ean khi lo\u1ea1i b\u1ecf ho\u00e0n to\u00e0n c\u00e1c c\u01a1 ch\u1ebf \u0111\u1ec7 quy (recurrence) v\u00e0 t\u00edch ch\u1eadp (convolution).</p> <p>B\u00e0i vi\u1ebft n\u00e0y tr\u00ecnh b\u00e0y c\u00f3 h\u1ec7 th\u1ed1ng c\u00e1c n\u1ec1n t\u1ea3ng to\u00e1n h\u1ecdc, tr\u1ef1c gi\u00e1c, v\u00e0 tri\u1ec3n khai th\u1ef1c t\u1ebf c\u1ee7a Transformer, t\u1eadp trung v\u00e0o c\u01a1 ch\u1ebf trung t\u00e2m quy\u1ebft \u0111\u1ecbnh hi\u1ec7u n\u0103ng c\u1ee7a m\u00f4 h\u00ecnh: Self-Attention (c\u01a1 ch\u1ebf t\u1ef1 ch\u00fa \u00fd).</p>"},{"location":"genai/transformer-attention/#en-bottleneck","title":"1. The Bottleneck of Recurrence","text":"<p>Prior to Transformers, Sequence-to-Sequence (Seq2Seq) tasks were dominated by RNNS (LSTMs/GRUs). These suffered from a critical limitation: Sequential Computation.</p> <ul> <li>Sequentiality: \\(h_t\\) depends on \\(h_{t-1}\\), preventing parallelization across time steps.</li> <li>Long-term Dependencies: Information must flow through \\(O(N)\\) steps to connect distant words.</li> </ul> <p>Transformers process the entire sequence in parallel, reducing path length between any two positions to \\(O(1)\\).</p>"},{"location":"genai/transformer-attention/#en-attention","title":"2. Scaled Dot-Product Attention","text":"<p>The core engine of the Transformer is the attention mechanism. It allows the model to weigh the importance of different tokens in the input sequence when processing a specific token.</p>"},{"location":"genai/transformer-attention/#en-qkv","title":"The Query-Key-Value Abstraction","text":"<p>We map the input vectors into three distinct spaces:</p> <ul> <li>Query (\\(Q\\)): What I am looking for? (The question)</li> <li>Key (\\(K\\)): What can I offer? (The index)</li> <li>Value (\\(V\\)): What is my actual content? (The answer)</li> </ul>"},{"location":"genai/transformer-attention/#en-math","title":"Mathematical Formulation","text":"<p>Given a query matrix \\(Q\\), key matrix \\(K\\), and value matrix \\(V\\), the attention scores are calculated as:</p> \\[ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\] <p>Where \\(d_k\\) is the dimension of the key vectors.</p> <p>Why Scale by \\(\\sqrt{d_k}\\)?</p> <p>As \\(d_k\\) increases, the dot products \\(q \\cdot k\\) can grow large in magnitude. This pushes the softmax function into regions where gradients are extremely small (vanishing gradients). Scaling by \\(\\frac{1}{\\sqrt{d_k}}\\) keeps the variance stable.</p>"},{"location":"genai/transformer-attention/#en-intuition","title":"2.1 Intuition of Attention","text":"<p>Attention can be viewed as a soft, differentiable lookup mechanism. For a given query, the model searches over all keys, determines their relevance, and aggregates the corresponding values.</p>"},{"location":"genai/transformer-attention/#en-visualization","title":"2.2 Visualization of Attention","text":"<p>Each token attends to all other tokens with different strengths, forming a weighted dependency graph.</p> <p>Example: In the sentence \"The animal didn't cross the street because it was tired\", the token \"it\" will assign a high attention weight to \"animal\" and low to \"street\", helping the model resolve coreference.</p>"},{"location":"genai/transformer-attention/#en-pytorch","title":"Implementation (PyTorch)","text":"<pre><code>import torch\nimport torch.nn.functional as F\nimport math\n\ndef scaled_dot_product_attention(query, key, value, mask=None):\n    d_k = query.size(-1)\n    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, -1e9)\n    attn_weights = F.softmax(scores, dim=-1)\n    output = torch.matmul(attn_weights, value)\n    return output, attn_weights\n</code></pre>"},{"location":"genai/transformer-attention/#en-mha","title":"3. Multi-Head Attention (MHA)","text":"<p>A single attention head might focus on a specific relationship (e.g., subject-verb). To capture multiple types of relationships simultaneously, we use Multi-Head Attention.</p> \\[ \\begin{aligned} \\text{MultiHead}(Q, K, V) &amp;= \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h)W^O \\\\ \\text{head}_i &amp;= \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) \\end{aligned} \\]"},{"location":"genai/transformer-attention/#en-pos","title":"4. Positional Encoding","text":"<p>Since the Transformer contains no recurrence and no convolution, it has no inherent sense of order. We inject Positional Encodings at the input embeddings.</p> \\[ \\begin{aligned} PE_{(pos, 2i)} &amp;= \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right) \\\\ PE_{(pos, 2i+1)} &amp;= \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right) \\end{aligned} \\]"},{"location":"genai/transformer-attention/#en-arch","title":"5. Architecture Components","text":"<p>A full Transformer block consists of: 1. Multi-Head Self-Attention 2. Position-wise Feed-Forward Networks (FFN)</p> \\[ \\text{LayerOutput}(x) = \\text{LayerNorm}(x + \\text{Sublayer}(x)) \\]"},{"location":"genai/transformer-attention/#en-summary","title":"6. Summary","text":"<p>The Transformer shift enabled:</p> <ol> <li>Massive Parallelism</li> <li>Global Receptive Field</li> <li>Foundation Models (GPT, Claude, Gemini)</li> </ol>"},{"location":"genai/transformer-attention/#vi-bottleneck","title":"1. N\u00fat th\u1eaft c\u1ee7a m\u00f4 h\u00ecnh \u0111\u1ec7 quy","text":"<p>Tr\u01b0\u1edbc khi Transformer ra \u0111\u1eddi, c\u00e1c b\u00e0i to\u00e1n Sequence-to-Sequence (Seq2Seq) ch\u1ee7 y\u1ebfu s\u1eed d\u1ee5ng c\u00e1c m\u00f4 h\u00ecnh d\u1ef1a tr\u00ean RNN (LSTM/GRU). Nh\u1eefng m\u00f4 h\u00ecnh n\u00e0y g\u1eb7p m\u1ed9t h\u1ea1n ch\u1ebf mang t\u00ednh c\u1ea5u tr\u00fac: t\u00ednh to\u00e1n tu\u1ea7n t\u1ef1.</p> <ul> <li>T\u00ednh tu\u1ea7n t\u1ef1 (Sequentiality): Tr\u1ea1ng th\u00e1i \u1ea9n \\(h_t\\) ph\u1ee5 thu\u1ed9c v\u00e0o \\(h_{t-1}\\), khi\u1ebfn vi\u1ec7c song song h\u00f3a theo chi\u1ec1u th\u1eddi gian l\u00e0 kh\u00f4ng kh\u1ea3 thi.</li> <li>Ph\u1ee5 thu\u1ed9c d\u00e0i h\u1ea1n (Long-term dependencies): Th\u00f4ng tin ph\u1ea3i \u0111i qua \\(O(N)\\) b\u01b0\u1edbc \u0111\u1ec3 li\u00ean k\u1ebft c\u00e1c token \u1edf xa nhau, l\u00e0m suy gi\u1ea3m kh\u1ea3 n\u0103ng h\u1ecdc quan h\u1ec7 d\u00e0i h\u1ea1n.</li> </ul> <p>Transformer x\u1eed l\u00fd to\u00e0n b\u1ed9 chu\u1ed7i song song, \u0111\u1ed3ng th\u1eddi r\u00fat ng\u1eafn \u0111\u1ed9 d\u00e0i \u0111\u01b0\u1eddng truy\u1ec1n th\u00f4ng tin gi\u1eefa hai v\u1ecb tr\u00ed b\u1ea5t k\u1ef3 xu\u1ed1ng c\u00f2n \\(O(1)\\).</p>"},{"location":"genai/transformer-attention/#vi-attention","title":"2. C\u01a1 ch\u1ebf Scaled Dot-Product Attention","text":"<p>Th\u00e0nh ph\u1ea7n c\u1ed1t l\u00f5i c\u1ee7a Transformer l\u00e0 c\u01a1 ch\u1ebf Attention. C\u01a1 ch\u1ebf n\u00e0y cho ph\u00e9p m\u00f4 h\u00ecnh \u0111\u00e1nh tr\u1ecdng s\u1ed1 m\u1ee9c \u0111\u1ed9 li\u00ean quan gi\u1eefa c\u00e1c token trong chu\u1ed7i khi bi\u1ec3u di\u1ec5n m\u1ed9t token c\u1ee5 th\u1ec3.</p>"},{"location":"genai/transformer-attention/#vi-qkv","title":"Tr\u1eebu t\u01b0\u1ee3ng Query\u2013Key\u2013Value (QKV)","text":"<p>C\u00e1c bi\u1ec3u di\u1ec5n \u0111\u1ea7u v\u00e0o \u0111\u01b0\u1ee3c chi\u1ebfu tuy\u1ebfn t\u00ednh sang ba kh\u00f4ng gian vector kh\u00e1c nhau:</p> <ul> <li>Query (\\(Q\\)): Bi\u1ec3u di\u1ec5n th\u00f4ng tin m\u00e0 token hi\u1ec7n t\u1ea1i \u0111ang truy v\u1ea5n.</li> <li>Key (\\(K\\)): Bi\u1ec3u di\u1ec5n th\u00f4ng tin d\u00f9ng \u0111\u1ec3 so kh\u1edbp (matching) v\u1edbi query.</li> <li>Value (\\(V\\)): Bi\u1ec3u di\u1ec5n n\u1ed9i dung th\u00f4ng tin th\u1ef1c s\u1ef1 s\u1ebd \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p.</li> </ul>"},{"location":"genai/transformer-attention/#vi-math","title":"C\u00f4ng th\u1ee9c to\u00e1n h\u1ecdc","text":"\\[ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\] <p>Trong \u0111\u00f3 \\(d_k\\) l\u00e0 s\u1ed1 chi\u1ec1u c\u1ee7a vector key.</p> <p>V\u00ec sao c\u1ea7n chu\u1ea9n h\u00f3a theo \\(\\sqrt{d_k}\\)?</p> <p>Khi \\(d_k\\) t\u0103ng, t\u00edch v\u00f4 h\u01b0\u1edbng \\(q \\cdot k\\) c\u00f3 xu h\u01b0\u1edbng c\u00f3 \u0111\u1ed9 l\u1edbn l\u1edbn h\u01a1n, khi\u1ebfn h\u00e0m softmax r\u01a1i v\u00e0o v\u00f9ng b\u00e3o h\u00f2a v\u00e0 l\u00e0m gradient tr\u1edf n\u00ean r\u1ea5t nh\u1ecf. Vi\u1ec7c chia cho \\(\\sqrt{d_k}\\) gi\u00fap \u1ed5n \u0111\u1ecbnh ph\u01b0\u01a1ng sai c\u1ee7a \u0111i\u1ec3m attention v\u00e0 c\u1ea3i thi\u1ec7n qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n.</p>"},{"location":"genai/transformer-attention/#vi-intuition","title":"2.1 Tr\u1ef1c gi\u00e1c v\u1ec1 Attention","text":"<p>Attention c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c hi\u1ec3u nh\u01b0 m\u1ed9t c\u01a1 ch\u1ebf tra c\u1ee9u m\u1ec1m (soft lookup) v\u00e0 kh\u1ea3 vi. V\u1edbi m\u1ed7i token \u0111ang x\u00e9t (query), m\u00f4 h\u00ecnh:</p> <ol> <li>So s\u00e1nh query v\u1edbi t\u1ea5t c\u1ea3 key trong chu\u1ed7i.</li> <li>\u0110\u00e1nh gi\u00e1 m\u1ee9c \u0111\u1ed9 li\u00ean quan th\u00f4ng qua t\u00edch v\u00f4 h\u01b0\u1edbng.</li> <li>Chu\u1ea9n h\u00f3a c\u00e1c m\u1ee9c \u0111\u1ed9 li\u00ean quan b\u1eb1ng softmax.</li> <li>T\u1ed5ng h\u1ee3p th\u00f4ng tin t\u1eeb c\u00e1c value theo tr\u1ecdng s\u1ed1 t\u01b0\u01a1ng \u1ee9ng.</li> </ol> <p>N\u00f3i c\u00e1ch kh\u00e1c, m\u1ed7i token t\u1ef1 quy\u1ebft \u0111\u1ecbnh n\u00ean \u201cch\u00fa \u00fd\u201d \u0111\u1ebfn nh\u1eefng token n\u00e0o kh\u00e1c khi x\u00e2y d\u1ef1ng bi\u1ec3u di\u1ec5n c\u1ee7a ch\u00ednh n\u00f3.</p>"},{"location":"genai/transformer-attention/#vi-visualization","title":"2.2 H\u00ecnh dung c\u01a1 ch\u1ebf Attention","text":"<p>C\u00f3 th\u1ec3 h\u00ecnh dung Attention nh\u01b0 m\u1ed9t \u0111\u1ed3 th\u1ecb ph\u1ee5 thu\u1ed9c \u0111\u1ea7y \u0111\u1ee7: m\u1ed7i token l\u00e0 m\u1ed9t n\u00fat v\u00e0 tr\u1ecdng s\u1ed1 attention l\u00e0 \u0111\u1ed9 m\u1ea1nh c\u1ee7a c\u1ea1nh n\u1ed1i.</p> <p>V\u00ed d\u1ee5: Trong c\u00e2u \u201cThe animal didn\u2019t cross the street because it was tired\u201d, t\u1eeb \u201cit\u201d s\u1ebd g\u00e1n tr\u1ecdng s\u1ed1 cao cho \u201canimal\u201d v\u00e0 th\u1ea5p cho \u201cstreet\u201d, gi\u00fap m\u00f4 h\u00ecnh hi\u1ec3u \u0111\u01b0\u1ee3c \u201cit\u201d \u0111ang \u00e1m ch\u1ec9 \u0111\u1ed1i t\u01b0\u1ee3ng n\u00e0o.</p>"},{"location":"genai/transformer-attention/#vi-pytorch","title":"Tri\u1ec3n khai (PyTorch)","text":"<pre><code>import torch\nimport torch.nn.functional as F\nimport math\n\ndef scaled_dot_product_attention(query, key, value, mask=None):\n    d_k = query.size(-1)\n    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, -1e9)\n    attn_weights = F.softmax(scores, dim=-1)\n    output = torch.matmul(attn_weights, value)\n    return output, attn_weights\n</code></pre>"},{"location":"genai/transformer-attention/#vi-mha","title":"3. C\u01a1 ch\u1ebf ch\u00fa \u00fd \u0111a \u0111\u1ea7u (MHA)","text":"<p>M\u1ed9t \u0111\u1ea7u ch\u00fa \u00fd \u0111\u01a1n l\u1ebb th\u01b0\u1eddng ch\u1ec9 h\u1ecdc \u0111\u01b0\u1ee3c m\u1ed9t ki\u1ec3u quan h\u1ec7 nh\u1ea5t \u0111\u1ecbnh. Multi-Head Attention cho ph\u00e9p m\u00f4 h\u00ecnh h\u1ecdc nhi\u1ec1u lo\u1ea1i quan h\u1ec7 song song t\u1eeb nhi\u1ec1u g\u00f3c nh\u00ecn kh\u00e1c nhau.</p> \\[ \\begin{aligned} \\text{MultiHead}(Q, K, V) &amp;= \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h)W^O \\\\ \\text{head}_i &amp;= \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) \\end{aligned} \\]"},{"location":"genai/transformer-attention/#vi-pos","title":"4. M\u00e3 h\u00f3a v\u1ecb tr\u00ed (Positional Encoding)","text":"<p>Do Transformer kh\u00f4ng c\u00f3 c\u01a1 ch\u1ebf \u0111\u1ec7 quy, th\u00f4ng tin v\u1ecb tr\u00ed ph\u1ea3i \u0111\u01b0\u1ee3c ti\u00eam tr\u1ef1c ti\u1ebfp v\u00e0o embedding th\u00f4ng qua c\u00e1c h\u00e0m sin v\u00e0 cos.</p> \\[ \\begin{aligned} PE_{(pos, 2i)} &amp;= \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right) \\\\ PE_{(pos, 2i+1)} &amp;= \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right) \\end{aligned} \\]"},{"location":"genai/transformer-attention/#vi-arch","title":"5. C\u00e1c th\u00e0nh ph\u1ea7n ki\u1ebfn tr\u00fac","text":"<p>M\u1ed9t kh\u1ed1i Transformer chu\u1ea9n bao g\u1ed3m hai l\u1edbp ph\u1ee5: Multi-Head Self-Attention v\u00e0 Feed-Forward Network (FFN), \u0111\u01b0\u1ee3c bao b\u1ecdc b\u1edfi k\u1ebft n\u1ed1i d\u01b0 v\u00e0 chu\u1ea9n h\u00f3a l\u1edbp (LayerNorm).</p> \\[ \\text{LayerOutput}(x) = \\text{LayerNorm}(x + \\text{Sublayer}(x)) \\]"},{"location":"genai/transformer-attention/#vi-summary","title":"6. T\u1ed5ng k\u1ebft","text":"<p>Transformer thay th\u1ebf ho\u00e0n to\u00e0n \u0111\u1ec7 quy b\u1eb1ng Attention, cho ph\u00e9p:</p> <ol> <li>Song song h\u00f3a to\u00e0n di\u1ec7n</li> <li>Tr\u01b0\u1eddng ti\u1ebfp nh\u1eadn to\u00e0n c\u1ee5c</li> <li>Kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng quy m\u00f4 l\u1edbn (n\u1ec1n t\u1ea3ng cho GPT, Claude, Gemini).</li> </ol>"},{"location":"ml/practice/","title":"Machine Learning Practice","text":"<p>This section focuses on implementation details, best practices, and code snippets.</p>"},{"location":"ml/practice/#sota-roadmap","title":"SOTA Roadmap","text":""},{"location":"ml/practice/#1-distributed-training","title":"1. Distributed Training","text":"<ul> <li>Parallelism: Data Parallel (DDP/FSDP), Tensor Parallel (TP), Pipeline Parallel (PP).</li> <li>Infrastructure: DeepSpeed, Megatron-LM, DTensor (PyTorch).</li> </ul>"},{"location":"ml/practice/#2-high-performance-kernels","title":"2. High-Performance Kernels","text":"<ul> <li>Triton: Writing custom CUDA kernels in Python.</li> <li>FlashAttention: IO-Aware exact attention.</li> <li>Kernel Fusion: torch.compile (Inductor).</li> </ul>"},{"location":"ml/practice/#3-mlops-for-llms-llmops","title":"3. MLOps for LLMs (LLMOps)","text":"<ul> <li>Evaluation: Ragas, TruLens.</li> <li>serving: vLLM, TGI, SGLang.</li> </ul>"},{"location":"ml/practice/#key-resources","title":"Key Resources","text":"<ul> <li>Guide: Effective PyTorch.</li> <li>Book: Machine Learning Engineering (Andriy Burkov).</li> <li>Repo: Hugging Face Transformers.</li> </ul>"},{"location":"ml/practice/#efficient-data-loading","title":"Efficient Data Loading","text":"<p>When training large models, data loading can become a bottleneck. Here is a comparison of standard vs optimized loading patterns.</p> Standard PyTorchOptimized with Prefetch <pre><code>import torch\nfrom torch.utils.data import DataLoader, Dataset\n\nclass SimpleDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n\n    def __getitem__(self, index):\n        return self.data[index]\n\n    def __len__(self):\n        return len(self.data)\n\n# Standard loader\nloader = DataLoader(\n    SimpleDataset(range(1000)), \n    batch_size=32, \n    shuffle=True\n)\n</code></pre> <pre><code>import torch\nfrom torch.utils.data import DataLoader\n\n# Optimized loader config\nloader = DataLoader(\n    dataset, \n    batch_size=32, \n    shuffle=True,\n    num_workers=4,           # Parallelize reading\n    pin_memory=True,         # Fast transfer to CUDA\n    prefetch_factor=2        # Pre-load batches\n)\n</code></pre>"},{"location":"ml/practice/#fun-with-python","title":"Fun with Python","text":"<p>Sometimes we need to remember the roots of our tools.</p> <pre><code>\"\"\"\nThe Antigravity Module.\nA classic Python Easter egg.\n\"\"\"\n\nimport antigravity\n\ndef fly():\n    print(\"Flying with Python!\")\n    # This module opens a web browser to the XKCD comic about Python.\n    # https://xkcd.com/353/\n\nif __name__ == \"__main__\":\n    fly()\n</code></pre> <p>This snippet is loaded dynamically from <code>docs/snippets/antigravity.py</code>!</p>"},{"location":"ml/theory/","title":"Machine Learning Theory","text":"<p>This section covers the mathematical foundations of modern machine learning algorithms.</p>"},{"location":"ml/theory/#sota-roadmap","title":"SOTA Roadmap","text":""},{"location":"ml/theory/#1-modern-optimization-theory","title":"1. Modern Optimization Theory","text":"<ul> <li>Loss Landscapes: Mode Connectivity, Sharpness-Aware Minimization (SAM).</li> <li>Convergence: Grokking (Delayed Generalization), Edge of Stability.</li> </ul>"},{"location":"ml/theory/#2-deep-learning-foundations","title":"2. Deep Learning Foundations","text":"<ul> <li>Normalization: LayerNorm vs RMSNorm effects on signal propagation.</li> <li>Scaling Laws: Chinchilla Scaling, Kaplan Laws.</li> <li>Neural Tangent Kernel (NTK): Limits of infinite width networks.</li> </ul>"},{"location":"ml/theory/#3-generalization","title":"3. Generalization","text":"<ul> <li>Double Descent: Bias-Variance Trade-off revisited.</li> <li>Benign Overfitting: Why deep networks generalize without regularization.</li> </ul>"},{"location":"ml/theory/#key-resources","title":"Key Resources","text":"<ul> <li>Book: Deep Learning (Goodfellow et al.).</li> <li>Course: Practical Deep Learning for Coders (fast.ai).</li> <li>Visuals: Distill.pub (Interactive explanations).</li> </ul>"},{"location":"paper-reviews/","title":"Paper Reviews","text":"<p>Keeping up with the firehose of AI research. Concise summaries, critical takes, and implementation notes.</p>"},{"location":"paper-reviews/#latest-reviews","title":"Latest Reviews","text":"<ul> <li>Coming Soon: Setup for weekly Arxiv highlights.</li> </ul>"},{"location":"paper-reviews/#key-themes","title":"Key Themes","text":"<ul> <li>Architecture Innovations: New attention mechanisms, State Space Models.</li> <li>Training Dynamics: Scaling laws, loss landscape analysis.</li> <li>Post-Training: Alignment algorithms (DPO, KTO).</li> </ul>"},{"location":"trustworthy-ai/","title":"Trustworthy AI","text":"<p>Research on bias, fairness, robustness, and interpretability in AI systems.</p>"},{"location":"trustworthy-ai/#sota-roadmap","title":"SOTA Roadmap","text":""},{"location":"trustworthy-ai/#1-mechanistic-interpretability","title":"1. Mechanistic Interpretability","text":"<ul> <li>Reverse Engineering LLMs: Induction Heads, Superposition, Monosemanticity.</li> <li>Probing: Linear Probing, Activation Steering (Representation Engineering).</li> <li>Dictionary Learning: Sparse Autoencoders (SAE) for feature extraction (Anthropic research).</li> </ul>"},{"location":"trustworthy-ai/#2-adversarial-robustness-safety","title":"2. Adversarial Robustness &amp; Safety","text":"<ul> <li>Jailbreaking: GCG (Greedy Coordinate Gradient), PAIR, TAP (Tree of Attacks).</li> <li>Defenses: LlamaGuard, NeMo Guardrails, Circuit Breaking.</li> <li>Red Teaming: Automated Red Teaming via LLMs.</li> </ul>"},{"location":"trustworthy-ai/#3-evaluation-benchmarks","title":"3. Evaluation &amp; Benchmarks","text":"<ul> <li>Benchmarks: MMLU-Pro, GPQA (Graduate-Level Reasoning), MATH.</li> <li>Safety Benchmarks: TruthfulQA, RealToxicityPrompts, Do-Not-Answer.</li> <li>LLM-as-a-Judge: MT-Bench, AlpacaEval 2.0.</li> </ul>"},{"location":"trustworthy-ai/#4-detection-watermarking","title":"4. Detection &amp; Watermarking","text":"<ul> <li>Watermarking: Tree-Ring Watermarking, Distillation-Resistant Watermarking.</li> <li>Hallucination: Detection via Uncertainty (SelfCheckGPT), RAG-based Fact Checking.</li> </ul>"},{"location":"trustworthy-ai/#key-resources","title":"Key Resources","text":"<ul> <li>Journal: Transformer Circuits Thread (Anthropic's interpretability research).</li> <li>Course: AI Safety Fundamentals (BlueDot).</li> <li>Benchmark: Chatbot Arena Leaderboard.</li> </ul>"}]}